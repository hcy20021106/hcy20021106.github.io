<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hechenyi.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Basic Concept先了解MMSE，MMSE（Minimum Mean Square Error），也就是最小均方误差，是一种常用的统计估计方法，它的目标就是最小化估计值与实际值之间的均方误差（MSE）。在通信系统中，MMSE被广泛用于信道估计，因为它能够在噪声和干扰的影响下，给出一个最优估计。另外，在信道估计中，交叉相关矩阵通常用于计算数据子载波和导频子载波之间的相关性，这对于估计信道的状">
<meta property="og:type" content="article">
<meta property="og:title" content="LMMSE base channel estimation">
<meta property="og:url" content="https://hechenyi.github.io/2025/04/29/LMMSE-base-channel-estimation/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Basic Concept先了解MMSE，MMSE（Minimum Mean Square Error），也就是最小均方误差，是一种常用的统计估计方法，它的目标就是最小化估计值与实际值之间的均方误差（MSE）。在通信系统中，MMSE被广泛用于信道估计，因为它能够在噪声和干扰的影响下，给出一个最优估计。另外，在信道估计中，交叉相关矩阵通常用于计算数据子载波和导频子载波之间的相关性，这对于估计信道的状">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-04-28T16:45:01.000Z">
<meta property="article:modified_time" content="2025-08-04T13:37:05.573Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://hechenyi.github.io/2025/04/29/LMMSE-base-channel-estimation/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>LMMSE base channel estimation | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/04/29/LMMSE-base-channel-estimation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          LMMSE base channel estimation
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-04-29 00:45:01" itemprop="dateCreated datePublished" datetime="2025-04-29T00:45:01+08:00">2025-04-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-04 21:37:05" itemprop="dateModified" datetime="2025-08-04T21:37:05+08:00">2025-08-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/5G/" itemprop="url" rel="index"><span itemprop="name">5G</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Basic-Concept"><a href="#Basic-Concept" class="headerlink" title="Basic Concept"></a>Basic Concept</h2><p>先了解MMSE，MMSE（Minimum Mean Square Error），也就是最小均方误差，是一种常用的统计估计方法，它的目标就是最小化估计值与实际值之间的均方误差（MSE）。在通信系统中，MMSE被广泛用于信道估计，因为它能够在噪声和干扰的影响下，给出一个最优估计。<br>另外，在信道估计中，交叉相关矩阵通常用于计算数据子载波和导频子载波之间的相关性，这对于估计信道的状态至关重要。</p>
<h2 id="数学公式推导"><a href="#数学公式推导" class="headerlink" title="数学公式推导"></a>数学公式推导</h2><h1 id="OFDM-System-Simulation-with-LMMSE-Channel-Estimation"><a href="#OFDM-System-Simulation-with-LMMSE-Channel-Estimation" class="headerlink" title="OFDM System Simulation with LMMSE Channel Estimation"></a>OFDM System Simulation with LMMSE Channel Estimation</h1><p>This MATLAB project simulates an OFDM system using <strong>LMMSE (Linear Minimum Mean Square Error)</strong> channel estimation over a <strong>frequency-selective Rayleigh fading channel</strong>. The system uses QPSK modulation and pilot symbols to perform accurate channel estimation in the frequency domain.</p>
<hr>
<h2 id="📌-Features"><a href="#📌-Features" class="headerlink" title="📌 Features"></a>📌 Features</h2><ul>
<li>QPSK modulation  </li>
<li>Rayleigh fading multipath channel  </li>
<li>AWGN noise  </li>
<li>LMMSE-based pilot-aided channel estimation (PACE)  </li>
<li>Bit Error Rate (BER) analysis</li>
</ul>
<hr>
<h2 id="🧠-Theoretical-Background"><a href="#🧠-Theoretical-Background" class="headerlink" title="🧠 Theoretical Background"></a>🧠 Theoretical Background</h2><h3 id="1-OFDM-Signal-Model"><a href="#1-OFDM-Signal-Model" class="headerlink" title="1. OFDM Signal Model"></a>1. OFDM Signal Model</h3><p>The received signal on subcarrier ( k ) is:</p>
<p>$$<br>Y[k] &#x3D; H[k] \cdot X[k] + W[k]<br>$$</p>
<p>Where:</p>
<p>$$<br>X[k]: \text{ Transmitted signal on subcarrier } k \<br>H[k]: \text{ Channel frequency response at subcarrier } k \<br>W[k]: \text{ Additive white Gaussian noise (AWGN)} \<br>Y[k]: \text{ Received signal at subcarrier } k<br>$$</p>
<hr>
<h3 id="2-LMMSE-Channel-Estimation"><a href="#2-LMMSE-Channel-Estimation" class="headerlink" title="2. LMMSE Channel Estimation"></a>2. LMMSE Channel Estimation</h3><p>The LMMSE estimate of the channel at data subcarriers is:</p>
<p>$$<br>\hat{H}<em>{\text{data}} &#x3D; R</em>{hd,hp} \left( R_{hp,hp} + \sigma^2 (X X^H)^{-1} \right)^{-1} \hat{H}_{\text{pilot}}<br>$$</p>
<p>Where:</p>
<p>$$<br>R_{hd,hp}: \text{ Cross-correlation matrix between data and pilot subcarriers} \<br>R_{hp,hp}: \text{ Autocorrelation matrix of pilot subcarriers} \<br>\hat{H}_{\text{pilot}}: \text{ LS-estimated channel at pilot positions} \<br>\sigma^2: \text{ Noise variance} \<br>X: \text{ Diagonal matrix of known pilot symbols}<br>$$</p>
<hr>
<h3 id="3-Channel-Frequency-Response-DFT"><a href="#3-Channel-Frequency-Response-DFT" class="headerlink" title="3. Channel Frequency Response (DFT)"></a>3. Channel Frequency Response (DFT)</h3><p>The time-domain convolution is，这也是一个离散时间的线性卷积公式，它描述了<strong>多径信道</strong>(多径效应)对时域基带信号的影响，其中每一个h[l]表示不同时间延迟下的路径增益:</p>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>引入OFDM可以抗多径，因为在循环前缀CP足够长的条件下，把时域的多径线性卷积变换为<strong>循环卷积</strong>,也就是Y[k] &#x3D; H[k]X[k] + W[k]<br></p>
</blockquote>
<hr>
<p>$$<br>y[n] &#x3D; \sum_{m&#x3D;0}^{L-1} h[m] \cdot x[n - m]<br>$$</p>
<p>The corresponding channel frequency response is obtained via DFT:</p>
<p>$$<br>H[k] &#x3D; \sum_{l&#x3D;0}^{L-1} h[l] \cdot e^{-j \frac{2\pi k l}{N}}<br>$$</p>
<p>Where:</p>
<p>$$<br>h[l]: \text{ Channel tap in time domain} \<br>N: \text{ FFT length (number of subcarriers)} \<br>k: \text{ Subcarrier index}<br>$$</p>
<hr>
<h3 id="4-Calculation-of-R-hp-hp"><a href="#4-Calculation-of-R-hp-hp" class="headerlink" title="4. Calculation of $R_{hp,hp}$"></a>4. Calculation of $R_{hp,hp}$</h3><p>在统计通信理论中，如果H[i]是频率索引为i的频域信道系数（例如OFDM中第i个子载波的信道响应）<br>$R_H(i,j)&#x3D;E[H[i]H[j]]$<br>To calculate the autocorrelation matrix between pilot subcarriers $R_{hp,hp}$, we start from the frequency-domain channel representation. The channel frequency response at subcarrier ( n ) is given by the discrete Fourier transform (DFT) of the time-domain channel taps:</p>
<p>$$<br>H[n] &#x3D; \sum_{l&#x3D;0}^{L-1} h[l] e^{-j \frac{2\pi}{N} n l}<br>$$</p>
<p>where:</p>
<ul>
<li>( L ) is the number of channel taps,</li>
<li>( h[l] ) is the complex channel coefficient of the ( l )-th tap,</li>
<li>( N ) is the FFT length,</li>
<li>( n ) is the subcarrier index.</li>
</ul>
<p>The autocorrelation between frequency responses at pilot subcarrier indices ( n_i ) and ( n_j ) is:</p>
<p>$$<br>\begin{aligned}<br>R_{hp,hp}(i,j) &amp;&#x3D; E \left[ H[n_i] H^<em>[n_j] \right] \<br>&amp;&#x3D; E \left[ \left( \sum_{l&#x3D;0}^{L-1} h[l] e^{-j \frac{2\pi}{N} n_i l} \right) \left( \sum_{m&#x3D;0}^{L-1} h[m] e^{-j \frac{2\pi}{N} n_j m} \right)^</em> \right] \<br>&amp;&#x3D; \sum_{l&#x3D;0}^{L-1} \sum_{m&#x3D;0}^{L-1} e^{-j \frac{2\pi}{N} n_i l} e^{j \frac{2\pi}{N} n_j m} E \left[ h[l] h^*[m] \right]<br>\end{aligned}<br>$$</p>
<p>Assuming that the channel taps are uncorrelated with power delay profile $\sigma_l^2 &#x3D; E[|h[l]|^2]$, we have:</p>
<p>$$<br>E \left[ h[l] h^*[m] \right] &#x3D;<br>\begin{cases}<br>\sigma_l^2, &amp; l &#x3D; m \<br>0, &amp; l \neq m<br>\end{cases}<br>$$</p>
<p>Thus, the autocorrelation matrix element simplifies to:</p>
<p>$$<br>R_{hp,hp}(i,j) &#x3D; \sum_{l&#x3D;0}^{L-1} \sigma_l^2 e^{-j \frac{2\pi}{N} (n_i - n_j) l}<br>$$</p>
<p>This formula describes the correlation between frequency-domain channel coefficients at pilot positions ( n_i ) and ( n_j ), derived from the time-domain power delay profile.</p>
<hr>
<h3 id="5-Calculation-of-R-hd-hp"><a href="#5-Calculation-of-R-hd-hp" class="headerlink" title="5. Calculation of $R_{hd,hp}$"></a>5. Calculation of $R_{hd,hp}$</h3><p>计算过程和计算导频之间的互相关函数一样，只是需要注意data部分的索引。</p>
<h2 id="📁-File-Structure"><a href="#📁-File-Structure" class="headerlink" title="📁 File Structure"></a>📁 File Structure</h2><ul>
<li><code>ofdm_lmmse_sim.m</code> – Main simulation script  </li>
<li><code>Gen_autocorr.m</code> – Generates channel autocorrelation values  </li>
<li><code>README.md</code> – Project documentation</li>
</ul>
<hr>
<h2 id="⚙️-Key-Parameters"><a href="#⚙️-Key-Parameters" class="headerlink" title="⚙️ Key Parameters"></a>⚙️ Key Parameters</h2><table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody><tr>
<td>FFT Length</td>
<td>256</td>
</tr>
<tr>
<td>Pilot Count</td>
<td>32</td>
</tr>
<tr>
<td>Channel Taps</td>
<td>10</td>
</tr>
<tr>
<td>Cyclic Prefix</td>
<td>9</td>
</tr>
<tr>
<td>SNR</td>
<td>40 dB</td>
</tr>
<tr>
<td>Modulation</td>
<td>QPSK</td>
</tr>
<tr>
<td>Simulation Frames</td>
<td>1000</td>
</tr>
</tbody></table>
<hr>
<h2 id="CSI-Acquisition-and-Precoding-Impact-on-BER"><a href="#CSI-Acquisition-and-Precoding-Impact-on-BER" class="headerlink" title="CSI Acquisition and Precoding Impact on BER"></a>CSI Acquisition and Precoding Impact on BER</h2><p>In MIMO-OFDM systems, accurate Channel State Information (CSI) is essential for leveraging spatial multiplexing gains and optimizing transmission through precoding:</p>
<ul>
<li><strong>Channel Sounding:</strong> Known pilot or preamble sequences are transmitted to probe the channel. The receiver estimates the CSI (\hat{H}) using LMMSE or similar methods.  </li>
<li><strong>CSI Feedback &amp; Precoding:</strong> The estimated CSI is fed back to the transmitter, which computes a precoding matrix ( \mathbf{V} ) (e.g., based on SVD or LMMSE estimation) to pre-multiply data symbols. This precoding enhances signal quality and mitigates interference.  </li>
<li><strong>Data Transmission &amp; BER:</strong> The precoded data is transmitted through the MIMO channel. The receiver decodes the signals based on the estimated CSI. The accuracy of CSI directly affects Bit Error Rate (BER) performance — better CSI leads to lower BER.</li>
</ul>
<p>Example MATLAB snippet for per-subcarrier precoding:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> carrIdx = <span class="number">1</span>:prm.numCarriers</span><br><span class="line">    Q = <span class="built_in">squeeze</span>(v(carrIdx,:,:));</span><br><span class="line">    normQ = Q * <span class="built_in">sqrt</span>(numTx)/norm(Q,<span class="string">&#x27;fro&#x27;</span>);</span><br><span class="line">    preData(carrIdx,symIdx,:) = <span class="built_in">squeeze</span>(gridData(carrIdx,symIdx,:)).&#x27; * normQ;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Deep-Learning-for-CSI-Prediction"><a href="#Deep-Learning-for-CSI-Prediction" class="headerlink" title="Deep Learning for CSI Prediction"></a>Deep Learning for CSI Prediction</h3><h4 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h4><p>Use a neural network to predict CSI vectors from the received LTF sequences instead of using LMMSE.</p>
<h4 id="Model-Architecture-Keras"><a href="#Model-Architecture-Keras" class="headerlink" title="Model Architecture (Keras)"></a>Model Architecture (Keras)</h4><ul>
<li>Fully Connected Neural Network (FC或MLP)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.model == <span class="string">&#x27;FC&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;now the model is Full Dense Model&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> args.datasource == <span class="string">&#x27;matlab_maMimo&#x27;</span>:</span><br><span class="line">        <span class="keyword">if</span> args.decimate_max:</span><br><span class="line">            decimate = Flatten()(MaxPooling1D()(next_layer_in))</span><br><span class="line">            next_layer_in = Concatenate(axis=1)([decimate, seq_p])</span><br><span class="line">        <span class="keyword">elif</span> args.decimate_avg:</span><br><span class="line">            decimate = Flatten()(AveragePooling1D()(next_layer_in))</span><br><span class="line">            next_layer_in = Concatenate(axis=1)([decimate, seq_p])</span><br><span class="line">        <span class="comment"># TODO aggiungere decimazione pura (senza max o avg pooling, solo scarto)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            flatten = Flatten()(next_layer_in)</span><br><span class="line">            next_layer_in = Concatenate(axis=1)([flatten, seq_p])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, n <span class="keyword">in</span> enumerate(nn):</span><br><span class="line">        layers[<span class="string">&#x27;dense&#x27;</span>].append(</span><br><span class="line">            Dense(nn[i], activation=<span class="string">&#x27;relu&#x27;</span>, kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>, name=<span class="string">&#x27;fc_dense&#x27;</span>+str(i))(next_layer_in)</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> args.useBN:</span><br><span class="line">            layers[<span class="string">&#x27;batchnorm&#x27;</span>].append(</span><br><span class="line">                BatchNormalization()(layers[<span class="string">&#x27;dense&#x27;</span>][-1])</span><br><span class="line">            )</span><br><span class="line">            next_layer_in = layers[<span class="string">&#x27;batchnorm&#x27;</span>][-1]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            next_layer_in = layers[<span class="string">&#x27;dense&#x27;</span>][-1]</span><br><span class="line">        <span class="keyword">if</span> (i &lt; (numDense - 1)) and (args.dropout != 0.0):  <span class="comment"># if not the last layer, add dropout</span></span><br><span class="line">            layers[<span class="string">&#x27;dropout&#x27;</span>].append(</span><br><span class="line">                Dropout(args.dropout, name=<span class="string">&#x27;drop&#x27;</span>+str(i))(next_layer_in)</span><br><span class="line">            )</span><br><span class="line">            next_layer_in = layers[<span class="string">&#x27;dropout&#x27;</span>][-1]</span><br><span class="line">    encoder = Dense(simParams[<span class="string">&#x27;nSubCarr&#x27;</span>], activation=<span class="string">&#x27;linear&#x27;</span>, kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>, name=<span class="string">&#x27;fc_regressor&#x27;</span>)(next_layer_in)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.datasource == <span class="string">&#x27;matlab_maMimo&#x27;</span>:</span><br><span class="line">        CSI_predictor = Model([seq_in,seq_p], encoder)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        CSI_predictor = Model(seq_in, encoder)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中隐藏层nn数列为[1024,1024],因此最后的模型summary为：</p>
<table>
<thead>
<tr>
<th>Layer Name</th>
<th>Type</th>
<th>Output Shape</th>
<th>Parameters</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><code>seq_in</code></td>
<td>Input</td>
<td><code>(None, T, F)</code></td>
<td>0</td>
<td>CSI time-series input</td>
</tr>
<tr>
<td><code>seq_p</code></td>
<td>Input</td>
<td><code>(None, P)</code></td>
<td>0</td>
<td>Position input</td>
</tr>
<tr>
<td><code>flatten</code></td>
<td>Flatten</td>
<td><code>(None, T×F)</code></td>
<td>0</td>
<td>Flattens CSI sequence</td>
</tr>
<tr>
<td><code>concatenate</code></td>
<td>Concatenate</td>
<td><code>(None, T×F + P)</code></td>
<td>0</td>
<td>Merges CSI and position inputs</td>
</tr>
<tr>
<td><code>fc_dense0</code></td>
<td>Dense</td>
<td><code>(None, 1024)</code></td>
<td><code>(T×F + P + 1) × 1024</code></td>
<td>Fully connected layer with ReLU</td>
</tr>
<tr>
<td><code>batch_norm_0</code></td>
<td>BatchNorm</td>
<td><code>(None, 1024)</code></td>
<td>4096</td>
<td>Batch normalization</td>
</tr>
<tr>
<td><code>drop0</code></td>
<td>Dropout</td>
<td><code>(None, 1024)</code></td>
<td>0</td>
<td>Dropout layer (optional)</td>
</tr>
<tr>
<td><code>fc_dense1</code></td>
<td>Dense</td>
<td><code>(None, 1024)</code></td>
<td><code>1024 × 1024 + 1024 = 1,049,600</code></td>
<td>Hidden dense layer</td>
</tr>
<tr>
<td><code>batch_norm_1</code></td>
<td>BatchNorm</td>
<td><code>(None, 1024)</code></td>
<td>4096</td>
<td>Batch normalization</td>
</tr>
<tr>
<td><code>fc_regressor</code></td>
<td>Dense</td>
<td><code>(None, nSubCarr)</code></td>
<td><code>1024 × nSubCarr + nSubCarr</code></td>
<td>Output prediction (e.g., CSI subcarriers)</td>
</tr>
</tbody></table>
<ul>
<li>CNN</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> args.model ==<span class="string">&#x27;CONV1D&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;now the model is Convolution 1D Model&quot;</span>)</span><br><span class="line"></span><br><span class="line">    conv1 = BatchNormalization()(Conv1D(128, 7, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;cnn1d_1&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(next_layer_in))</span><br><span class="line">    maxpool1 = AveragePooling1D()(conv1)</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    conv2 = BatchNormalization()(Conv1D(64, 7, padding=&#x27;same&#x27;, name=&#x27;cnn1d_2&#x27;, activation=&#x27;relu&#x27;)(maxpool1))</span></span><br><span class="line"><span class="string">    maxpool2 = AveragePooling1D()(conv2)</span></span><br><span class="line"><span class="string">   </span></span><br><span class="line"><span class="string">    conv3 = BatchNormalization()(Conv1D(64, 5, padding=&#x27;same&#x27;, name=&#x27;cnn1d_3&#x27;, activation=&#x27;relu&#x27;)(maxpool2))</span></span><br><span class="line"><span class="string">    maxpool3 = MaxPooling1D()(conv3)</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    flatten = Flatten()(maxpool1)</span><br><span class="line">    <span class="comment"># TODO INSERT CONVOLUTIONAL AUTOENCODER HERE</span></span><br><span class="line"></span><br><span class="line">    next_layer_in = Concatenate(axis=1)([flatten, seq_p])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, n <span class="keyword">in</span> enumerate(nn):</span><br><span class="line">        layers[<span class="string">&#x27;dense&#x27;</span>].append(</span><br><span class="line">            Dense(nn[i], activation=<span class="string">&#x27;relu&#x27;</span>, kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>, name=<span class="string">&#x27;fc_dense&#x27;</span>+str(i))(next_layer_in)</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> args.useBN:</span><br><span class="line">            layers[<span class="string">&#x27;batchnorm&#x27;</span>].append(</span><br><span class="line">                BatchNormalization()(layers[<span class="string">&#x27;dense&#x27;</span>][-1])</span><br><span class="line">            )</span><br><span class="line">            next_layer_in = layers[<span class="string">&#x27;batchnorm&#x27;</span>][-1]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            next_layer_in = layers[<span class="string">&#x27;dense&#x27;</span>][-1]</span><br><span class="line">        <span class="keyword">if</span> i &lt; (numDense - 1):  <span class="comment"># if not the last layer, add dropout</span></span><br><span class="line">            layers[<span class="string">&#x27;dropout&#x27;</span>].append(</span><br><span class="line">                Dropout(args.dropout, name=<span class="string">&#x27;drop&#x27;</span>+str(i))(next_layer_in)</span><br><span class="line">            )</span><br><span class="line">            next_layer_in = layers[<span class="string">&#x27;dropout&#x27;</span>][-1]</span><br><span class="line">    encoder = Dense(n_out, activation=<span class="string">&#x27;linear&#x27;</span>, kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>, name=<span class="string">&#x27;fc_regressor&#x27;</span>)(next_layer_in)</span><br><span class="line"></span><br><span class="line">    CSI_predictor = Model([seq_in,seq_p], encoder)</span><br></pre></td></tr></table></figure>
<p>模型的summary如下：</p>
<table>
<thead>
<tr>
<th>Layer Name</th>
<th>Layer Type</th>
<th>Output Shape</th>
<th>Number of Parameters</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>seq_in</td>
<td>InputLayer</td>
<td>(None, T, F)</td>
<td>0</td>
<td>Input CSI sequence</td>
</tr>
<tr>
<td>cnn1d_1</td>
<td>Conv1D</td>
<td>(None, T, 128)</td>
<td>(F * 7 * 128) + 128</td>
<td>1D convolution, kernel size 7, 128 filters</td>
</tr>
<tr>
<td>batch_normalization</td>
<td>BatchNormalization</td>
<td>(None, T, 128)</td>
<td>512</td>
<td>Normalization after conv1d</td>
</tr>
<tr>
<td>average_pooling1d</td>
<td>AveragePooling1D</td>
<td>(None, T&#x2F;&#x2F;2, 128)</td>
<td>0</td>
<td>Downsampling by average pooling</td>
</tr>
<tr>
<td>flatten</td>
<td>Flatten</td>
<td>(None, (T&#x2F;&#x2F;2) * 128)</td>
<td>0</td>
<td>Flatten pooled feature maps</td>
</tr>
<tr>
<td>seq_p</td>
<td>InputLayer</td>
<td>(None, P)</td>
<td>0</td>
<td>Additional parameter input (e.g., position)</td>
</tr>
<tr>
<td>concatenate</td>
<td>Concatenate</td>
<td>(None, (T&#x2F;&#x2F;2)*128 + P)</td>
<td>0</td>
<td>Concatenate flattened features and params</td>
</tr>
<tr>
<td>fc_dense0</td>
<td>Dense</td>
<td>(None, 1024)</td>
<td>((T&#x2F;&#x2F;2)*128 + P + 1) * 1024</td>
<td>Fully connected layer with 1024 units</td>
</tr>
<tr>
<td>batch_normalization_1</td>
<td>BatchNormalization</td>
<td>(None, 1024)</td>
<td>4096</td>
<td>Normalization after fc_dense0</td>
</tr>
<tr>
<td>drop0</td>
<td>Dropout</td>
<td>(None, 1024)</td>
<td>0</td>
<td>Dropout for regularization</td>
</tr>
<tr>
<td>fc_dense1</td>
<td>Dense</td>
<td>(None, 1024)</td>
<td>1,049,600 (1024*1024 + 1024)</td>
<td>Fully connected layer with 1024 units</td>
</tr>
<tr>
<td>batch_normalization_2</td>
<td>BatchNormalization</td>
<td>(None, 1024)</td>
<td>4096</td>
<td>Normalization after fc_dense1</td>
</tr>
<tr>
<td>drop1</td>
<td>Dropout</td>
<td>(None, 1024)</td>
<td>0</td>
<td>Dropout for regularization</td>
</tr>
<tr>
<td>fc_re</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>需要注意这里的T就是inPreamble，因此在取卷积后output shape为(T,128)，其中128为通道数<br></p>
</blockquote>
<hr>
<p>Output:</p>
<ul>
<li>Predicted CSI of shape $n_{Rx} \times n_{Tx} \times n_{SubCarriers}$</li>
</ul>
<h4 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h4><p>The model minimizes <strong>MSE</strong> between predicted CSI and ground truth:</p>
<p>$$<br>\text{MSE} &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^{N} \left| H_i - \hat{H}_i \right|^2<br>$$</p>
<p>Also supports NMSE:</p>
<p>$$<br>\text{NMSE} &#x3D; \frac{| H - \hat{H} |^2}{| H |^2}<br>$$<br>这里的$\hat{H}$是通过LMMSE计算得到的，因此是将传统信道估计方法得到的CSI作为ground truth，也就是target</p>
<h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><h5 id="数据生成"><a href="#数据生成" class="headerlink" title="数据生成"></a>数据生成</h5><ul>
<li>generate_maMIMO_LTF.m</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> [mean_ber] = generate_maMIMO_LTF(exp_ID, numPackets, numBSTx, numUERx, snr_dB_CS, isOnlyCSI, saveFlag, isPlotting, prm, isMMSE)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">usr_data = cell(prm.numUsers, 3);</span><br><span class="line"><span class="keyword">for</span> p = 1 : numPackets:</span><br><span class="line">    <span class="keyword">for</span> nUser = 1:prm.numUsers:</span><br><span class="line">        /// preambleSig的维度 = (FFTLength + CyclicPrefixLength) * numSTS</span><br><span class="line">        /// numSTS = numTx</span><br><span class="line">        preambleSig = helperGenPreamble(prm);</span><br><span class="line">        /// rxPreSig的维度 = numRx x numPreambleSig</span><br><span class="line">        [rxPreSig,chanDelay,h_tau,h_response] = helperApplyMUChannel(preambleSig,prm,spLoss,N_chan_taps,p);</span><br><span class="line">        ...</span><br><span class="line">        usr_data&#123;nUser, 1&#125; = [];</span><br><span class="line">        usr_data&#123;nUser, 2&#125; = [];</span><br><span class="line">        usr_data&#123;nUser, 3&#125; = [];</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>nRxAts x nTxAts x nPackets表示n个样本，按照batch_size从中取样，放到X和y中，用于后续train</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">data_X = f[ref_X][:]</span><br><span class="line">data_y = f[ref_y][:]</span><br><span class="line">nUsers = f[<span class="string">&#x27;usr_data&#x27;</span>].shape[1]</span><br><span class="line"><span class="comment"># (4, 10240, 30),</span></span><br><span class="line">nRxAts, inPreambLen, nPackets = data_X.shape</span><br><span class="line"><span class="comment"># (4, 32, 234, 30)，其中nRxAts表示接受端天线数量，nTxAts表示发送端天线数量</span></span><br><span class="line">nRxAts, nTxAts, nSubCarr, nPackets = data_y.shape</span><br><span class="line">P = f[<span class="string">&#x27;P&#x27;</span>][:]  <span class="comment"># retrieve pilot sequences matrix</span></span><br><span class="line"></span><br><span class="line">trainX_temp = np.zeros((nPackets*nTxAts*nRxAts, <span class="number">2</span>), dtype=int) # for every datapoint, this will contain every unique LTF relative [hash, iTx]</span><br><span class="line">trainy_real_temp = np.zeros((nPackets*nRxAts*nTxAts,nSubCarr))</span><br><span class="line">trainy_imag_temp = np.zeros((nPackets*nRxAts*nTxAts,nSubCarr))</span><br><span class="line"></span><br><span class="line"><span class="comment"># d是real和imag</span></span><br><span class="line"><span class="keyword">for</span> i, sampleIx <span class="keyword">in</span> enumerate(list_IDs_temp):</span><br><span class="line">    <span class="comment"># Store sample</span></span><br><span class="line">    Xsig[i] = self.dataset[<span class="string">&#x27;LTF&#x27;</span>][self.dataset[<span class="string">&#x27;X&#x27;</span>][sampleIx, 0]][self.d][</span><br><span class="line">                              0:int(self.prm[<span class="string">&#x27;lenLTF&#x27;</span>] / self.fraction)][:, np.newaxis]</span><br><span class="line">    Xp[i] = self.dataset[<span class="string">&#x27;P&#x27;</span>][:, self.dataset[<span class="string">&#x27;X&#x27;</span>][sampleIx, 1]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store class</span></span><br><span class="line">    y[i] = self.dataset[<span class="string">&#x27;y&#x27;</span>][self.d][sampleIx, :]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">earlystop = EarlyStopping(patience=10, restore_best_weights=True)</span><br><span class="line">reduce_lr = ReduceLROnPlateau(<span class="built_in">factor</span>=0.1, patience=20)</span><br><span class="line">callbacks = [earlystop, reduce_lr]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.method == <span class="string">&#x27;default_SNR&#x27;</span>:</span><br><span class="line">    applyGaussNoise = changeNoisePower(avg_sigPow, ...)</span><br><span class="line">    callbacks.append(applyGaussNoise)</span><br><span class="line"></span><br><span class="line">CSI_predictor.fit(</span><br><span class="line">    x=train_generator,</span><br><span class="line">    validation_data=valid_generator,</span><br><span class="line">    epochs=args.epochs,</span><br><span class="line">    callbacks=callbacks</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h4><h5 id="信道估计来源（estSource）"><a href="#信道估计来源（estSource）" class="headerlink" title="信道估计来源（estSource）"></a>信道估计来源（estSource）</h5><ul>
<li><code>estSource = 3</code>：使用 DNN 进行信道估计. </li>
<li><code>estSource = 4</code>：使用完美 CSI（理想信道）<br>来自低噪声情况下的信道估计</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">rxPreAmp_lowNoise = phased.ReceiverPreamp( ...</span><br><span class="line">            <span class="string">&#x27;Gain&#x27;</span>,gain_dB, ...    % account <span class="keyword">for</span> path loss</span><br><span class="line">            <span class="string">&#x27;NoiseMethod&#x27;</span>, <span class="string">&#x27;Noise power&#x27;</span>, ...</span><br><span class="line">            <span class="string">&#x27;NoisePower&#x27;</span>, db2pow(-100));        </span><br><span class="line">        </span><br><span class="line">rxPreSigAmp_real = rxPreAmp_lowNoise(rxPreSig&#123;uIdx&#125;); </span><br><span class="line">%   scale power <span class="keyword">for</span> used sub-carriers</span><br><span class="line">rxPreSigAmp_real = rxPreSigAmp_real * (sqrt(prm.FFTLength - ...</span><br><span class="line">    length(prm.NullCarrierIndices))/prm.FFTLength);</span><br><span class="line">        </span><br><span class="line">inputRXSig_real = rxPreSigAmp_real(chanDelay(uIdx)+1: ...</span><br><span class="line">                 end-(prm.numPadZeros-chanDelay(uIdx)),:);</span><br><span class="line">% OFDM demodulation</span><br><span class="line">rxOFDM_real = ofdmdemod(inputRXSig_real,prm.FFTLength, ...</span><br><span class="line">            prm.CyclicPrefixLength,prm.CyclicPrefixLength, ...</span><br><span class="line">            prm.NullCarrierIndices,prm.PilotCarrierIndices);</span><br><span class="line"></span><br><span class="line">% Channel estimation from preamble</span><br><span class="line">%       numCarr, numTx, numRx</span><br><span class="line">% Using classic (LS) method</span><br><span class="line">[hDp_real&#123;uIdx&#125;,~,~,~] = helperMIMOChannelEstimate(rxOFDM_real(:,1:numTx,:),prm,1,h,snr_dB_CS,<span class="literal">false</span>);     </span><br></pre></td></tr></table></figure>

<h5 id="NMSE计算"><a href="#NMSE计算" class="headerlink" title="NMSE计算"></a>NMSE计算</h5><p>使用 <code>NMSE_subk</code> 函数计算每个子载波、每对天线的归一化均方误差，并取平均：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> [out] = NMSE_subk(real, pred)</span><br><span class="line">    diff = real - pred;</span><br><span class="line">    tx = size(real,2);</span><br><span class="line">    rx = size(real,3);</span><br><span class="line">    subK_nmse = zeros(tx,rx);</span><br><span class="line">    <span class="keyword">for</span> t=1:tx</span><br><span class="line">        <span class="keyword">for</span> r=1:rx</span><br><span class="line">            subK_nmse(t,r) = norm(squeeze(diff(:,t,r)))^2 / norm(squeeze(real(:,t,r)))^2;</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    out = mean(subK_nmse, <span class="string">&#x27;all&#x27;</span>);</span><br><span class="line">end</span><br></pre></td></tr></table></figure>


<h5 id="BER-Bit-Error-Rate"><a href="#BER-Bit-Error-Rate" class="headerlink" title="BER(Bit Error Rate)"></a>BER(Bit Error Rate)</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> estSource=1:4   % 1 = LS est.; 2 = MMSE est.; 3 = DNN est.; 4 = perfect est.</span><br><span class="line">        <span class="keyword">if</span> estSource == 3</span><br><span class="line">            hDp&#123;1&#125; = hDpDNN&#123;1&#125;; % only substitute <span class="keyword">for</span> user ID=1</span><br><span class="line">        elseif estSource == 2</span><br><span class="line">            hDp = hDp_mmse;</span><br><span class="line">        elseif estSource == 4</span><br><span class="line">            hDp = hDp_real;</span><br><span class="line">        end</span><br><span class="line">        [Fbb,Frf] = omphybweights(hDp&#123;1&#125;, numSTS, numSTS, AtExp);</span><br><span class="line">        mFrf = permute(mean(Frf,1), [2 3 1]);</span><br><span class="line">        preData(carrIdx,symIdx,:) = squeeze(gridData(carrIdx,symIdx,:)).<span class="string">&#x27; * normQ;</span></span><br><span class="line"><span class="string">        txSig = txSigSTS * mFrf;</span></span><br><span class="line"><span class="string">        ...</span></span><br><span class="line"><span class="string">        % Compute and display bit error rate</span></span><br><span class="line"><span class="string">        ber = comm.ErrorRate;</span></span><br><span class="line"><span class="string">        measures = ber(txDataBits&#123;uIdx&#125;,rxBits);        </span></span><br></pre></td></tr></table></figure>
<h5 id="EVM-Error-Vector-Magnitude"><a href="#EVM-Error-Vector-Magnitude" class="headerlink" title="EVM(Error Vector Magnitude)"></a>EVM(Error Vector Magnitude)</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">evm = comm.EVM(<span class="string">&#x27;Normalization&#x27;</span>,<span class="string">&#x27;Average constellation power&#x27;</span>, ...</span><br><span class="line">                <span class="string">&#x27;ReferenceSignalSource&#x27;</span>,<span class="string">&#x27;Estimated from reference constellation&#x27;</span>, ...</span><br><span class="line">                <span class="string">&#x27;ReferenceConstellation&#x27;</span>, ...</span><br><span class="line">                qammod((<span class="number">0</span>:prm.modMode-<span class="number">1</span>)&#x27;,prm.modMode,&#x27;UnitAveragePower&#x27;,<span class="number">1</span>));</span><br><span class="line">rmsEVM = evm(rxSymbs);</span><br><span class="line">            </span><br></pre></td></tr></table></figure>
    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/04/28/C%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E6%B1%A0/" rel="prev" title="C语言实现线程池">
      <i class="fa fa-chevron-left"></i> C语言实现线程池
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/05/01/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/" rel="next" title="随机过程">
      随机过程 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-Concept"><span class="nav-number">1.</span> <span class="nav-text">Basic Concept</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC"><span class="nav-number">2.</span> <span class="nav-text">数学公式推导</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#OFDM-System-Simulation-with-LMMSE-Channel-Estimation"><span class="nav-number"></span> <span class="nav-text">OFDM System Simulation with LMMSE Channel Estimation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%F0%9F%93%8C-Features"><span class="nav-number">1.</span> <span class="nav-text">📌 Features</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%F0%9F%A7%A0-Theoretical-Background"><span class="nav-number">2.</span> <span class="nav-text">🧠 Theoretical Background</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-OFDM-Signal-Model"><span class="nav-number">2.1.</span> <span class="nav-text">1. OFDM Signal Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-LMMSE-Channel-Estimation"><span class="nav-number">2.2.</span> <span class="nav-text">2. LMMSE Channel Estimation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Channel-Frequency-Response-DFT"><span class="nav-number">2.3.</span> <span class="nav-text">3. Channel Frequency Response (DFT)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Calculation-of-R-hp-hp"><span class="nav-number">2.4.</span> <span class="nav-text">4. Calculation of $R_{hp,hp}$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Calculation-of-R-hd-hp"><span class="nav-number">2.5.</span> <span class="nav-text">5. Calculation of $R_{hd,hp}$</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%F0%9F%93%81-File-Structure"><span class="nav-number">3.</span> <span class="nav-text">📁 File Structure</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E2%9A%99%EF%B8%8F-Key-Parameters"><span class="nav-number">4.</span> <span class="nav-text">⚙️ Key Parameters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CSI-Acquisition-and-Precoding-Impact-on-BER"><span class="nav-number">5.</span> <span class="nav-text">CSI Acquisition and Precoding Impact on BER</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-Learning-for-CSI-Prediction"><span class="nav-number">5.1.</span> <span class="nav-text">Deep Learning for CSI Prediction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Objective"><span class="nav-number">5.1.1.</span> <span class="nav-text">Objective</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Model-Architecture-Keras"><span class="nav-number">5.1.2.</span> <span class="nav-text">Model Architecture (Keras)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loss"><span class="nav-number">5.1.3.</span> <span class="nav-text">Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">5.1.4.</span> <span class="nav-text">数据处理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90"><span class="nav-number">5.1.4.1.</span> <span class="nav-text">数据生成</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Training"><span class="nav-number">5.1.5.</span> <span class="nav-text">Training</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Evaluation-Metrics"><span class="nav-number">5.1.6.</span> <span class="nav-text">Evaluation Metrics</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BF%A1%E9%81%93%E4%BC%B0%E8%AE%A1%E6%9D%A5%E6%BA%90%EF%BC%88estSource%EF%BC%89"><span class="nav-number">5.1.6.1.</span> <span class="nav-text">信道估计来源（estSource）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NMSE%E8%AE%A1%E7%AE%97"><span class="nav-number">5.1.6.2.</span> <span class="nav-text">NMSE计算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#BER-Bit-Error-Rate"><span class="nav-number">5.1.6.3.</span> <span class="nav-text">BER(Bit Error Rate)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#EVM-Error-Vector-Magnitude"><span class="nav-number">5.1.6.4.</span> <span class="nav-text">EVM(Error Vector Magnitude)</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
