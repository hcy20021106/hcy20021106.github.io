<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hechenyi.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Basic ConceptLook for a function for e.g., image recognition, speech recognition.    RegressionThe function outputs a scalar ClassificationGiven options (classes), the function outputs the correct one">
<meta property="og:type" content="article">
<meta property="og:title" content="MachineLearning">
<meta property="og:url" content="https://hechenyi.github.io/2025/06/16/MachineLearning/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Basic ConceptLook for a function for e.g., image recognition, speech recognition.    RegressionThe function outputs a scalar ClassificationGiven options (classes), the function outputs the correct one">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://hechenyi.github.io/images/LSTM_Formulation.png">
<meta property="article:published_time" content="2025-06-16T15:42:25.000Z">
<meta property="article:modified_time" content="2025-10-14T15:16:52.404Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hechenyi.github.io/images/LSTM_Formulation.png">

<link rel="canonical" href="https://hechenyi.github.io/2025/06/16/MachineLearning/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>MachineLearning | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/06/16/MachineLearning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          MachineLearning
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-06-16 23:42:25" itemprop="dateCreated datePublished" datetime="2025-06-16T23:42:25+08:00">2025-06-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-14 23:16:52" itemprop="dateModified" datetime="2025-10-14T23:16:52+08:00">2025-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Basic-Concept"><a href="#Basic-Concept" class="headerlink" title="Basic Concept"></a>Basic Concept</h2><p>Look for a function for e.g., image recognition, speech recognition.  </p>
<ul>
<li>Regression<br>The function outputs a scalar</li>
<li>Classification<br>Given options (classes), the function outputs the correct one.</li>
<li>Structured Learning</li>
</ul>
<h3 id="Linear-Model"><a href="#Linear-Model" class="headerlink" title="Linear Model"></a>Linear Model</h3><h4 id="Define-function-with-unknown-parameters"><a href="#Define-function-with-unknown-parameters" class="headerlink" title="Define function with unknown parameters"></a>Define function with unknown parameters</h4><p>Model: $y &#x3D; b + w_1x_1$ based on domain knowledge<br>w (weight) and b (bias) are unknown parameters (learn from data)<br>å¦‚æœæ˜¯ä¸€ç»„åŒ…å«æœ‰å¤šä¸ªfeatureï¼ˆä¾‹å¦‚åŒæ—¶è€ƒè™‘å‰ä¸ƒå¤©çš„æ•°æ®æ¥è¿›è¡Œé¢„æµ‹ï¼‰<br>é‚£ä¹ˆ$y &#x3D; b + \sum_j w_jx_j$</p>
<h4 id="Define-Loss-from-Training-Data"><a href="#Define-Loss-from-Training-Data" class="headerlink" title="Define Loss from Training Data"></a>Define Loss from Training Data</h4><p>Loss is a function of the unknown parameters: L(b,w)<br>e.g., L(0.5k, 1) corresponding to $\hat{y} &#x3D; 0.5k + 1x_1$.<br>$\hat{y}$ is predicted value, y is ground truth (target)<br>æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªloss functionä¸º:<br>$e_n &#x3D; |y_n - \hat{y_n}|$  </p>
<p>Loss: $L(b, w) &#x3D; \frac{1}{N} \sum_{n&#x3D;1}^{N} \left| y_n - \hat{y}_n \right|$</p>
<p>å…¶ä¸­yä¸ºçœŸå®å€¼ï¼Œ$\hat{y}$ä¸ºé¢„æµ‹å€¼,è¿™é‡Œæˆ‘ä»¬å®šä¹‰çš„Lossæ˜¯mean absolute error ï¼ˆMAEï¼‰ï¼Œå¦‚æœæ˜¯mean square errorï¼ˆMSEï¼‰ï¼Œåˆ™æ˜¯å·®å€¼çš„çš„å¹³æ–¹ã€‚</p>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>é™¤äº†å¸¸è§çš„ MAEï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰å’Œ MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰ä¹‹å¤–ï¼ŒNMSEï¼ˆå½’ä¸€åŒ–å‡æ–¹è¯¯å·®ï¼‰ä¹Ÿæ˜¯ä¸€ç§å¸¸ç”¨çš„è¯„ä»·æŒ‡æ ‡ã€‚NMSE<br><br>æ˜¯å°†å‡æ–¹è¯¯å·®å½’ä¸€åŒ–åˆ°çœŸå®ä¿¡å·çš„èƒ½é‡ä¸Šï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š<br><br>$\text{NMSE} &#x3D; \frac{\sum ( \hat{y}_i - y_i )^2}{\sum y_i^2}$<br><br>å®ƒè¡¡é‡çš„æ˜¯é¢„æµ‹è¯¯å·®ç›¸å¯¹äºçœŸå®ä¿¡å·å¼ºåº¦çš„æ¯”ä¾‹ï¼Œé€‚åˆç”¨äºä¿¡å·å¤„ç†ã€é€šä¿¡ç­‰é¢†åŸŸï¼Œå¯ä»¥æ›´å…¬å¹³åœ°åæ˜ é¢„æµ‹æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¿¡å·å¹…åº¦å˜åŒ–è¾ƒå¤§æ—¶ã€‚<br></p>
</blockquote>
<hr>
<h4 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h4><p>æˆ‘ä»¬é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•° <em>L(b, w)</em> æ¥å­¦ä¹ æœªçŸ¥å‚æ•° b å’Œ wã€‚ä¼˜åŒ–ç›®æ ‡ä¸ºï¼š</p>
<p>$b^<em>, w^</em> &#x3D; \arg\min_{b, w} L(b, w)$</p>
<p>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•è¿›è¡Œä¼˜åŒ–ï¼Œå‚æ•°æ›´æ–°å¦‚ä¸‹ï¼š</p>
<p>$w \leftarrow w - \eta \frac{\partial L}{\partial w}, \quad<br>b \leftarrow b - \eta \frac{\partial L}{\partial b}$</p>
<p>å…¶ä¸­ $\eta$ ä¸ºå­¦ä¹ ç‡ã€‚å¯¹äº MAE æŸå¤±ï¼Œç”±äºå…¶ä¸å¯å¯¼ç‚¹è¾ƒå¤šï¼Œå¯ä»¥ä½¿ç”¨æ¬¡æ¢¯åº¦æ³•ï¼›å¯¹äº MSE æŸå¤±ï¼Œåˆ™å¯ä»¥ç›´æ¥ä½¿ç”¨æ ‡å‡†æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚</p>
<h3 id="Sophisticated-Models"><a href="#Sophisticated-Models" class="headerlink" title="Sophisticated Models"></a>Sophisticated Models</h3><p>Beacuse linear models have severe limitation (model bias), so we include more sophisticated models.</p>
<h4 id="Sigmoid-functionï¼ˆlogistic-regressionï¼‰"><a href="#Sigmoid-functionï¼ˆlogistic-regressionï¼‰" class="headerlink" title="Sigmoid functionï¼ˆlogistic regressionï¼‰"></a>Sigmoid functionï¼ˆlogistic regressionï¼‰</h4><p>$y &#x3D; b + wx_1 &#x3D;&gt; y &#x3D; b + \sum_i c_i \cdot \sigma(b_i + w_ix_1)$<br>æ³¨ï¼šä¸åŒçš„wï¼Œbï¼Œcå¯ä»¥è®©sigmoidæ›²çº¿å¯ä»¥æ‹Ÿåˆä¸åŒçš„æ›²çº¿ã€‚</p>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>è¾“å…¥å±‚: $x_j (j &#x3D; 1â€¦d)$<br><br>   â†“ <br><br>éšè—å±‚: $h_i &#x3D; \sigma(b_i + \sum w_ij x_j) (i &#x3D; 1â€¦N)$<br><br>   â†“ <br><br>è¾“å‡ºå±‚: $y &#x3D; b + \sum c_i h_i$ (æ ‡é‡è¾“å‡º)<br></p>
</blockquote>
<hr>
<p>å› æ­¤è¿™é‡Œè®¾è®¡åˆ°deep learningä¸­çš„<strong>hiden node</strong>çš„æ¦‚å¿µ(hiden nodeçš„æ•°é‡å¯ä»¥ç†è§£ä¸ºç”¨æ¥æ‹Ÿåˆçš„ReLUæ›²çº¿æ•°é‡)ï¼Œéšè—ç‚¹è¶Šå¤šï¼Œèƒ½å¤Ÿæ‹Ÿåˆå‡ºæ¥çš„functionè¶Šå‡†ç¡®ã€‚<br>æ³¨æ„è¿™é‡Œæ˜¯å¤šä¸ªsigmoidçš„å’Œï¼Œå› ä¸ºå®é™…æƒ…å†µå¯èƒ½æ˜¯ç”±å¤šä¸ªsigmoidæ‹Ÿåˆè€Œæˆã€‚<br>ç›¸å¯¹åº”çš„ï¼Œå¯¹äº$y &#x3D; b + \sum_j w_jx_j$, åˆ™æœ‰$y &#x3D; b + \sum_i c_i \cdot \sigma(b_i + \sum_j w_{ij} x_j)$  </p>
<p>ç¤ºä¾‹ï¼ši &#x3D; 1,2,3; j &#x3D; 1,2,3 æ—¶çš„æ˜¾å¼å½¢å¼<br>$$<br>r_1 &#x3D; b_1 + w_{11}x_1 + w_{12}x_2 + w_{13}x_3<br>$$</p>
<p>$$<br>r_2 &#x3D; b_2 + w_{21}x_1 + w_{22}x_2 + w_{23}x_3<br>$$</p>
<p>$$<br>r_3 &#x3D; b_3 + w_{31}x_1 + w_{32}x_2 + w_{33}x_3<br>$$</p>
<p>å‘é‡åŒ–ï¼ˆçŸ©é˜µï¼‰å½¢å¼<br>$$<br>\mathbf{r} &#x3D; W \mathbf{x} + \mathbf{b}<br>$$</p>
<p>ç„¶åå¯¹ç”Ÿæˆçš„råšsigmoidå‡½æ•°ï¼ŒçŸ©é˜µè¡¨è¾¾å½¢å¼å¦‚ä¸‹</p>
<p>$$<br>\mathbf{a} &#x3D; \sigma(\mathbf{r})<br>$$</p>
<p>æœ€åçš„è¾“å‡ºyçŸ©é˜µè¡¨è¾¾å½¢å¼å¦‚ä¸‹ï¼š<br>$$<br>y &#x3D; b + \mathbf{c}^T \mathbf{a}<br>$$</p>
<p>Optimizationéƒ¨åˆ†ï¼Œå…ˆå°†æ‰€æœ‰unknown parametersæ”¾åˆ°$\mathbf{\theta}$å‘é‡ä¸­<br>$$<br>\mathbf{\theta} &#x3D; \left[ b,\ c_1,\ \dots,\ c_i,\ b_1,\ \dots,\ b_i,\ w_{11},\ \dots,\ w_{ij} \right]<br>$$</p>
<p>å®šä¹‰Loss function $L(\theta)$,æœ€åæƒ³è¦å–å¾—çš„ $\mathbf{\theta^{*}} &#x3D; \arg\min_{\theta} L$  </p>
<p>å› æ­¤æˆ‘ä»¬åŒæ ·çš„ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°å»å¾—åˆ°æœ€åçš„$\mathbf{\theta^{*}}$<br>$$<br>\theta \leftarrow \theta - \eta \cdot \nabla_\theta L(\theta)<br>$$  </p>
<p><strong>Batch Size</strong>, <strong>Epoch</strong>, <strong>N</strong><br>1,000 examples (N &#x3D; 1,000), Batch size is 100, so 100 update in 1 epoch (10 Batch).</p>
<h3 id="Use-Quadratic-and-Higher-Order-Terms"><a href="#Use-Quadratic-and-Higher-Order-Terms" class="headerlink" title="Use Quadratic and Higher-Order Terms"></a>Use Quadratic and Higher-Order Terms</h3><p>To increase model expressiveness, you can replace the linear input with polynomial terms.</p>
<p>For example, a quadratic input:<br>$$<br>y &#x3D; b + w_1 \cdot x_1 + w_2 \cdot x_1^2 + w_3 \cdot x_1^3 + â€¦ + w_n \cdot x_1^n<br>$$</p>
<h4 id="Overfitting-Risk"><a href="#Overfitting-Risk" class="headerlink" title="Overfitting Risk"></a>Overfitting Risk</h4><ul>
<li>Adding higher-degree polynomials increases the parameter space.</li>
<li>The model can fit training data too well, including noise.</li>
<li>This leads to poor generalization on unseen data.</li>
</ul>
<h5 id="Rugularization-to-Prevent-Overfitting"><a href="#Rugularization-to-Prevent-Overfitting" class="headerlink" title="Rugularization to Prevent Overfitting"></a>Rugularization to Prevent Overfitting</h5><p>Add a penalty term to the loss function:</p>
<p>ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œé€šå¸¸åœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥æ­£åˆ™åŒ–é¡¹ï¼Œå¯¹æƒé‡è¿›è¡Œæƒ©ç½šã€‚<br>å¸¸è§çš„æœ‰ <strong>L2 æ­£åˆ™åŒ–ï¼ˆæƒé‡è¡°å‡ï¼‰</strong>ï¼š</p>
<p>$\text{Loss} &#x3D; \text{MSE} + \lambda \sum_{i} w_i^2$</p>
<ul>
<li>å…¶ä¸­ï¼Œ$\lambda$ æ˜¯æ­£åˆ™åŒ–ç³»æ•°ï¼ˆä¹Ÿå« <strong>weight decay</strong>ï¼‰ã€‚</li>
<li>é€šè¿‡é™åˆ¶æƒé‡ $w_i çš„å¤§å°ï¼Œå‡å°‘æ¨¡å‹å¯¹é«˜é˜¶é¡¹çš„è¿‡åº¦ä¾èµ–ï¼Œä»è€Œé™ä½è¿‡æ‹Ÿåˆé£é™©ã€‚</li>
</ul>
<h5 id="è®­ç»ƒæ—¶å¦‚ä½•åŠ ä¸Šæ­£åˆ™åŒ–ç›¸"><a href="#è®­ç»ƒæ—¶å¦‚ä½•åŠ ä¸Šæ­£åˆ™åŒ–ç›¸" class="headerlink" title="è®­ç»ƒæ—¶å¦‚ä½•åŠ ä¸Šæ­£åˆ™åŒ–ç›¸"></a>è®­ç»ƒæ—¶å¦‚ä½•åŠ ä¸Šæ­£åˆ™åŒ–ç›¸</h5><p>è®­ç»ƒæ¨¡å‹æ—¶ï¼Œéœ€è¦åœ¨å‚æ•°æ›´æ–°æ­¥éª¤ä¸­åŠ ä¸Šæ­£åˆ™åŒ–é¡¹ã€‚<br>ä»¥ <strong>L2 æ­£åˆ™åŒ–</strong> ä¸ºä¾‹ï¼Œæ¯æ¬¡å‚æ•°æ›´æ–°å…¬å¼ï¼š</p>
<p>$w :&#x3D; w - \eta (\nabla L + \lambda w)$</p>
<ul>
<li>$\eta$ï¼šå­¦ä¹ ç‡ï¼ˆlearning rateï¼‰</li>
<li>$\nabla L$ï¼šæŸå¤±å‡½æ•°å¯¹å‚æ•°çš„æ¢¯åº¦</li>
<li>$\lambda w$ï¼šæ­£åˆ™åŒ–é¡¹å¯¹å‚æ•°çš„æ¢¯åº¦ï¼ˆL2 æ­£åˆ™åŒ–ï¼‰</li>
</ul>
<h5 id="Dropout-Randomly-Dropping-Neurons"><a href="#Dropout-Randomly-Dropping-Neurons" class="headerlink" title="Dropout: Randomly Dropping Neurons"></a>Dropout: Randomly Dropping Neurons</h5><p>Dropout is a technique where randomly selected neurons are ignored during training.</p>
<ul>
<li>For each training iteration, with probability <code>p</code>, a neuronâ€™s output is set to 0.</li>
<li>At test time, all neurons are active, but their outputs are scaled by <code>p</code>.</li>
</ul>
<p><strong>Training Phase Formula:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hÌƒ = h * m</span><br></pre></td></tr></table></figure>

<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼šè¿™ä¸ªçŸ©é˜µä¹˜æ³•æ˜¯æŒ‰å…ƒç´ ä¸€ä¸€ç›¸ä¹˜ï¼ˆé€å…ƒç´ å±è”½ï¼‰ã€‚å¹¶ä¸”dropoutä¸ä¼šå‡å°‘ç¥ç»å…ƒæ•°é‡å’Œæ¨¡å‹å‚æ•°æ•°é‡ï¼Œåªæ˜¯ä½¿åœ¨è®­ç»ƒæ—¶éƒ¨åˆ†ç¥ç»å…ƒä¸´æ—¶å¤±æ´»ã€‚</p>
<ul>
<li><code>h</code> &#x3D; hidden activation vector  </li>
<li><code>m</code> &#x3D; Bernoulli mask vector (with probability <code>p</code>)</li>
</ul>
<p>âœ… <em>Benefits</em>:</p>
<ul>
<li>Reduces co-dependence between neurons  </li>
<li>Acts like an ensemble of multiple sub-models  </li>
<li>Improves robustness and generalization</li>
</ul>
<hr>
<p>âœ… ç›´è§‚ç†è§£</p>
<p>æ¯æ¬¡æ›´æ–°æ—¶ï¼ŒæŠŠæƒé‡å¾€ 0 å†æ‹‰ä¸€ç‚¹ï¼Œ<br>é˜²æ­¢å®ƒä»¬å˜å¾—å¤ªå¤§ï¼Œé¿å…æ¨¡å‹æ‹Ÿåˆå™ªå£°ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚</p>
<h3 id="PyTorch-CNN-äºŒåˆ†ç±»ç¤ºä¾‹"><a href="#PyTorch-CNN-äºŒåˆ†ç±»ç¤ºä¾‹" class="headerlink" title="PyTorch CNN äºŒåˆ†ç±»ç¤ºä¾‹"></a>PyTorch CNN äºŒåˆ†ç±»ç¤ºä¾‹</h3><h4 id="é¢„å¤„ç†transform"><a href="#é¢„å¤„ç†transform" class="headerlink" title="é¢„å¤„ç†transform"></a>é¢„å¤„ç†transform</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">256</span>, <span class="number">256</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h4 id="è‡ªå®šä¹‰Dataset"><a href="#è‡ªå®šä¹‰Dataset" class="headerlink" title="è‡ªå®šä¹‰Dataset"></a>è‡ªå®šä¹‰Dataset</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">class MyData(Dataset):</span><br><span class="line">    def __init__(self, root_dir, classes, transform=None):</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.classes = classes</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">        self.img_paths = []</span><br><span class="line">        self.labels = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, cls <span class="keyword">in</span> enumerate(classes):</span><br><span class="line">            cls_path = os.path.join(root_dir, cls)</span><br><span class="line">            <span class="keyword">for</span> img_name <span class="keyword">in</span> os.listdir(cls_path):</span><br><span class="line">                self.img_paths.append(os.path.join(cls_path, img_name))</span><br><span class="line">                self.labels.append(idx)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        img_path = self.img_paths[idx]</span><br><span class="line">        img = Image.open(img_path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        label = self.labels[idx]</span><br><span class="line">        <span class="built_in">return</span> img, label</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        <span class="built_in">return</span> len(self.img_paths)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="ç®€å•CNNæ¨¡å‹"><a href="#ç®€å•CNNæ¨¡å‹" class="headerlink" title="ç®€å•CNNæ¨¡å‹"></a>ç®€å•CNNæ¨¡å‹</h4><p>CNNé€šå¸¸ç”¨PyTorchçš„nn.Conv1då’Œnn.Conv2dæˆ–è€…keraså®ç°å·ç§¯æ“ä½œ</p>
<ul>
<li>Conv1d.<br>ä¸€ç»´å·ç§¯ï¼Œå¸¸ç”¨äºå¤„ç†æ—¶é—´åºåˆ—ï¼Œæ–‡æœ¬åºåˆ—ç­‰ã€‚åœ¨æ„å»ºæ—¶éœ€è¦è®¾å®šout_channels, kernel_size, stride, paddingç­‰å‚æ•°<br>è¾“å…¥å¼ é‡ç»´åº¦ä¸ºï¼ˆbatch_size, channels, lengthï¼‰</li>
<li>Conv2d.<br>äºŒç»´å·ç§¯ï¼Œå¸¸ç”¨äºå›¾åƒå¤„ç†ã€‚åœ¨æ„å»ºæ—¶åŒæ ·éœ€è¦è®¾å®šout_channels, kernel_size, stride, paddingç­‰å‚æ•°<br>è¾“å…¥å¼ é‡å½¢çŠ¶ä¸º(batch_size, channels, height, width),</li>
</ul>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>æ‰€ä»¥åœ¨model.summay()é‡Œï¼Œç¬¬ä¸€ä¸ªç»´åº¦æ˜¾ç¤ºä¸º<strong>None</strong>, è¿™å°±æ˜¯batch sizeå¯å˜çš„å ä½ç¬¦<br></p>
</blockquote>
<hr>
<h5 id="è¾“å…¥æ•°æ®æ ¼å¼"><a href="#è¾“å…¥æ•°æ®æ ¼å¼" class="headerlink" title="è¾“å…¥æ•°æ®æ ¼å¼"></a>è¾“å…¥æ•°æ®æ ¼å¼</h5><ul>
<li>è¾“å…¥å›¾åƒä¸ºå½©è‰²å›¾åƒï¼ˆRGBï¼‰ï¼Œå°ºå¯¸ç»Ÿä¸€ä¸º 256Ã—256 åƒç´ ã€‚</li>
<li>è¾“å…¥å¼ é‡å½¢çŠ¶ä¸º <code>[batch_size, 3, 256, 256]</code>ï¼Œå…¶ä¸­ <code>3</code> æ˜¯é€šé“æ•°ï¼ˆRGBï¼‰ï¼Œ<code>batch_size</code> æ˜¯æ‰¹é‡å¤§å°ã€‚</li>
</ul>
<h5 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h5><h5 id="å·ç§¯å±‚å’Œæ± åŒ–å±‚æµç¨‹"><a href="#å·ç§¯å±‚å’Œæ± åŒ–å±‚æµç¨‹" class="headerlink" title="å·ç§¯å±‚å’Œæ± åŒ–å±‚æµç¨‹"></a>å·ç§¯å±‚å’Œæ± åŒ–å±‚æµç¨‹</h5><hr>
<blockquote>
<p><strong>Notice</strong><br><br>æ± åŒ–å±‚ä½¿ç”¨çš„kernel_sizeé€šå¸¸ä¸strideæ­¥é•¿ç›¸ç­‰<br><br>æ± åŒ–å±‚çš„ç›®çš„æ˜¯å¯¹ç‰¹å¾å›¾è¿›è¡Œä¸‹é‡‡æ ·ï¼ˆå¦‚æœ€å¤§æ± åŒ–ã€å¹³å‡æ± åŒ–ï¼‰ï¼Œå‡å°ç‰¹å¾å›¾çš„å®½é«˜ï¼Œä»è€Œå‡å°åç»­å±‚çš„å‚æ•°é‡å’Œè®¡ç®—é‡<br><br>ä¿ç•™ä¸»è¦ä¿¡æ¯ï¼Œä¸¢å¼ƒä¸é‡è¦çš„ç»†èŠ‚<br><br>é€šè¿‡ä¿¡æ¯å‹ç¼©å’Œå‚æ•°å‡å°ï¼Œé™ä½æ¨¡å‹è¿‡æ‹Ÿåˆé£é™©<br></p>
</blockquote>
<hr>
<ul>
<li><p><strong>ç¬¬ä¸€å±‚å·ç§¯</strong>: <code>nn.Conv2d(3, 16, kernel_size=3, padding=1)</code></p>
<ul>
<li>è¾“å…¥é€šé“æ•°ï¼š3</li>
<li>è¾“å‡ºé€šé“æ•°ï¼š16</li>
<li>å·ç§¯æ ¸å¤§å°ï¼š3Ã—3</li>
<li>å¡«å……å¤§å°ï¼š1ï¼Œæ­¥é•¿é»˜è®¤1</li>
<li>è¾“å‡ºå°ºå¯¸è®¡ç®—å…¬å¼ï¼š<br>$$<br>\text{Output Size} &#x3D; \left\lfloor \frac{\text{Input Size} + 2 \times \text{padding} - \text{kernel size}}{\text{stride}} \right\rfloor + 1<br>ä»£å…¥å‚æ•°ï¼š<br>\frac{256 + 2 \times 1 - 3}{1} + 1 &#x3D; 256<br>$$</li>
<li>è¾“å‡ºå¼ é‡å½¢çŠ¶ï¼š<code>[batch_size, 16, 256, 256]</code></li>
</ul>
</li>
<li><p><strong>ReLUæ¿€æ´»</strong></p>
</li>
<li><p><strong>ç¬¬ä¸€æ¬¡æ± åŒ–</strong>: <code>nn.MaxPool2d(2)</code></p>
<ul>
<li>æ± åŒ–çª—å£å¤§å°ï¼š2Ã—2ï¼Œæ­¥é•¿2</li>
<li>å°ºå¯¸å‡åŠï¼Œè¾“å‡ºå½¢çŠ¶ä¸ºï¼š<code>[batch_size, 16, 128, 128]</code></li>
</ul>
</li>
<li><p><strong>ç¬¬äºŒå±‚å·ç§¯</strong>: <code>nn.Conv2d(16, 32, kernel_size=3, padding=1)</code></p>
<ul>
<li>è¾“å…¥é€šé“æ•°ï¼š16</li>
<li>è¾“å‡ºé€šé“æ•°ï¼š32</li>
<li>å·ç§¯æ ¸å¤§å°ï¼š3Ã—3ï¼Œå¡«å……1ï¼Œæ­¥é•¿1</li>
<li>è¾“å‡ºå°ºå¯¸åŒç†è®¡ç®—ä¸ºï¼š<code>128</code></li>
<li>è¾“å‡ºå¼ é‡å½¢çŠ¶ï¼š<code>[batch_size, 32, 128, 128]</code></li>
</ul>
</li>
<li><p><strong>ReLUæ¿€æ´»</strong></p>
</li>
<li><p><strong>ç¬¬äºŒæ¬¡æ± åŒ–</strong>: <code>nn.MaxPool2d(2)</code></p>
<ul>
<li>å°ºå¯¸å‡åŠï¼Œè¾“å‡ºå½¢çŠ¶ä¸ºï¼š<code>[batch_size, 32, 64, 64]</code></li>
</ul>
</li>
</ul>
<h5 id="å…¨è¿æ¥å±‚æµç¨‹ã€‚"><a href="#å…¨è¿æ¥å±‚æµç¨‹ã€‚" class="headerlink" title="å…¨è¿æ¥å±‚æµç¨‹ã€‚"></a>å…¨è¿æ¥å±‚æµç¨‹ã€‚</h5><hr>
<blockquote>
<p><strong>Notice</strong><br><br>ä¸­é—´å±‚æ¿€æ´»å‡½æ•°é€šå¸¸ç”¨ReLUï¼Œæœ€ååˆ†ç±»é€šå¸¸ä½¿ç”¨Sigmoidå‡½æ•°<br></p>
</blockquote>
<hr>
<ul>
<li><p><strong>å±•å¹³å±‚</strong>: å°†å·ç§¯å±‚è¾“å‡ºå±•å¹³æˆä¸€ç»´å‘é‡<br>Flattenæ˜¯å°†å·ç§¯å±‚ä¸­æå–åˆ°çš„ç©ºé—´ç‰¹å¾å±•å¼€ä¸ºä¸€ç»´å‘é‡ã€‚ç”¨äºåç»­å…¨è¿æ¥å±‚ã€‚</p>
<p>è¾“å…¥ç»´åº¦ä¸ºï¼š<br>$$<br>32 \times 64 \times 64 &#x3D; 131072<br>$$</p>
</li>
<li><p><strong>å…¨è¿æ¥å±‚1</strong>: <code>nn.Linear(131072, 64)</code>  </p>
</li>
<li><p><strong>ReLUæ¿€æ´»</strong></p>
</li>
<li><p><strong>å…¨è¿æ¥å±‚2</strong>: <code>nn.Linear(64, 1)</code></p>
</li>
<li><p><strong>Sigmoidæ¿€æ´»</strong>: è¾“å‡ºæ¦‚ç‡å€¼ï¼ŒèŒƒå›´åœ¨[0,1]ä¹‹é—´</p>
</li>
<li><p><strong>è¾“å‡º</strong>: ä½¿ç”¨ <code>.squeeze(1)</code> å°†è¾“å‡ºç»´åº¦ä» <code>[batch_size, 1]</code> è½¬æ¢ä¸º <code>[batch_size]</code>ï¼Œä¾¿äºè®¡ç®—æŸå¤±å‡½æ•°ã€‚</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">class SimpleCNN(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(3,16,3,padding = 1);</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Conv2d(16,32,3,padding = 1);</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(32 * 64 * 64, 64),  <span class="comment"># 256-&gt;128-&gt;64ï¼Œå®½é«˜å‡åŠä¸¤æ¬¡</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(64, 1),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        def forward(self, x):</span><br><span class="line">            x = self.conv(x)</span><br><span class="line">            x = self.fc(x)</span><br><span class="line">            <span class="built_in">return</span> x.squeeze(1)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="å‡†å¤‡æ•°æ®å’Œæ¨¡å‹"><a href="#å‡†å¤‡æ•°æ®å’Œæ¨¡å‹" class="headerlink" title="å‡†å¤‡æ•°æ®å’Œæ¨¡å‹"></a>å‡†å¤‡æ•°æ®å’Œæ¨¡å‹</h4><h5 id="train-validate-testæ•°æ®é›†çš„åŒºåˆ«"><a href="#train-validate-testæ•°æ®é›†çš„åŒºåˆ«" class="headerlink" title="train,validate,testæ•°æ®é›†çš„åŒºåˆ«"></a>train,validate,testæ•°æ®é›†çš„åŒºåˆ«</h5><table>
<thead>
<tr>
<th>é›†åˆ</th>
<th>ä½œç”¨</th>
<th>ä½¿ç”¨é˜¶æ®µ</th>
<th>å¤‡æ³¨</th>
</tr>
</thead>
<tbody><tr>
<td>è®­ç»ƒé›† (Train)</td>
<td>ç”¨äºæ¨¡å‹è®­ç»ƒï¼Œæ›´æ–°æ¨¡å‹å‚æ•°</td>
<td>è®­ç»ƒé˜¶æ®µ</td>
<td>å æ¯”æœ€å¤§ï¼Œæ•°æ®å¤šæ ·æ€§ä¸°å¯Œ</td>
</tr>
<tr>
<td>éªŒè¯é›† (Validation)</td>
<td>ç”¨äºè°ƒå‚å’Œæ¨¡å‹é€‰æ‹©ï¼Œç›‘æ§è¿‡æ‹Ÿåˆæƒ…å†µ</td>
<td>è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯„ä¼°é˜¶æ®µ</td>
<td>ä¸å‚ä¸è®­ç»ƒï¼Œç”¨äºè°ƒèŠ‚è¶…å‚æ•°å’Œæ¨¡å‹ç»“æ„</td>
</tr>
<tr>
<td>æµ‹è¯•é›† (Test)</td>
<td>ç”¨äºè¯„ä¼°æœ€ç»ˆæ¨¡å‹æ€§èƒ½</td>
<td>è®­ç»ƒå®Œæˆåçš„æ€§èƒ½è¯„ä¼°</td>
<td>å®Œå…¨ç‹¬ç«‹ï¼Œä¸å‚ä¸è®­ç»ƒå’Œè°ƒå‚</td>
</tr>
</tbody></table>
<h5 id="train-validate-testæ•°æ®é›†çš„åˆ’åˆ†"><a href="#train-validate-testæ•°æ®é›†çš„åˆ’åˆ†" class="headerlink" title="train,validate,testæ•°æ®é›†çš„åˆ’åˆ†"></a>train,validate,testæ•°æ®é›†çš„åˆ’åˆ†</h5><ul>
<li><p>åˆ›å»ºå®Œæ•´æ•°æ®é›†<br>dataset &#x3D; MyData(root_dir, classes, transform&#x3D;transform)</p>
</li>
<li><p>æŒ‰æ¯”ä¾‹åˆ’åˆ†è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•é›† 70%, 15%, 15%<br>total_size &#x3D; len(dataset)<br>train_size &#x3D; int(0.7 * total_size)<br>val_size &#x3D; int(0.15 * total_size)<br>test_size &#x3D; total_size - train_size - val_size</p>
</li>
</ul>
<p>train_dataset, val_dataset, test_dataset &#x3D; random_split(dataset, [train_size, val_size, test_size])</p>
<ul>
<li>åˆ›å»ºDataLoader<br>train_loader &#x3D; DataLoader(train_dataset, batch_size&#x3D;64, shuffle&#x3D;True)<br>val_loader &#x3D; DataLoader(val_dataset, batch_size&#x3D;64, shuffle&#x3D;False)<br>test_loader &#x3D; DataLoader(test_dataset, batch_size&#x3D;64, shuffle&#x3D;False)</li>
</ul>
<h4 id="è®­ç»ƒå¾ªç¯"><a href="#è®­ç»ƒå¾ªç¯" class="headerlink" title="è®­ç»ƒå¾ªç¯"></a>è®­ç»ƒå¾ªç¯</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = 10</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">    model.train()</span><br><span class="line">    running_loss = 0.0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> dataloader:</span><br><span class="line">        x, y = x.to(device), y.float().to(device)</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        pred = model(x)</span><br><span class="line">        loss = criterion(pred, y)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item() * x.size(0)</span><br><span class="line"></span><br><span class="line">    epoch_loss = running_loss / len(dataset)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;Epoch &#123;epoch+1&#125;/&#123;n_epochs&#125; - Loss: &#123;epoch_loss:.4f&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;è®­ç»ƒå®Œæˆï¼&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="CNN-ResNet-Residual-Network"><a href="#CNN-ResNet-Residual-Network" class="headerlink" title="CNN + ResNet (Residual Network)"></a>CNN + ResNet (Residual Network)</h3><p>æ®‹å·®ç»“æ„:<br>$y &#x3D; F(x) + x$<br>è§£å†³äº†æ·±å±‚ç½‘ç»œæ¢¯åº¦æ¶ˆå¤±ã€é€€åŒ–é—®é¢˜<br>RestNetè¿˜ä¼šåº”ç”¨åœ¨Attention&#x2F;Transformerä¸­ï¼Œä¾‹å¦‚åœ¨Transformerä¸­å¤§é‡ä½¿ç”¨äº†æ®‹å·®è¿æ¥+LayerNormï¼Œåœ¨Attentionä¸­ï¼Œæ¯ä¸ªSelf-Attentionå±‚ã€Feed Forwardå±‚å¤–é¢éƒ½æœ‰ä¸€ä¸ªæ®‹å·®ã€‚æ²¡æœ‰æ®‹å·®ï¼ŒTransformerå°±å¾ˆéš¾è®­ç»ƒæ·±å±‚ç»“æ„ã€‚</p>
<h4 id="ç¤ºä¾‹"><a href="#ç¤ºä¾‹" class="headerlink" title="ç¤ºä¾‹"></a>ç¤ºä¾‹</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import functional as F</span><br><span class="line">from d2l import torch as d2l</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">class Residual(nn.Module):  </span><br><span class="line">    def __init__(self, input_channels, num_channels,</span><br><span class="line">                 use_1x1conv=False, strides=1):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                               kernel_size=3, padding=1, stride=strides)</span><br><span class="line">        self.conv2 = nn.Conv2d(num_channels, num_channels,</span><br><span class="line">                               kernel_size=3, padding=1)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                                   kernel_size=1, stride=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = None</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(num_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(num_channels)</span><br><span class="line"> </span><br><span class="line">    def forward(self, X):</span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        Y += X</span><br><span class="line">        <span class="built_in">return</span> F.relu(Y)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>è¿™æ®µä»£ç å®ç°äº†RestNetçš„æ®‹å·®å—:</p>
<ul>
<li>ä¸¤ä¸ª3x3å·ç§¯+BN</li>
<li>å¯é€‰1x1å·ç§¯æ¥åŒ¹é…é€šé“æˆ–å¤§å°</li>
<li>æ®‹å·®è¿æ¥Y + X</li>
<li>æœ€åç»è¿‡ReLU</li>
</ul>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>1x1çš„å·ç§¯å±‚é€šå¸¸ç”¨æ¥è°ƒæ•´è¾“å‡ºçš„é€šé“ç»´åº¦ï¼Œå› ä¸º1x1å·ç§¯ä¸ä¼šå±€éƒ¨ç©ºé—´ç‰¹å¾ã€‚<br></p>
</blockquote>
<hr>
<h3 id="è†¨èƒ€å·ç§¯ï¼ˆDilated-Convolutionï¼‰"><a href="#è†¨èƒ€å·ç§¯ï¼ˆDilated-Convolutionï¼‰" class="headerlink" title="è†¨èƒ€å·ç§¯ï¼ˆDilated Convolutionï¼‰"></a>è†¨èƒ€å·ç§¯ï¼ˆDilated Convolutionï¼‰</h3><p>æ—¢å¯ä»¥å¢å¤§æ„Ÿå—é‡ï¼Œåˆèƒ½ä¿æŒè¾“å…¥ç‰¹å¾å›¾çš„Wå’ŒHä¸å˜ï¼ˆé€šè¿‡paddingå’Œstrideé…åˆï¼Œä¿è¯è¾“å…¥ç‰¹å¾å›¾çš„å°ºå¯¸ï¼‰<br>åŸå› ï¼š<br>åœ¨åŸCNNç½‘ç»œä¸­ï¼Œä½¿ç”¨Maxpoolingå±‚å°±æ˜¯é€šè¿‡æ± åŒ–æ“ä½œä½¿å¾—åç»­çš„å·ç§¯å±‚è·å¾—æ›´å¤§çš„æ„Ÿå—é‡ï¼Œä½†æ˜¯è¿™æ ·ä¼šå¸¦æ¥ä¸¤ä¸ªé—®é¢˜ï¼š</p>
<ul>
<li>æ± åŒ–æ“ä½œä¼šä¸¢å¤±ä¸€äº›å¾®å°ä¿¡æ¯</li>
<li>æ± åŒ–æ“ä½œä¼šä½¿å¾—ä¸‹é‡‡æ ·å€ç‡è¿›ä¸€æ­¥å˜å¤§</li>
</ul>
<h4 id="å…¬å¼"><a href="#å…¬å¼" class="headerlink" title="å…¬å¼"></a>å…¬å¼</h4><p>$y[i] &#x3D; \sum_{k&#x3D;0}^{K-1} w[k] * x[i + r * k] + b$. </p>
<ul>
<li>r æ˜¯ dilation rateï¼ˆè†¨èƒ€ç‡ï¼‰</li>
<li>å½“ r &#x3D; 1æ—¶ï¼Œé€€åŒ–ä¸ºæ™®é€šå·ç§¯</li>
<li>å½“ r &gt; 1æ—¶ï¼Œç›¸å½“äºåœ¨è¾“å…¥ä¸Šè·³æ­¥é‡‡æ ·ï¼Œæ‰©å¤§æ„Ÿå—é‡</li>
</ul>
<h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><p>åœ¨åˆ†ç±»ä¸­ï¼Œéœ€è¦è®²çº¿æ€§è¾“å‡ºæ˜ å°„åˆ°æ¦‚ç‡</p>
<h4 id="Sigmoidï¼ˆäºŒåˆ†ç±»ï¼‰"><a href="#Sigmoidï¼ˆäºŒåˆ†ç±»ï¼‰" class="headerlink" title="Sigmoidï¼ˆäºŒåˆ†ç±»ï¼‰"></a>Sigmoidï¼ˆäºŒåˆ†ç±»ï¼‰</h4><p>æ¨¡å‹ï¼š<br>$p &#x3D; \sigma(z) &#x3D; \frac{1}{1 + e^{-z}},\quad z &#x3D; b + \sum_j w_j x_j$.<br>é¢„æµ‹ç±»åˆ«ï¼š<br>$\hat{y} &#x3D;\begin{cases} 1 &amp; \text{if } p &gt; 0.5 \ 0 &amp; \text{otherwise} \end{cases}$.<br>Binary Cross-Entropy Loss (BCL):<br>$L(b, w) &#x3D; -\frac{1}{N} \sum_{n&#x3D;1}^{N} [, y_n \log p_n + (1 - y_n) \log (1 - p_n)$</p>
<h4 id="Softmaxï¼ˆå¤šåˆ†ç±»ï¼‰"><a href="#Softmaxï¼ˆå¤šåˆ†ç±»ï¼‰" class="headerlink" title="Softmaxï¼ˆå¤šåˆ†ç±»ï¼‰"></a>Softmaxï¼ˆå¤šåˆ†ç±»ï¼‰</h4><p>å¯¹äº$K$ä¸ªç±»åˆ«<br>$p_k &#x3D; \frac{e^{z_k}}{\sum_{j&#x3D;1}^{K} e^{z_j}},\quad z_k &#x3D; b_k + \sum_j w_{kj} x_j \quad k&#x3D;1 \dots,K$.<br>Multiclass Cross-Entropy Loss:<br>$L(b, w) &#x3D; -\frac{1}{N} \sum_{n&#x3D;1}^{N} \sum_{k&#x3D;1}^{K} y_{nk} \log p_{nk}$ã€‚<br>å…¶ä¸­ï¼š<br>$y_{nk} &#x3D; 1$ if sample $n$ is of class $k$, otherwise $0$.<br>å› æ­¤è¿™é‡Œç”¨äº†one-hotç¼–ç ï¼Œå› ä¸ºåªè€ƒè™‘äº†åªæœ‰çœŸå®ç±»åˆ«å¯¹åº”çš„$y_{nk} &#x3D; 1$,å…¶ä½™ä¸º0ï¼Œ$p_{nk}$æ˜¯Softmaxåé¢„æµ‹å±äºç±»åˆ«kçš„æ¦‚ç‡</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><h4 id="Linear-Regression-vs-Sigmoid-Regression"><a href="#Linear-Regression-vs-Sigmoid-Regression" class="headerlink" title="Linear Regression vs Sigmoid Regression"></a>Linear Regression vs Sigmoid Regression</h4><table>
<thead>
<tr>
<th>Task</th>
<th>Output Function</th>
<th>Activation</th>
<th>Loss Function</th>
</tr>
</thead>
<tbody><tr>
<td>Regression</td>
<td>$y$</td>
<td>Linear</td>
<td>MAE &#x2F; MSE</td>
</tr>
<tr>
<td>Binary Classification</td>
<td>$p$</td>
<td>Sigmoid</td>
<td>Binary Cross-Entropy (BCE)</td>
</tr>
<tr>
<td>Multiclass Classification</td>
<td>$p_k$</td>
<td>Softmax</td>
<td>Multiclass Cross-Entropy</td>
</tr>
</tbody></table>
<h4 id="MSE-vs-Binary-Cross-Entropy"><a href="#MSE-vs-Binary-Cross-Entropy" class="headerlink" title="MSE vs Binary Cross-Entropy"></a>MSE vs Binary Cross-Entropy</h4><table>
<thead>
<tr>
<th></th>
<th>Linear Regression</th>
<th>Logistic Regression</th>
</tr>
</thead>
<tbody><tr>
<td>ğŸ¯ ä»»åŠ¡</td>
<td>é¢„æµ‹è¿ç»­å€¼ï¼ˆå›å½’ï¼‰</td>
<td>é¢„æµ‹äºŒåˆ†ç±»ï¼ˆåˆ†ç±»ï¼‰</td>
</tr>
<tr>
<td>ğŸ“ˆ æ¨¡å‹</td>
<td>$y_hat &#x3D; b + Î£ w_j * x_j$</td>
<td>$p &#x3D; Ïƒ(z) &#x3D; 1&#x2F;(1+exp(-z)), z &#x3D; b + Î£ w_j * x_j$</td>
</tr>
<tr>
<td>ğŸ“Š è¾“å‡º</td>
<td>å®æ•° (-âˆ, +âˆ)</td>
<td>æ¦‚ç‡ [0, 1]</td>
</tr>
<tr>
<td>ğŸ“š åˆ†å¸ƒ</td>
<td>å‡è®¾è¾“å‡ºæœä»é«˜æ–¯åˆ†å¸ƒ</td>
<td>å‡è®¾è¾“å‡ºæœä»ä¼¯åŠªåˆ©åˆ†å¸ƒ</td>
</tr>
<tr>
<td>ğŸ”— æŸå¤±</td>
<td>å‡æ–¹è¯¯å·® (MSE: Mean Squared Error)</td>
<td>äºŒå…ƒäº¤å‰ç†µ (BCE: Binary Cross-Entropy)</td>
</tr>
<tr>
<td>âš¡ ç›®æ ‡</td>
<td>æœ€å¤§åŒ–é«˜æ–¯ä¼¼ç„¶</td>
<td>æœ€å¤§åŒ–ä¼¯åŠªåˆ©ä¼¼ç„¶</td>
</tr>
<tr>
<td>âš™ï¸ æ¢¯åº¦</td>
<td>æ¢¯åº¦çº¿æ€§ï¼Œæ›´æ–°ç›¸å¯¹å¹³æ»‘</td>
<td>æ¢¯åº¦åœ¨éé¥±å’ŒåŒºé—´è¾ƒå¤§ï¼Œä¸‹é™å¿«ï¼Œä½†æ¥è¿‘ 0&#x2F;1 æ—¶å¯èƒ½é¥±å’Œ</td>
</tr>
<tr>
<td>æ€»ä½“æ¥è¯´ï¼ŒCross-Entropyæ•ˆæœæ›´å¥½ä¸€ç‚¹</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="Support-Vector-Machine"><a href="#Support-Vector-Machine" class="headerlink" title="Support Vector Machine"></a>Support Vector Machine</h3><p><strong>Support Vector Machine(SVM)</strong> æ˜¯ä¸€ç§å¸¸è§çš„ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œå¸¸ç”¨äºäºŒåˆ†ç±»ä»»åŠ¡ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¯»æ‰¾ä¸€ä¸ªæœ€ä¼˜çš„åˆ†å‰²è¶…å¹³é¢ï¼Œä½¿å¾—ä¸åŒç±»åˆ«ä¹‹é—´çš„é—´éš”ï¼ˆmarginï¼‰æœ€å¤§åŒ–ã€‚</p>
<h4 id="Linear-Model-1"><a href="#Linear-Model-1" class="headerlink" title="Linear Model"></a>Linear Model</h4><p>å¯¹äºçº¿æ€§å¯åˆ†æ•°æ®ï¼ŒSVMå®šä¹‰ä¸€ä¸ªçº¿æ€§å†³ç­–å‡½æ•°ï¼š<br>$$<br>f(x) &#x3D; w^T x + b<br>$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$w$ æ˜¯æƒé‡å‘é‡ï¼Œ</li>
<li>$b$ æ˜¯åç½®é¡¹ã€‚</li>
</ul>
<p>åˆ†ç±»è§„åˆ™ï¼š</p>
<p>$$<br>\hat{y} &#x3D; \text{sign}(f(x)) &#x3D;<br>\begin{cases}<br>+1 &amp; \text{if } f(x) \ge 0 \\<br>-1 &amp; \text{if } f(x) &lt; 0<br>\end{cases}<br>$$</p>
<h4 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h4><p>SVM å¸¸ç”¨ <strong>åˆé¡µæŸå¤±ï¼ˆHinge Lossï¼‰</strong>ï¼š</p>
<p>$$<br>L_n &#x3D; \max(0,, 1 - y_n f(x_n))<br>$$</p>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>å¦‚æœ$y_nf(x_n)&gt;0$åˆ™è¯´æ˜åˆ†ç±»æ­£ç¡®<br><br>ä½†æ˜¯,$y_nf(x_n)&gt;&#x3D;1$æ‰å®Œç¾ï¼Œå› ä¸ºSVMä¸ä»…è¦æ±‚åˆ†ç±»æ­£ç¡®ï¼Œè¿˜è¦æœ€å¤§åŒ–é—´éš”ï¼Œä¹Ÿå°±æ˜¯å®‰å…¨é—´éš”ï¼Œæ‰€ä»¥åœ¨åˆé¡µæŸå¤±ä¸­æœ‰1<br></p>
</blockquote>
<hr>
<p>æ•´ä½“ç›®æ ‡å‡½æ•°ï¼š</p>
<h2 id="L-w-b-frac-1-2-w-2-C-sum-n-1-N-max-0-1-y-n-w-T-x-n-b"><a href="#L-w-b-frac-1-2-w-2-C-sum-n-1-N-max-0-1-y-n-w-T-x-n-b" class="headerlink" title="$$L(w,b) &#x3D; \frac{1}{2} |w|^2 + C \sum_{n&#x3D;1}^N \max(0,, 1 - y_n (w^T x_n + b)).$$"></a>$$<br>L(w,b) &#x3D; \frac{1}{2} |w|^2 + C \sum_{n&#x3D;1}^N \max(0,, 1 - y_n (w^T x_n + b)).<br>$$</h2><blockquote>
<p><strong>Notice</strong><br><br>$\frac{1}{2}|w|^2$æ˜¯æ­£åˆ™åŒ–é¡¹ï¼Œç”¨äºæ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæƒé‡ä¸è¦å¤ªå¤§ã€‚<br><br>$C \sum_{n&#x3D;1}^N \max(0,, 1 - y_n (w^T x_n + b))$æ˜¯æ‰€æœ‰æ ·æœ¬çš„åˆé¡µæŸå¤±çš„åŠ æƒå’Œã€‚<br></p>
</blockquote>
<hr>
<h4 id="Optimization-Gradient-Descent"><a href="#Optimization-Gradient-Descent" class="headerlink" title="Optimization (Gradient Descent)"></a>Optimization (Gradient Descent)</h4><p>åˆé¡µæŸå¤±å¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™æˆ–éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ä¼˜åŒ–ï¼š</p>
<p>$$<br>w \leftarrow w - \eta (w - C \sum_{n \in M} y_n x_n),<br>\quad<br>M &#x3D; { n ,|, 1 - y_n f(x_n) &gt; 0 }<br>$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$\eta$ æ˜¯å­¦ä¹ ç‡ï¼Œ</li>
<li>$M$ æ˜¯å½“å‰è¿å margin æ¡ä»¶çš„æ ·æœ¬é›†åˆã€‚</li>
</ul>
<h3 id="æœ´ç´ è´å¶æ–¯ï¼ˆNaive-Bayesï¼‰"><a href="#æœ´ç´ è´å¶æ–¯ï¼ˆNaive-Bayesï¼‰" class="headerlink" title="æœ´ç´ è´å¶æ–¯ï¼ˆNaive Bayesï¼‰"></a>æœ´ç´ è´å¶æ–¯ï¼ˆNaive Bayesï¼‰</h3><p>åˆ©ç”¨è´å¶æ–¯å…¬å¼æ ¹æ®æŸç‰¹å¾çš„å…ˆéªŒæ¦‚ç‡è®¡ç®—å‡ºå…¶åéªŒæ¦‚ç‡ï¼Œç„¶åé€‰æ‹©å…·æœ‰æœ€å¤§åéªŒæ¦‚ç‡çš„ç±»ä½œä¸ºè¯¥ç‰¹å¾æ‰€å±çš„ç±»</p>
<h4 id="æ¡ä»¶æ¦‚ç‡ã€‚"><a href="#æ¡ä»¶æ¦‚ç‡ã€‚" class="headerlink" title="æ¡ä»¶æ¦‚ç‡ã€‚"></a>æ¡ä»¶æ¦‚ç‡ã€‚</h4><p>å°±æ˜¯åœ¨äº‹ä»¶Bå‘ç”Ÿçš„æƒ…å†µä¸‹ï¼Œäº‹ä»¶Aå‘ç”Ÿçš„æ¦‚ç‡ï¼Œç”¨P(A|B)æ¥è¡¨ç¤º<br>$P(A|B) &#x3D; \frac{P(B|A)P(A)}{P(B)}$</p>
<h4 id="å…¨æ¦‚ç‡"><a href="#å…¨æ¦‚ç‡" class="headerlink" title="å…¨æ¦‚ç‡"></a>å…¨æ¦‚ç‡</h4><p>å¦‚æœäº‹ä»¶A1,A2,â€¦,Anæ„æˆä¸€ä¸ªå®Œå¤‡äº‹ä»¶éƒ½æœ‰æ­£æ¦‚ç‡ï¼Œé‚£ä¹ˆå¯¹äºä»»æ„ä¸€ä¸ªäº‹ä»¶Båˆ™æœ‰ï¼š<br>$P(B)&#x3D;\sum_{i&#x3D;1}^{n}P(A_i)P(B|A_i)$</p>
<h4 id="è´å¶æ–¯æ¨æ–­"><a href="#è´å¶æ–¯æ¨æ–­" class="headerlink" title="è´å¶æ–¯æ¨æ–­"></a>è´å¶æ–¯æ¨æ–­</h4><p>$P(A|B) &#x3D; \frac{P(B|A)P(A)}{P(B)}$ </p>
<p>$P(A_i|B) &#x3D; P(A_i)\frac{P(B|A_i)}{\sum_{i&#x3D;1}^{n}P(A_i)P(B|A_i)}$<br>å…¶ä¸­P(A)ä¸ºå…ˆéªŒæ¦‚ç‡ï¼Œ$P(A|B)$ä¸ºåéªŒæ¦‚ç‡ï¼Œ$\frac{P(B|A)}{P(B)}$ä¸ºå¯èƒ½æ€§å‡½æ•°ï¼ˆLikely hoodï¼‰<br>è½¬æ¢æˆåˆ†ç±»ä»»åŠ¡çš„è¡¨è¾¾å¼ï¼š<br>$P(ç±»åˆ«|ç‰¹å¾) &#x3D; P(ç±»åˆ«)\frac{P(ç‰¹å¾|ç±»åˆ«)}{P(ç‰¹å¾)}$ã€‚</p>
<h4 id="ä¸¾ä¾‹è¯´æ˜"><a href="#ä¸¾ä¾‹è¯´æ˜" class="headerlink" title="ä¸¾ä¾‹è¯´æ˜"></a>ä¸¾ä¾‹è¯´æ˜</h4><p>$P(å¸… æ€§æ ¼ä¸å¥½ ä¸ä¸Šè¿›) &#x3D; P(å«)P(å¸…|å«)P(æ€§æ ¼ä¸å¥½|å«)P(ä¸ä¸Šè¿›ï½œå«) +  P(ä¸å«)P(å¸…|ä¸å«)P(æ€§æ ¼ä¸å¥½|ä¸å«)P(ä¸ä¸Šè¿›ï½œä¸å«) &#x3D; 2&#x2F;125 + 3&#x2F;125$  </p>
<p>æœ€ç»ˆè®¡ç®—ç»“æœï¼š<br>P(å«|å¸… æ€§æ ¼ä¸å¥½ ä¸ä¸Šè¿›) &#x3D; P(å«)P(å¸…|å«)P(æ€§æ ¼ä¸å¥½|å«)P(ä¸ä¸Šè¿›ï½œå«) &#x2F; P(å¸… æ€§æ ¼ä¸å¥½ ä¸ä¸Šè¿›) &#x3D; (2&#x2F;125) &#x2F; (2&#x2F;125 + 3&#x2F;125) &#x3D; 0.4.<br>P(å«|å¸… æ€§æ ¼ä¸å¥½ ä¸ä¸Šè¿›) &#x3D; (3&#x2F;125) &#x2F; (2&#x2F;125 + 3&#x2F;125) &#x3D; 0.6. </p>
<h4 id="æœ€å¤§ä¼¼ç„¶ä¼°è®¡"><a href="#æœ€å¤§ä¼¼ç„¶ä¼°è®¡" class="headerlink" title="æœ€å¤§ä¼¼ç„¶ä¼°è®¡"></a>æœ€å¤§ä¼¼ç„¶ä¼°è®¡</h4><h4 id="æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰åŠ-GaussianNB-ç¤ºä¾‹"><a href="#æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰åŠ-GaussianNB-ç¤ºä¾‹" class="headerlink" title="æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰åŠ GaussianNB ç¤ºä¾‹"></a>æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰åŠ GaussianNB ç¤ºä¾‹</h4><hr>
<p>è§‚æµ‹æ•°æ®ï¼š<br>$$<br>X &#x3D; {x_1, x_2, \ldots, x_n}<br>$$</p>
<p>å‚æ•°ï¼š<br>$$<br>\theta<br>$$</p>
<p>é‚£ä¹ˆæ•°æ®çš„ä¼¼ç„¶å‡½æ•°æ˜¯ï¼š<br>$$<br>L(\theta; X) &#x3D; P(X \mid \theta)<br>$$</p>
<p>æœ€å¤§ä¼¼ç„¶ä¼°è®¡å°±æ˜¯ï¼š<br>$$<br>\hat{\theta}<em>{MLE} &#x3D; \arg\max</em>{\theta} L(\theta; X)<br>$$</p>
<hr>
<p>ğŸ”¬ <strong>ç”¨åœ¨ GaussianNB çš„ä¾‹å­</strong>  </p>
<p>åœ¨é«˜æ–¯æœ´ç´ è´å¶æ–¯ä¸­ï¼Œå‡è®¾æ¯ä¸ªç‰¹å¾<br>$$<br>X_j<br>$$<br>åœ¨ç±»åˆ«<br>$$<br>C_k<br>$$<br>ä¸‹æœä»æ­£æ€åˆ†å¸ƒã€‚</p>
<p>é‚£ä¹ˆå¯¹åº”å‚æ•°çš„ä¼°è®¡ä¸ºï¼š</p>
<ul>
<li><p>å‡å€¼ï¼š<br>$$<br>\mu_{jk} &#x3D; \frac{1}{n_k} \sum_{i&#x3D;1}^{n_k} x_j^{(i)}<br>$$</p>
</li>
<li><p>æ–¹å·®ï¼š<br>$$<br>\sigma_{jk}^2 &#x3D; \frac{1}{n_k} \sum_{i&#x3D;1}^{n_k} \left( x_j^{(i)} - \mu_{jk} \right)^2<br>$$</p>
</li>
</ul>
<p>å…¶ä¸­ï¼Œ  </p>
<ul>
<li>$n_k$ æ˜¯ç±»åˆ« $C_k$ çš„æ ·æœ¬æ•°ï¼Œ  </li>
<li>$x_j^{(i)}$ è¡¨ç¤ºç±»åˆ« $C_k$ ä¸­ç¬¬ i ä¸ªæ ·æœ¬çš„ç¬¬ j ä¸ªç‰¹å¾å€¼ã€‚</li>
</ul>
<hr>
<h4 id="æœ´ç´ è´å¶æ–¯ä¸­åéªŒæ¦‚ç‡è®¡ç®—ï¼ˆä»¥é«˜æ–¯æœ´ç´ è´å¶æ–¯ä¸ºä¾‹ï¼‰"><a href="#æœ´ç´ è´å¶æ–¯ä¸­åéªŒæ¦‚ç‡è®¡ç®—ï¼ˆä»¥é«˜æ–¯æœ´ç´ è´å¶æ–¯ä¸ºä¾‹ï¼‰" class="headerlink" title="æœ´ç´ è´å¶æ–¯ä¸­åéªŒæ¦‚ç‡è®¡ç®—ï¼ˆä»¥é«˜æ–¯æœ´ç´ è´å¶æ–¯ä¸ºä¾‹ï¼‰"></a>æœ´ç´ è´å¶æ–¯ä¸­åéªŒæ¦‚ç‡è®¡ç®—ï¼ˆä»¥é«˜æ–¯æœ´ç´ è´å¶æ–¯ä¸ºä¾‹ï¼‰</h4><hr>
<p>ç»™å®šç±»åˆ«é›†åˆ $A_1, A_2, \ldots, A_n$ å’Œè§‚å¯Ÿåˆ°çš„ç‰¹å¾å‘é‡ $B &#x3D; (x_1, x_2, \ldots, x_d)$ï¼Œ<br>åéªŒæ¦‚ç‡è®¡ç®—å…¬å¼ä¸ºï¼š</p>
<p>$$<br>P(A_i \mid B) &#x3D; \frac{P(A_i) , P(B \mid A_i)}{\sum_{j&#x3D;1}^n P(A_j) , P(B \mid A_j)}<br>$$</p>
<hr>
<p>åœ¨é«˜æ–¯æœ´ç´ è´å¶æ–¯ä¸­ï¼Œå‡è®¾ç‰¹å¾æ¡ä»¶ç‹¬ç«‹ä¸”æœä»é«˜æ–¯åˆ†å¸ƒï¼Œ<br>åˆ™ç±»åˆ« $A_i$ ä¸‹ç‰¹å¾ $x_k$ çš„æ¡ä»¶æ¦‚ç‡ä¸ºï¼š</p>
<p>$$<br>P(x_k \mid A_i) &#x3D; \frac{1}{\sqrt{2\pi \sigma_{ik}^2}} \exp\left( -\frac{(x_k - \mu_{ik})^2}{2\sigma_{ik}^2} \right)<br>$$</p>
<p>å…¶ä¸­ï¼š  </p>
<ul>
<li>$\mu_{ik}$ å’Œ $\sigma_{ik}^2$ æ˜¯ç±»åˆ« $A_i$ ä¸‹ç¬¬ k ä¸ªç‰¹å¾çš„å‡å€¼å’Œæ–¹å·®ã€‚</li>
</ul>
<hr>
<p>æ ¹æ®ç‰¹å¾ç‹¬ç«‹æ€§å‡è®¾ï¼Œæ•´ä½“ä¼¼ç„¶ä¸ºï¼š</p>
<p>$$<br>P(B \mid A_i) &#x3D; \prod_{k&#x3D;1}^d P(x_k \mid A_i)<br>$$</p>
<hr>
<p>ç»¼ä¸Šï¼ŒåéªŒæ¦‚ç‡è®¡ç®—æ­¥éª¤ä¸ºï¼š</p>
<ol>
<li>è®¡ç®—å…ˆéªŒæ¦‚ç‡ $P(A_i)$ï¼Œä¸€èˆ¬ä¸ºç±»åˆ«æ ·æœ¬æ¯”ä¾‹ï¼›</li>
<li>åˆ©ç”¨é«˜æ–¯åˆ†å¸ƒè®¡ç®—æ¯ä¸ªç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡ $P(x_k \mid A_i)$ï¼›</li>
<li>è®¡ç®—ä¼¼ç„¶ $P(B \mid A_i) &#x3D; \prod_{k&#x3D;1}^d P(x_k \mid A_i)$ï¼›</li>
<li>ä»£å…¥è´å¶æ–¯å…¬å¼æ±‚å¾—åéªŒæ¦‚ç‡ï¼š</li>
</ol>
<p>$$<br>P(A_i \mid B) &#x3D; \frac{P(A_i) \prod_{k&#x3D;1}^d P(x_k \mid A_i)}{\sum_{j&#x3D;1}^n P(A_j) \prod_{k&#x3D;1}^d P(x_k \mid A_j)}<br>$$</p>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>åœ¨ é«˜æ–¯æœ´ç´ è´å¶æ–¯ï¼ˆGaussian Naive Bayesï¼‰ ä¸­ï¼Œæ¯ä¸ªç±»åˆ«ï¼ˆtargetï¼‰éƒ½ä¼šå•ç‹¬æ‹Ÿåˆä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼Œè€Œä¸”æ˜¯é’ˆå¯¹æ¯ä¸ªç‰¹å¾åˆ†åˆ«è®¡ç®—ã€‚<br><br>åœ¨åŒä¸€ä¸ªç±»åˆ«ï¼ˆtargetï¼‰ä¸‹ï¼Œå¤šä¸ªç‰¹å¾æ˜¯æ¡ä»¶ç‹¬ç«‹çš„ï¼ˆ<strong>æœ´ç´ è´å¶æ–¯çš„å‰æ</strong>,ä¾¿äºæ±‚å¾—<strong>è”åˆæ¦‚ç‡</strong>ï¼‰<br></p>
</blockquote>
<hr>
<h3 id="Discriminative-Model-vs-Generative-Model"><a href="#Discriminative-Model-vs-Generative-Model" class="headerlink" title="Discriminative Model vs Generative Model"></a>Discriminative Model vs Generative Model</h3><h4 id="åŸºæœ¬å®šä¹‰"><a href="#åŸºæœ¬å®šä¹‰" class="headerlink" title="åŸºæœ¬å®šä¹‰"></a>åŸºæœ¬å®šä¹‰</h4><table>
<thead>
<tr>
<th></th>
<th><strong>Discriminative Model (åˆ¤åˆ«å¼æ¨¡å‹)</strong></th>
<th><strong>Generative Model (ç”Ÿæˆå¼æ¨¡å‹)</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>æ ¸å¿ƒæ€æƒ³</strong></td>
<td>ç›´æ¥å­¦ä¹  <strong>åéªŒåˆ†å¸ƒ</strong> $p(y|x)$</td>
<td>å…ˆå­¦ä¹  <strong>è”åˆåˆ†å¸ƒ</strong> $p(x,y)$ï¼Œæˆ–æ¡ä»¶åˆ†å¸ƒ $p(x|y)$ å’Œå…ˆéªŒ $p(y)$</td>
</tr>
<tr>
<td><strong>å…³é”®ä»»åŠ¡</strong></td>
<td>æ‰¾åˆ°æœ€å¥½çš„å†³ç­–è¾¹ç•Œï¼Œåˆ†æ¸…ç±»åˆ«</td>
<td>ç†è§£æ•°æ®æ˜¯å¦‚ä½•ç”Ÿæˆçš„ï¼Œå¯ç”¨äºç”Ÿæˆæ–°æ ·æœ¬</td>
</tr>
<tr>
<td><strong>ä¸¾ä¸ªä¾‹å­</strong></td>
<td>Logistic Regression, SVM, Neural Network</td>
<td>Naive Bayes, GMM, HMM, GAN, VAE</td>
</tr>
</tbody></table>
<h4 id="å…¬å¼å¯¹æ¯”"><a href="#å…¬å¼å¯¹æ¯”" class="headerlink" title="å…¬å¼å¯¹æ¯”"></a>å…¬å¼å¯¹æ¯”</h4><table>
<thead>
<tr>
<th></th>
<th><strong>åˆ¤åˆ«å¼</strong></th>
<th><strong>ç”Ÿæˆå¼</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>æ ¸å¿ƒå»ºæ¨¡</strong></td>
<td>$p(y|x)$</td>
<td>$p(x,y) &#x3D; p(x|y) p(y)$</td>
</tr>
<tr>
<td><strong>ç›®æ ‡</strong></td>
<td>æœ€å¤§åŒ–æ¡ä»¶ä¼¼ç„¶ï¼š$\max_\theta p(y|x)$</td>
<td>æœ€å¤§åŒ–è”åˆä¼¼ç„¶ï¼š$\max_\theta p(x,y)$</td>
</tr>
</tbody></table>
<hr>
<h4 id="ä¼˜ç¼ºç‚¹"><a href="#ä¼˜ç¼ºç‚¹" class="headerlink" title="ä¼˜ç¼ºç‚¹"></a>ä¼˜ç¼ºç‚¹</h4><table>
<thead>
<tr>
<th></th>
<th><strong>åˆ¤åˆ«å¼</strong></th>
<th><strong>ç”Ÿæˆå¼</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>ä¼˜ç‚¹</strong></td>
<td>- ä¸éœ€è¦å»ºæ¨¡è¾“å…¥åˆ†å¸ƒï¼Œç®€å•é«˜æ•ˆ  <br> - ä¸€èˆ¬åˆ†ç±»å‡†ç¡®ç‡æ›´é«˜</td>
<td>- å¯ç”Ÿæˆæ–°æ•°æ®  <br> - å¯å¤„ç†ç¼ºå¤±å€¼  <br> - å¯¹å°æ ·æœ¬é—®é¢˜æœ‰ä¼˜åŠ¿</td>
</tr>
<tr>
<td><strong>ç¼ºç‚¹</strong></td>
<td>- æ— æ³•ç”Ÿæˆæ•°æ®  <br> - å¯¹ç¼ºå¤±å€¼æ•æ„Ÿ</td>
<td>- å¯¹è¾“å…¥åˆ†å¸ƒéœ€è¦å‡è®¾  <br> - ç‰¹å¾æ¡ä»¶ç‹¬ç«‹å‡è®¾å¯èƒ½å¤ªå¼º</td>
</tr>
</tbody></table>
<hr>
<h4 id="å¸¸è§ç¤ºä¾‹"><a href="#å¸¸è§ç¤ºä¾‹" class="headerlink" title="å¸¸è§ç¤ºä¾‹"></a>å¸¸è§ç¤ºä¾‹</h4><table>
<thead>
<tr>
<th></th>
<th><strong>åˆ¤åˆ«å¼</strong></th>
<th><strong>ç”Ÿæˆå¼</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>çº¿æ€§æ¨¡å‹</strong></td>
<td>Logistic Regression</td>
<td>Naive Bayes (Gaussian&#x2F;Multinomial)</td>
</tr>
<tr>
<td><strong>éçº¿æ€§</strong></td>
<td>Neural Network, SVM</td>
<td>GMM, HMM, GAN, VAE</td>
</tr>
</tbody></table>
<h3 id="Optimization-1"><a href="#Optimization-1" class="headerlink" title="Optimization"></a>Optimization</h3><h4 id="ä½¿ç”¨Hessianåˆ†æSaddle-Pointå’ŒLocal-Minimal"><a href="#ä½¿ç”¨Hessianåˆ†æSaddle-Pointå’ŒLocal-Minimal" class="headerlink" title="ä½¿ç”¨Hessianåˆ†æSaddle Pointå’ŒLocal Minimal"></a>ä½¿ç”¨Hessianåˆ†æSaddle Pointå’ŒLocal Minimal</h4><p>At critical point: $L(\theta) &#x3D; L(\theta_0) + \frac{1}{2}(\theta - \theta_0)^TH(\theta - \theta_0)$.<br>æˆ‘ä»¬æŠŠu(an eigen vector of H)å½“ä½œ$\theta - \theta_0$,$\lambda$ä¸ºeigen value. </p>
<p>é‚£ä¹ˆ$u^T H u &#x3D; u^T(\lambda u) &#x3D; \lambda|u|^2 $.<br>å› æ­¤$\lambda$æ­£è´Ÿä¼šç›´æ¥Lçš„increase or decrease<br>æ ¹æ®è¿™ä¸ªå…¬å¼å¯çŸ¥è§£å†³saddle pointé—®é¢˜æ­¥éª¤å¦‚ä¸‹ï¼š  </p>
<ul>
<li>æ‰¾åˆ°H</li>
<li>æ‰¾åˆ°Hçš„æŸä¸ªè´Ÿç‰¹å¾å€¼</li>
<li>å¯¹åº”çš„ç‰¹å¾å‘é‡uå°±æ˜¯æƒ³æ‰¾çš„ä¸‹é™æ–¹å‘</li>
<li>$\theta &#x3D; \theta_0 + u$</li>
</ul>
<h4 id="Adaptive-Learning-Rate"><a href="#Adaptive-Learning-Rate" class="headerlink" title="Adaptive Learning Rate"></a>Adaptive Learning Rate</h4><h5 id="Root-Mean-Square"><a href="#Root-Mean-Square" class="headerlink" title="Root Mean Square"></a>Root Mean Square</h5><p><strong>å®šä¹‰ï¼š</strong><br>Root Mean Squareï¼ˆRMSï¼‰æ˜¯æŒ‡ä¸€ç»„æ•°å¹³æ–¹åæ±‚å¹³å‡å†å¼€æ–¹ï¼Œåæ˜ å¹³å‡â€œèƒ½é‡â€å¤§å°ã€‚</p>
<p>å…¬å¼å¦‚ä¸‹ï¼š</p>
<p>$\sigma_i^t &#x3D; \sqrt{\frac{1}{t+1}\sum_{i&#x3D;0}^t (g_i^t)^2}$.  </p>
<p>$\theta_i^{t+1} &#x3D; \theta_i^t - \frac{\eta}{\sigma_i^t}g_i^t$</p>
<p>åœ¨ä¼˜åŒ–ä¸­ï¼Œç”¨äºè¡¡é‡æ¢¯åº¦å¤§å°ï¼Œä½œä¸ºå­¦ä¹ ç‡è°ƒæ•´çš„ä¾æ®ã€‚</p>
<h5 id="RMSProp-Root-Mean-Square-Propagation"><a href="#RMSProp-Root-Mean-Square-Propagation" class="headerlink" title="RMSProp (Root Mean Square Propagation)"></a>RMSProp (Root Mean Square Propagation)</h5><ul>
<li>æ¢¯åº¦å¹³æ–¹æ»‘åŠ¨å¹³å‡ï¼š</li>
</ul>
<p>$\sigma_i^t &#x3D; \sqrt{\alpha (\sigma_i^{t-1})^2 + (1-\alpha)(g_i^t)^2}$</p>
<ul>
<li>å‚æ•°æ›´æ–°ï¼š</li>
</ul>
<p>$Î¸_i^{t+1} &#x3D; Î¸_i^t - \frac{\eta}{\sigma_i^t}g_i^t$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>Ï æ˜¯è¡°å‡ç‡ï¼ˆå¸¸ç”¨ 0.9ï¼‰</li>
<li>Î· æ˜¯åŸºç¡€å­¦ä¹ ç‡</li>
<li>Îµ æ˜¯é˜²æ­¢é™¤ä»¥ 0 çš„å°å¸¸æ•°ï¼ˆå¦‚ 1e-8ï¼‰</li>
</ul>
<h5 id="ç›´è§‰ç†è§£ï¼š"><a href="#ç›´è§‰ç†è§£ï¼š" class="headerlink" title="ç›´è§‰ç†è§£ï¼š"></a>ç›´è§‰ç†è§£ï¼š</h5><ul>
<li>æ¢¯åº¦å¤§çš„å‚æ•°æ–¹å‘ï¼šæ­¥é•¿ç¼©å°ï¼Œé¿å…éœ‡è¡</li>
<li>æ¢¯åº¦å°çš„å‚æ•°æ–¹å‘ï¼šæ­¥é•¿æ”¾å¤§ï¼Œé¿å…åœæ»</li>
<li>RMSProp æ ¹æ®æ¯ä¸ªå‚æ•°çš„å†å²æ¢¯åº¦è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡ï¼Œå®ç°æ›´ç¨³å®šçš„æ”¶æ•›è¿‡ç¨‹</li>
</ul>
<h4 id="æ€»ç»“å¯¹æ¯”"><a href="#æ€»ç»“å¯¹æ¯”" class="headerlink" title="æ€»ç»“å¯¹æ¯”"></a>æ€»ç»“å¯¹æ¯”</h4><table>
<thead>
<tr>
<th>æ¦‚å¿µ</th>
<th>å«ä¹‰ &#x2F; ä½œç”¨</th>
<th>ä¸ RMSProp çš„å…³ç³»</th>
</tr>
</thead>
<tbody><tr>
<td>Adaptive Learning Rate</td>
<td>æ¯ä¸ªå‚æ•°ç‹¬ç«‹å­¦ä¹ ç‡ï¼ŒåŠ¨æ€è°ƒæ•´</td>
<td>RMSProp æ˜¯å…¶ä»£è¡¨æ€§å®ç°æ–¹æ³•</td>
</tr>
<tr>
<td>Root Mean Square</td>
<td>ç”¨äºä¼°è®¡æ¢¯åº¦å¹³å‡èƒ½é‡ï¼Œæ§åˆ¶æ­¥é•¿</td>
<td>è¢« RMSProp ç”¨äºç¼©æ”¾å­¦ä¹ ç‡</td>
</tr>
<tr>
<td>RMSProp</td>
<td>è‡ªé€‚åº”ä¼˜åŒ–ç®—æ³•ï¼Œé˜²æ­¢å­¦ä¹ ç‡è¿‡æ—©è¡°å‡</td>
<td>å®ç°äº† adaptive learning rate</td>
</tr>
</tbody></table>
<h5 id="Learning-Rate-Scheduling"><a href="#Learning-Rate-Scheduling" class="headerlink" title="Learning Rate Scheduling"></a>Learning Rate Scheduling</h5><h4 id="Batch-å’Œ-Momentumç®€è¦è¯´æ˜"><a href="#Batch-å’Œ-Momentumç®€è¦è¯´æ˜" class="headerlink" title="Batch å’Œ Momentumç®€è¦è¯´æ˜"></a>Batch å’Œ Momentumç®€è¦è¯´æ˜</h4><h5 id="Batchï¼ˆå°æ‰¹é‡ï¼‰"><a href="#Batchï¼ˆå°æ‰¹é‡ï¼‰" class="headerlink" title="Batchï¼ˆå°æ‰¹é‡ï¼‰"></a>Batchï¼ˆå°æ‰¹é‡ï¼‰</h5><p>åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¸ä¼šæ¯æ¬¡ä½¿ç”¨æ•´ä¸ªè®­ç»ƒé›†æ¥æ›´æ–°å‚æ•°ï¼Œè€Œæ˜¯å°†æ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªâ€œå°æ‰¹é‡â€ï¼Œæ¯ä¸ª batch åŒ…å«è‹¥å¹²æ ·æœ¬ã€‚</p>
<p>ä¾‹å¦‚ï¼š</p>
<ul>
<li>æ•°æ®æ€»é‡ä¸º 10,000ï¼Œbatch size &#x3D; 32</li>
<li>åˆ™æ¯ä¸ª epoch æœ‰çº¦ 312 æ¬¡æ›´æ–°</li>
</ul>
<h6 id="ä½œç”¨"><a href="#ä½œç”¨" class="headerlink" title="ä½œç”¨"></a>ä½œç”¨</h6><ul>
<li>æé«˜è®­ç»ƒæ•ˆç‡ï¼ˆç›¸æ¯”ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†ï¼‰</li>
<li>æä¾›æ›´ç¨³å®šçš„æ¢¯åº¦ä¼°è®¡ï¼ˆç›¸æ¯”å•ä¸ªæ ·æœ¬ï¼‰</li>
<li>æœ‰åˆ©äº GPU å¹¶è¡Œè®¡ç®—</li>
</ul>
<h6 id="ç›´è§‰ï¼š"><a href="#ç›´è§‰ï¼š" class="headerlink" title="ç›´è§‰ï¼š"></a>ç›´è§‰ï¼š</h6><ul>
<li>å° batchï¼šè®­ç»ƒå¿«ä½†ä¸ç¨³å®šï¼Œæ¢¯åº¦å™ªå£°å¤§</li>
<li>å¤§ batchï¼šè®­ç»ƒç¨³å®šä½†è®¡ç®—å¼€é”€å¤§ï¼Œæ”¶æ•›å¯èƒ½æ…¢</li>
</ul>
<h5 id="Momentumï¼ˆåŠ¨é‡ï¼‰"><a href="#Momentumï¼ˆåŠ¨é‡ï¼‰" class="headerlink" title="Momentumï¼ˆåŠ¨é‡ï¼‰"></a>Momentumï¼ˆåŠ¨é‡ï¼‰</h5><p>Momentum æ˜¯ä¼˜åŒ–å™¨çš„ä¸€ç§åŠ é€ŸæŠ€å·§ï¼Œé€šè¿‡å¼•å…¥â€œåŠ¨é‡â€ï¼Œåœ¨æ¢¯åº¦æ–¹å‘ä¸Šç§¯ç´¯é€Ÿåº¦ã€‚</p>
<p>å¸¸è§„æ¢¯åº¦ä¸‹é™å…¬å¼ï¼š</p>
<pre><code>$Î¸_&#123;t+1&#125; = Î¸_t - Î· âˆ‡L(Î¸_t)$
</code></pre>
<p>åŠ å…¥åŠ¨é‡åçš„æ›´æ–°è§„åˆ™ï¼š</p>
<pre><code>$v_&#123;t+1&#125; = Î³ v_t - Î· âˆ‡L(Î¸_t)$
$Î¸_&#123;t+1&#125; = Î¸_t + v_&#123;t+1&#125;$
</code></pre>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>Î· æ˜¯å­¦ä¹ ç‡</li>
<li>Î³ æ˜¯åŠ¨é‡ç³»æ•°ï¼ˆå¦‚ 0.9ï¼‰</li>
<li>v æ˜¯â€œé€Ÿåº¦å‘é‡â€ï¼Œè¡¨ç¤ºå†å²æ¢¯åº¦ç´¯ç§¯æ•ˆæœ</li>
</ul>
<h6 id="ä½œç”¨ï¼š"><a href="#ä½œç”¨ï¼š" class="headerlink" title="ä½œç”¨ï¼š"></a>ä½œç”¨ï¼š</h6><ul>
<li>åŠ å¿«æ”¶æ•›é€Ÿåº¦</li>
<li>å‡å°‘æ¢¯åº¦éœ‡è¡</li>
<li>æ›´å®¹æ˜“è·³å‡ºå±€éƒ¨æœ€å°å€¼</li>
</ul>
<h6 id="ç›´è§‰ï¼š-1"><a href="#ç›´è§‰ï¼š-1" class="headerlink" title="ç›´è§‰ï¼š"></a>ç›´è§‰ï¼š</h6><p>åƒæ»šåŠ¨çš„å°çƒæœ‰æƒ¯æ€§ï¼ŒåŠ¨é‡è®©ä¼˜åŒ–å™¨åœ¨æ¢¯åº¦ä¸€è‡´çš„æ–¹å‘ä¸ŠåŠ é€Ÿå‰è¿›ï¼Œåœ¨æ¢¯åº¦å˜åŒ–å‰§çƒˆçš„æ–¹å‘ä¸Šç¨³å®šä¸‹æ¥ã€‚</p>
<h5 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h5><table>
<thead>
<tr>
<th>æ¦‚å¿µ</th>
<th>å®šä¹‰</th>
<th>ä½œç”¨</th>
</tr>
</thead>
<tbody><tr>
<td>Batch</td>
<td>ä¸€æ¬¡æ›´æ–°ä¸­ä½¿ç”¨çš„æ ·æœ¬å­é›†</td>
<td>æé«˜æ•ˆç‡ã€å¹³æ»‘æ¢¯åº¦ä¼°è®¡</td>
</tr>
<tr>
<td>Momentum</td>
<td>ä½¿ç”¨å†å²æ¢¯åº¦åŠ é€Ÿæ›´æ–°</td>
<td>åŠ é€Ÿæ”¶æ•›ã€å‡å°‘éœ‡è¡ã€è·³å‡ºå±€éƒ¨æœ€å°å€¼</td>
</tr>
</tbody></table>
<h3 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h3><p>æ— è®ºæ˜¯åœ¨å›¾åƒè¯†åˆ«ï¼ŒéŸ³é¢‘å¤„ç†ç­‰åº”ç”¨ä¸­ï¼Œè¾“å…¥éƒ½å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªå‘é‡ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªæ•°å€¼æˆ–ç±»åˆ«ã€‚ç„¶è€Œï¼Œè‹¥è¾“å…¥æ˜¯<strong>ä¸€ç³»åˆ—å‘é‡</strong>,åŒæ—¶é•¿åº¦ä¼šæ”¹å˜ï¼Œä¾‹å¦‚æŠŠå¥å­é‡Œçš„å•è¯éƒ½æè¿°ä¸ºå‘é‡ï¼Œé‚£ä¹ˆæ¨¡å‹çš„è¾“å…¥å°±æ˜¯ä¸€ä¸ªå‘é‡é›†åˆï¼Œå¹¶ä¸”æ¯ä¸ªå‘é‡çš„å¤§å°éƒ½ä¸ä¸€æ ·ã€‚<br>å¯¹äºè¿™ä¸ªä¸€ç³»åˆ—å‘é‡ï¼Œæˆ–è€…è¯´æ˜¯å‘é‡é›†åˆï¼Œæˆ‘ä»¬é€šå¸¸ä¼šè€ƒè™‘ä¸Šä¸‹æ–‡ï¼Œå› æ­¤æˆ‘ä»¬ä¼šå¼•å…¥æ»‘åŠ¨çª—å£æœºåˆ¶ï¼Œæ¯ä¸ªå‘é‡æŸ¥çœ‹çª—å£ä¸­ç›¸é‚»çš„å…¶ä»–å‘é‡çš„æ€§è´¨ã€‚ä¸ºäº†é‡åŒ–åœ°è®¡ç®—å‘é‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†Self-attentionæŠ€æœ¯ã€‚</p>
<h4 id="Basic-Concept-1"><a href="#Basic-Concept-1" class="headerlink" title="Basic Concept"></a>Basic Concept</h4><p>åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œä¸»è¦æ¶‰åŠä¸‰ä¸ªå‘é‡ï¼šQueryã€Key å’Œ Valueã€‚</p>
<p>ç»™å®šä¸€ä¸ªè¾“å…¥å‘é‡é›†åˆ ${a^1, a^2, \dots, a^n}$ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªå‘é‡ $a^i$ è¿›è¡Œçº¿æ€§å˜æ¢ä»¥è·å¾—å¯¹åº”çš„ Queryã€Key å’Œ Value å‘é‡ã€‚</p>
<h4 id="å‘é‡è®¡ç®—"><a href="#å‘é‡è®¡ç®—" class="headerlink" title="å‘é‡è®¡ç®—"></a>å‘é‡è®¡ç®—</h4><ul>
<li>Query å‘é‡ï¼š$q^i &#x3D; a^i W^q$</li>
<li>Key å‘é‡ï¼š$k^i &#x3D; a^i W^k$</li>
<li>Value å‘é‡ï¼š$v^i &#x3D; a^i W^v$</li>
</ul>
<p>å…¶ä¸­ï¼Œ$W^q$ã€$W^k$ã€$W^v$ æ˜¯å¯å­¦ä¹ çš„å‚æ•°çŸ©é˜µï¼Œç»´åº¦é€šå¸¸ä¸ºï¼š</p>
<ul>
<li>$W^q \in \mathbb{R}^{d_{model} \times d_k}$</li>
<li>$W^k \in \mathbb{R}^{d_{model} \times d_k}$</li>
<li>$W^v \in \mathbb{R}^{d_{model} \times d_v}$</li>
</ul>
<h4 id="æ³¨æ„åŠ›æ‰“åˆ†æœºåˆ¶"><a href="#æ³¨æ„åŠ›æ‰“åˆ†æœºåˆ¶" class="headerlink" title="æ³¨æ„åŠ›æ‰“åˆ†æœºåˆ¶"></a>æ³¨æ„åŠ›æ‰“åˆ†æœºåˆ¶</h4><p>å¯¹äºä¸€ä¸ªæŸ¥è¯¢å‘é‡ $q^i$ï¼Œå…¶å¯¹åº”çš„æ³¨æ„åŠ›æƒé‡æ˜¯é€šè¿‡å®ƒä¸æ‰€æœ‰ Key å‘é‡çš„ç‚¹ç§¯è®¡ç®—å¾—åˆ°çš„ï¼š</p>
<p>$$<br>\text{score}_{ij} &#x3D; \frac{q^i \cdot (k^j)^T}{\sqrt{d_k}}<br>$$</p>
<p>ç„¶åä½¿ç”¨ Softmax å‡½æ•°å¯¹æ‰€æœ‰å¾—åˆ†è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¾—åˆ°æ³¨æ„åŠ›åˆ†å¸ƒï¼š</p>
<p>$$<br>\alpha_{ij} &#x3D; \text{softmax}(\text{score}<em>{ij}) &#x3D; \frac{\exp(\text{score}</em>{ij})}{\sum_{j&#x3D;1}^{n} \exp(\text{score}_{ij})}<br>$$</p>
<h4 id="åŠ æƒæ±‚å’Œå¾—åˆ°è¾“å‡º"><a href="#åŠ æƒæ±‚å’Œå¾—åˆ°è¾“å‡º" class="headerlink" title="åŠ æƒæ±‚å’Œå¾—åˆ°è¾“å‡º"></a>åŠ æƒæ±‚å’Œå¾—åˆ°è¾“å‡º</h4><p>æœ€åï¼Œä½¿ç”¨è¿™äº›æ³¨æ„åŠ›æƒé‡å¯¹å¯¹åº”çš„ Value å‘é‡åŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æœ€ç»ˆçš„æ³¨æ„åŠ›è¾“å‡ºå‘é‡ï¼š</p>
<p>$$<br>z^i &#x3D; \sum_{j&#x3D;1}^{n} \alpha_{ij} v^j<br>$$</p>
<p>è¿™ä¸ªè¿‡ç¨‹å¯ä»¥è¡¨ç¤ºä¸ºçŸ©é˜µå½¢å¼ï¼š</p>
<p>$$<br>\text{Attention}(Q, K, V) &#x3D; \text{softmax}\left( \frac{QK^T}{\sqrt{d_k}} \right) V<br>$$</p>
<hr>
<h4 id="æ—¶é—´æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›"><a href="#æ—¶é—´æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›" class="headerlink" title="æ—¶é—´æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›"></a>æ—¶é—´æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›</h4><table>
<thead>
<tr>
<th>ç‰¹æ€§</th>
<th>ç©ºé—´æ³¨æ„åŠ› ğŸ§­ (CausalAttnBlock)</th>
<th>æ—¶é—´æ³¨æ„åŠ› ğŸ•’ (CausalTemporalAttnBlock)</th>
</tr>
</thead>
<tbody><tr>
<td>æ³¨æ„åŠ›è½´</td>
<td>HÃ—Wï¼ˆç©ºé—´ï¼‰</td>
<td>Tï¼ˆæ—¶é—´ï¼‰</td>
</tr>
<tr>
<td>softmax ç»´åº¦</td>
<td>HÃ—W</td>
<td>T</td>
</tr>
<tr>
<td>æ¯ä¸ª token è¡¨ç¤º</td>
<td>åƒç´ ä½ç½®</td>
<td>æ—¶é—´å¸§</td>
</tr>
<tr>
<td>Q&#x2F;K&#x2F;V å‘é‡é•¿åº¦ (d_k)</td>
<td>C</td>
<td>C</td>
</tr>
<tr>
<td>æ³¨æ„åŠ›çŸ©é˜µå¤§å°</td>
<td>[B<em>T, H</em>W, H*W]</td>
<td>[B<em>H</em>W, T, T]</td>
</tr>
<tr>
<td>æ•æ‰çš„ä¾èµ–ç±»å‹</td>
<td>ç©ºé—´ä¸Šä¸‹æ–‡ã€ç»“æ„ã€å±€éƒ¨-å…¨å±€å…³ç³»</td>
<td>æ—¶é—´åŠ¨æ€ã€å†å²ä¿¡æ¯ã€è¿åŠ¨ä¿¡æ¯</td>
</tr>
<tr>
<td>åº”ç”¨åœºæ™¯</td>
<td>å›¾åƒå±€éƒ¨ä¾èµ–å»ºæ¨¡ã€SRã€åˆ†å‰²</td>
<td>è§†é¢‘å»ºæ¨¡ã€æ—¶åºé¢„æµ‹ã€è¿åŠ¨è¡¥å¿</td>
</tr>
</tbody></table>
<h4 id="æ€»ç»“æµç¨‹ï¼š"><a href="#æ€»ç»“æµç¨‹ï¼š" class="headerlink" title="æ€»ç»“æµç¨‹ï¼š"></a>æ€»ç»“æµç¨‹ï¼š</h4><ol>
<li>è¾“å…¥å‘é‡é›† $a^i$</li>
<li>è®¡ç®— Query: $q^i &#x3D; a^i W^q$</li>
<li>è®¡ç®— Key: $k^i &#x3D; a^i W^k$</li>
<li>è®¡ç®— Value: $v^i &#x3D; a^i W^v$</li>
<li>è®¡ç®—æ³¨æ„åŠ›å¾—åˆ†ï¼ˆç‚¹ç§¯ï¼‰ï¼š$q^i \cdot (k^j)^T$</li>
<li>é€šè¿‡ Softmax å¾—åˆ°æ³¨æ„åŠ›æƒé‡</li>
<li>å¯¹ Value åŠ æƒæ±‚å’Œå¾—åˆ°è¾“å‡º $z^i$</li>
</ol>
<hr>
<h4 id="è¯´æ˜"><a href="#è¯´æ˜" class="headerlink" title="è¯´æ˜"></a>è¯´æ˜</h4><ul>
<li>$d_k$ æ˜¯ Key å‘é‡çš„ç»´åº¦</li>
<li>$d_v$ æ˜¯ Value å‘é‡çš„ç»´åº¦</li>
<li>æ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡å‹åŠ¨æ€åœ°èšç„¦äºè¾“å…¥åºåˆ—ä¸­æœ€ç›¸å…³çš„éƒ¨åˆ†</li>
</ul>
<h4 id="Local-Attention"><a href="#Local-Attention" class="headerlink" title="Local Attention"></a>Local Attention</h4><p>In <strong>local attention</strong>, each position only attends to a limited number of nearby positions (i.e., a fixed-size window). It mimics sliding-window machanims.<br><strong>Example (window size &#x3D; 2):</strong><br>$$<br>a_i attends to {a_{i-2}, a_{i-1}, a_i, a_{i+1}, a_{i+2}}<br>$$</p>
<h5 id="Pros"><a href="#Pros" class="headerlink" title="Pros:"></a>Pros:</h5><ul>
<li>Reduces computation to 0(nw), where w is the window size</li>
<li>Works well in spatial&#x2F;temporal data (e.g., images, audio)</li>
</ul>
<h4 id="Global-Attention"><a href="#Global-Attention" class="headerlink" title="Global Attention"></a>Global Attention</h4><p>In <strong>global attention</strong>, each query attends to <strong>all positions</strong> in the sequence.</p>
<h5 id="Pros-1"><a href="#Pros-1" class="headerlink" title="Pros:"></a>Pros:</h5><ul>
<li>Captures long-range dependencies</li>
<li>Powerful and general-purpose</li>
</ul>
<h5 id="Cons"><a href="#Cons" class="headerlink" title="Cons:"></a>Cons:</h5><ul>
<li>High computational cost</li>
</ul>
<h4 id="Clustering-based-Attention"><a href="#Clustering-based-Attention" class="headerlink" title="Clustering-based Attention"></a>Clustering-based Attention</h4><h3 id="RNN-Recurrent-Neural-Network"><a href="#RNN-Recurrent-Neural-Network" class="headerlink" title="RNN (Recurrent Neural Network)"></a>RNN (Recurrent Neural Network)</h3><h4 id="Long-Short-Term-Memory-LSTM-Cell-Explanation"><a href="#Long-Short-Term-Memory-LSTM-Cell-Explanation" class="headerlink" title="Long Short-Term Memory (LSTM) Cell Explanation"></a>Long Short-Term Memory (LSTM) Cell Explanation</h4><p>ä¸€ä¸ªLSTM cellå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªcnnä¸­çš„neuron<br>This project contains visual illustrations and numerical examples of how an LSTM (Long Short-Term Memory) cell works internally. The LSTM is a type of recurrent neural network (RNN) that is capable of learning long-term dependencies and solving the vanishing gradient problem.</p>
<h4 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h4><p>LSTMs introduce <strong>memory cells</strong> and <strong>gating mechanisms</strong> to control the flow of information. The key gates in an LSTM cell are:</p>
<ul>
<li><p><strong>é—å¿˜é—¨ï¼ˆForget Gateï¼‰</strong><br>æ§åˆ¶ä¿ç•™å¤šå°‘è¿‡å»çš„è®°å¿†ã€‚<br>è®¡ç®—æ–¹å¼ï¼š$f(z_f)$ï¼Œä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°ï¼Œè¾“å‡ºèŒƒå›´åœ¨ $[0, 1]$ï¼Œæ¨¡æ‹Ÿâ€œå¼€â€ä¸â€œå…³â€ã€‚</p>
</li>
<li><p><strong>è¾“å…¥é—¨ï¼ˆInput Gateï¼‰</strong><br>å†³å®šå½“å‰è¾“å…¥ä¸­ä¿ç•™å“ªäº›ä¿¡æ¯ã€‚<br>è¡¨è¾¾å¼ä¸ºï¼š$f(z_i)$ å’Œ $g(z)$ã€‚</p>
</li>
<li><p><strong>è®°å¿†å•å…ƒçŠ¶æ€ï¼ˆCell Stateï¼‰</strong><br>çŠ¶æ€æ›´æ–°å…¬å¼ï¼š<br>$$<br>C_{\text{new}} &#x3D; f(z_f) \cdot C_{\text{old}} + f(z_i) \cdot g(z)<br>$$</p>
</li>
<li><p><strong>è¾“å‡ºé—¨ï¼ˆOutput Gateï¼‰</strong><br>å†³å®šå½“å‰æ—¶åˆ»çš„éšè—çŠ¶æ€è¾“å‡º $a$ï¼š<br>$$<br>a &#x3D; f(z_o) \cdot h(C)<br>$$</p>
</li>
</ul>
<p>æ¿€æ´»å‡½æ•°è¯´æ˜ï¼š</p>
<ul>
<li>$f(\cdot)$ è¡¨ç¤º sigmoidï¼ˆ$\sigma$ å‡½æ•°ï¼‰ï¼Œæ§åˆ¶é—¨çš„å¼€å…³ï¼›</li>
<li>$g(\cdot)$ è¡¨ç¤º tanhï¼Œå¤„ç†è¾“å…¥çš„å€™é€‰è®°å¿†ï¼›</li>
<li>$h(\cdot)$ é€šå¸¸ä¹Ÿæ˜¯ tanhï¼Œç”¨äºè¾“å‡ºå¤„ç†ã€‚</li>
</ul>
<hr>
<h4 id="LSTM-æ•°å€¼è®¡ç®—ç¤ºä¾‹"><a href="#LSTM-æ•°å€¼è®¡ç®—ç¤ºä¾‹" class="headerlink" title="LSTM æ•°å€¼è®¡ç®—ç¤ºä¾‹"></a>LSTM æ•°å€¼è®¡ç®—ç¤ºä¾‹</h4><img src="/images/LSTM_Formulation.png">

<p>è¯¥å›¾å±•ç¤ºäº†ä¸€ä¸ªå®Œæ•´çš„ <strong>LSTM å•å…ƒçš„å‰å‘ä¼ æ’­æ•°å€¼è¿‡ç¨‹</strong>ï¼Œä¸»è¦ç‰¹å¾åŒ…æ‹¬ï¼š</p>
<ul>
<li>è¾“å…¥ç‰¹å¾å‘é‡ $x_1$, $x_2$, $x_3$ åŠåç½®é¡¹ï¼›</li>
<li>ä¸åŒé—¨æ§çš„æƒé‡çŸ©é˜µã€åç½®ä¸çº¿æ€§ç»„åˆï¼›</li>
<li>æ˜¾å¼æ˜¾ç¤ºäº†è¾“å…¥é—¨ã€é—å¿˜é—¨ã€è¾“å‡ºé—¨çš„è®¡ç®—è¿‡ç¨‹ï¼›</li>
<li>Cell çš„çŠ¶æ€å€¼å¦‚ä½•éšç€æ—¶é—´å˜åŒ–æ›´æ–°ï¼›</li>
<li>æœ€ç»ˆè¾“å‡º $y$ åºåˆ—ä¸­åœ¨ç‰¹å®šæ—¶é—´æ­¥æ¿€æ´»ï¼ˆä¾‹å¦‚è¾“å‡ºä¸º 7ï¼‰ã€‚</li>
</ul>
<p>é€šè¿‡å¯è§†åŒ–çš„çŸ©é˜µè®¡ç®—ï¼Œå¯ä»¥çœ‹åˆ° LSTM å¦‚ä½•â€œè®°ä½â€æˆ–â€œå¿˜è®°â€è¾“å…¥ä¸­çš„å…³é”®ä¿¡æ¯ã€‚</p>
<h5 id="å…³é”®è®¡ç®—å…¬å¼"><a href="#å…³é”®è®¡ç®—å…¬å¼" class="headerlink" title="å…³é”®è®¡ç®—å…¬å¼"></a>å…³é”®è®¡ç®—å…¬å¼</h5><p>$$<br>\begin{aligned}<br>f_t &amp;&#x3D; \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \\<br>i_t &amp;&#x3D; \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \\<br>g_t &amp;&#x3D; \tanh(W_g \cdot [h_{t-1}, x_t] + b_g) \\<br>C_t &amp;&#x3D; f_t \cdot C_{t-1} + i_t \cdot g_t \\<br>o_t &amp;&#x3D; \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \\<br>h_t &amp;&#x3D; o_t \cdot \tanh(C_t)<br>\end{aligned}<br>$$<br>ç”±æ­¤å¯çŸ¥$W_f, W_i, W_g, W_o$çš„ç»´åº¦æ˜¯(hidden_size, input_dim + hidder_size),å› ä¸ºè¾“å…¥æ˜¯ç”±$h_{t-1}$å’Œ$x_t$è¿æ¥è€Œæˆã€‚<br>è®°å·è§£é‡Š:</p>
<ul>
<li><p>éšè—çŠ¶æ€å‘é‡<br>$h_{t-1} âˆˆ R^{64}$. </p>
<p>ä¸Šä¸€æ­¥çš„éšè—çŠ¶æ€ï¼Œç»´åº¦ä¸º 64ï¼ˆå¯¹åº” 64 ä¸ª hidden units æˆ– memory cellsï¼‰ã€‚</p>
</li>
<li><p>å½“å‰æ—¶é—´æ­¥è¾“å…¥å‘é‡<br> $x_t âˆˆ R^{d}$</p>
<p>å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥ï¼Œç»´åº¦ä¸ºè¾“å…¥ç‰¹å¾æ•° dã€‚</p>
</li>
<li><p>æƒé‡çŸ©é˜µ<br>$W_f, W_i, W_g, W_o âˆˆ R^{(64 + d) Ã— 64}$<br>å››ä¸ªé—¨ï¼ˆé—å¿˜é—¨ã€è¾“å…¥é—¨ã€å€™é€‰çŠ¶æ€ã€è¾“å‡ºé—¨ï¼‰çš„æƒé‡çŸ©é˜µï¼Œè¾“å…¥æ˜¯æ‹¼æ¥çš„ $[h_{t-1}, x_t]$ï¼Œè¾“å‡ºæ˜¯å¤§å°ä¸º 64 çš„é—¨æ§å‘é‡ã€‚</p>
</li>
<li><p>åç½®å‘é‡<br>$b_f, b_i, b_g, b_o âˆˆ R^{64}$. </p>
<p>å››ä¸ªé—¨å¯¹åº”çš„åç½®é¡¹ï¼Œç»´åº¦å‡ä¸º 64ã€‚</p>
</li>
</ul>
<h4 id="LSTMçš„æ¨¡å—è¯´æ˜ä»¥åŠåº”ç”¨åœºæ™¯"><a href="#LSTMçš„æ¨¡å—è¯´æ˜ä»¥åŠåº”ç”¨åœºæ™¯" class="headerlink" title="LSTMçš„æ¨¡å—è¯´æ˜ä»¥åŠåº”ç”¨åœºæ™¯"></a>LSTMçš„æ¨¡å—è¯´æ˜ä»¥åŠåº”ç”¨åœºæ™¯</h4><table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>ä½œç”¨</th>
</tr>
</thead>
<tbody><tr>
<td>é—å¿˜é—¨</td>
<td>å­¦ä¹ å»â€œå¿˜è®°â€æ— å…³è®°å¿†</td>
</tr>
<tr>
<td>è¾“å…¥é—¨</td>
<td>å­¦ä¹ å°†å½“å‰è¾“å…¥å†™å…¥è®°å¿†</td>
</tr>
<tr>
<td>å€™é€‰è®°å¿†å—</td>
<td>ç”Ÿæˆå½“å‰è¾“å…¥çš„è¡¨ç¤º</td>
</tr>
<tr>
<td>Cell çŠ¶æ€</td>
<td>é•¿æœŸè®°å¿†å­˜å‚¨é€šé“</td>
</tr>
<tr>
<td>è¾“å‡ºé—¨</td>
<td>æ§åˆ¶å½“å‰è¾“å‡ºæš´éœ²å¤šå°‘å†…éƒ¨è®°å¿†</td>
</tr>
</tbody></table>
<p>LSTM ç½‘ç»œé€‚ç”¨äºå¤„ç†<strong>æ—¶é—´ç›¸å…³æ€§è¾ƒå¼º</strong>çš„ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼š</p>
<ul>
<li>ğŸ§  è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ï¼šæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€è¯­è¨€å»ºæ¨¡</li>
<li>ğŸ“ˆ æ—¶é—´åºåˆ—é¢„æµ‹ï¼šè‚¡ä»·ã€ä¼ æ„Ÿå™¨æ•°æ®ã€æ°”è±¡æ•°æ®</li>
<li>ğŸ—£ è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³ç”Ÿæˆ</li>
<li>ğŸ”„ åºåˆ—åˆ°åºåˆ—ï¼ˆSeq2Seqï¼‰ï¼šæœºå™¨ç¿»è¯‘ã€æ‘˜è¦ç”Ÿæˆç­‰</li>
</ul>
<h4 id="è¾“å…¥æ ¼å¼"><a href="#è¾“å…¥æ ¼å¼" class="headerlink" title="è¾“å…¥æ ¼å¼"></a>è¾“å…¥æ ¼å¼</h4><p>Keras çš„ LSTM å±‚æ¥å—çš„è¾“å…¥å½¢çŠ¶ä¸€èˆ¬æ˜¯ (batch_size, timesteps, input_dim)ï¼Œ<br>å…¶ä¸­ timestepsï¼ˆåºåˆ—é•¿åº¦ï¼‰å¯ä»¥æ˜¯åŠ¨æ€çš„ï¼Œæˆ–è€…åœ¨æ¨¡å‹æ„å»ºæ—¶éšå«å®šä¹‰ã€‚<br>å¦‚æœä½ çš„ next_layer_in æ˜¯ä¸€ä¸ªä¸‰ç»´å¼ é‡ï¼ŒKeras ä¼šè‡ªåŠ¨æ ¹æ®è¾“å…¥çš„ shape è¯†åˆ«åºåˆ—é•¿åº¦ã€‚<br>åªè¦ä½ ä¼ å…¥çš„æ•°æ®å½¢çŠ¶ç¬¦åˆè¦æ±‚ï¼ŒKeras ä¼šæ ¹æ®å®é™…è¾“å…¥åŠ¨æ€å¤„ç†åºåˆ—é•¿åº¦ï¼Œä¸å¿…åœ¨ä»£ç é‡Œæ˜¾å¼å£°æ˜ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seq_in = Input(shape=(timesteps, input_dim))</span><br></pre></td></tr></table></figure>

<h4 id="LSTMå‚æ•°è®¡ç®—å…¬å¼"><a href="#LSTMå‚æ•°è®¡ç®—å…¬å¼" class="headerlink" title="LSTMå‚æ•°è®¡ç®—å…¬å¼"></a>LSTMå‚æ•°è®¡ç®—å…¬å¼</h4><p>å¯¹äºä¸€ä¸ªLSTMå±‚ï¼Œå‚æ•°æ•°é‡æ˜¯ï¼š<br>numParams &#x3D; 4 x [(units x input_dim + (units x units) + units]</p>
<ul>
<li>4 -&gt; å› ä¸ºLSTMæœ‰4ä¸ªé—¨ï¼ˆè¾“å…¥é—¨ã€é—å¿˜é—¨ã€å€™é€‰å•ä½ã€è¾“å‡ºé—¨ï¼‰ï¼Œæ¯ä¸ªé—¨éƒ½æœ‰ä¸€å¥—æƒé‡</li>
<li>units x input_dim -&gt; è¾“å…¥åˆ°éšè—å±‚çš„æƒé‡</li>
<li>units x units -&gt; éšè—åˆ°éšè—çš„å¾ªç¯æƒé‡</li>
<li>units -&gt; æ¯ä¸ªé—¨çš„åç½®</li>
</ul>
<h4 id="ç¤ºä¾‹-1"><a href="#ç¤ºä¾‹-1" class="headerlink" title="ç¤ºä¾‹"></a>ç¤ºä¾‹</h4><p>æœ¬ç¤ºä¾‹ç»“åˆä¸€ä¸ªLSTMæ¨¡å‹çš„å®Œæ•´ä»£ç ç»“æ„ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨pandaså‡†å¤‡æ•°æ®ã€æ„å»ºLSTMæ¨¡å‹åŠè®¡ç®—å‚æ•°é‡ï¼Œæ–¹ä¾¿åˆå­¦è€…ç†è§£å’Œåº”ç”¨ã€‚</p>
<h5 id="1-æ•°æ®é¢„å¤„ç†ï¼ˆpandasåŸºç¡€ï¼‰"><a href="#1-æ•°æ®é¢„å¤„ç†ï¼ˆpandasåŸºç¡€ï¼‰" class="headerlink" title="1. æ•°æ®é¢„å¤„ç†ï¼ˆpandasåŸºç¡€ï¼‰"></a>1. æ•°æ®é¢„å¤„ç†ï¼ˆpandasåŸºç¡€ï¼‰</h5><ul>
<li>è¯»å–CSVæ–‡ä»¶</li>
</ul>
<p>import pandas as pd<br>df &#x3D; pd.read_csv(â€œweatherHistory.csvâ€)</p>
<ul>
<li>æŸ¥çœ‹æ•°æ®å‰å‡ è¡Œ</li>
</ul>
<p>df.head()</p>
<ul>
<li>é€‰å–æ•°å€¼å‹åˆ—è®¡ç®—ç›¸å…³æ€§</li>
</ul>
<p>num_df &#x3D; df.select_dtypes(include&#x3D;[â€˜numberâ€™])<br>corr_matrix &#x3D; num_df.corr()</p>
<ul>
<li>å¤„ç†ç¼ºå¤±å€¼</li>
</ul>
<p>df.fillna(0, inplace&#x3D;True)</p>
<ul>
<li>æ ‡ç­¾ç¼–ç </li>
</ul>
<p>from sklearn.preprocessing import LabelEncoder<br>labelencoder &#x3D; LabelEncoder()<br>df[â€˜Summaryâ€™] &#x3D; labelencoder.fit_transform(df[â€˜Summaryâ€™])</p>
<ul>
<li>æ—¶é—´åºåˆ—è½¬ç›‘ç£å­¦ä¹ æ ¼å¼</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):</span><br><span class="line">    n_vars = 1 <span class="keyword">if</span> <span class="built_in">type</span>(data) is list <span class="keyword">else</span> data.shape[1]</span><br><span class="line">    <span class="built_in">df</span> = pd.DataFrame(data)</span><br><span class="line">    cols, names = [], []</span><br><span class="line">    <span class="comment"># è¿‡å»æ—¶é—´æ­¥ (t-n, ... t-1)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_in, 0, -1):</span><br><span class="line">        cols.append(df.shift(i))</span><br><span class="line">        names += [f<span class="string">&#x27;var&#123;j+1&#125;(t-&#123;i&#125;)&#x27;</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(n_vars)]</span><br><span class="line">    <span class="comment"># æœªæ¥æ—¶é—´æ­¥ (t, t+1, ... t+n)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_out):</span><br><span class="line">        cols.append(df.shift(-i))</span><br><span class="line">        <span class="keyword">if</span> i == 0:</span><br><span class="line">            names += [f<span class="string">&#x27;var&#123;j+1&#125;(t)&#x27;</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(n_vars)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            names += [f<span class="string">&#x27;var&#123;j+1&#125;(t+&#123;i&#125;)&#x27;</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(n_vars)]</span><br><span class="line">    agg = pd.concat(cols, axis=1)</span><br><span class="line">    agg.columns = names</span><br><span class="line">    <span class="keyword">if</span> dropnan:</span><br><span class="line">        agg.dropna(inplace=True)</span><br><span class="line">    <span class="built_in">return</span> agg</span><br></pre></td></tr></table></figure>
<hr>
<h5 id="2-æ•°æ®åˆ†å‰²ä¸å‡†å¤‡"><a href="#2-æ•°æ®åˆ†å‰²ä¸å‡†å¤‡" class="headerlink" title="2. æ•°æ®åˆ†å‰²ä¸å‡†å¤‡"></a>2. æ•°æ®åˆ†å‰²ä¸å‡†å¤‡</h5><p>å‡è®¾æœ‰ n_hours è¿‡å»æ—¶é—´æ­¥ï¼Œå’Œ n_features ç‰¹å¾æ•°ï¼š</p>
<p>n_obs &#x3D; n_hours * n_features<br>train_X, train_Y &#x3D; train[:, :n_obs], train[:, -6]   # ä»¥å€’æ•°ç¬¬6åˆ—ä¸ºè¾“å‡ºå˜é‡<br>test_X, test_Y &#x3D; test[:, :n_obs], test[:, -6]</p>
<hr>
<h5 id="3-æ¨¡å‹ç»“æ„ç¤ºä¾‹ï¼ˆKerasï¼‰"><a href="#3-æ¨¡å‹ç»“æ„ç¤ºä¾‹ï¼ˆKerasï¼‰" class="headerlink" title="3. æ¨¡å‹ç»“æ„ç¤ºä¾‹ï¼ˆKerasï¼‰"></a>3. æ¨¡å‹ç»“æ„ç¤ºä¾‹ï¼ˆKerasï¼‰</h5><p>Model: â€œsequentialâ€</p>
<table>
<thead>
<tr>
<th>Layer (type)</th>
<th>Output Shape</th>
<th>Param #</th>
</tr>
</thead>
<tbody><tr>
<td>LSTM (lstm)</td>
<td>(None, 30)</td>
<td>4680</td>
</tr>
<tr>
<td>Dense (FC1)</td>
<td>(None, 256)</td>
<td>7936</td>
</tr>
<tr>
<td>Activation</td>
<td>(None, 256)</td>
<td>0</td>
</tr>
<tr>
<td>Dropout</td>
<td>(None, 256)</td>
<td>0</td>
</tr>
<tr>
<td>Dense (out_layer)</td>
<td>(None, 1)</td>
<td>257</td>
</tr>
<tr>
<td><strong>Total Params</strong></td>
<td></td>
<td><strong>12873</strong></td>
</tr>
</tbody></table>
<ul>
<li>LSTMå±‚å‚æ•°è®¡ç®—å…¬å¼ï¼š</li>
</ul>
<p>Param &#x3D; 4 Ã— [(input_dim + hidden_dim) Ã— hidden_dim + hidden_dim]</p>
<p>å…¶ä¸­ï¼Œ<br>input_dim æ˜¯è¾“å…¥ç‰¹å¾ç»´åº¦ï¼Œ<br>hidden_dim æ˜¯LSTMéšè—å•å…ƒæ•°é‡ï¼ˆæœ¬ä¾‹ä¸º30ï¼‰ã€‚</p>
<hr>
<h5 id="4-LSTMç»†èƒçŠ¶æ€è®¡ç®—ç®€è¿°"><a href="#4-LSTMç»†èƒçŠ¶æ€è®¡ç®—ç®€è¿°" class="headerlink" title="4. LSTMç»†èƒçŠ¶æ€è®¡ç®—ç®€è¿°"></a>4. LSTMç»†èƒçŠ¶æ€è®¡ç®—ç®€è¿°</h5><p>ç»†èƒçŠ¶æ€æ›´æ–°ï¼š</p>
<p>$C_new &#x3D; f(z_f) * C_old + f(z_i) * g(z)$</p>
<p>éšè—çŠ¶æ€è¾“å‡ºï¼š</p>
<p>$a &#x3D; f(z_o) * h(C)$</p>
<p>å…¶ä¸­ï¼š<br>f æ˜¯sigmoidæ¿€æ´»å‡½æ•°ï¼Œ<br>g æ˜¯tanhæ¿€æ´»å‡½æ•°ï¼Œ<br>ç»´åº¦å‡ä¸º (hidden_dim,)ã€‚</p>
<hr>
<h5 id="5-é¢„æµ‹æµ‹è¯•é›†æ—¶çš„è¯´æ˜"><a href="#5-é¢„æµ‹æµ‹è¯•é›†æ—¶çš„è¯´æ˜" class="headerlink" title="5. é¢„æµ‹æµ‹è¯•é›†æ—¶çš„è¯´æ˜"></a>5. é¢„æµ‹æµ‹è¯•é›†æ—¶çš„è¯´æ˜</h5><p>è®­ç»ƒå®Œæ¨¡å‹åï¼Œé¢„æµ‹æµ‹è¯•é›†æ—¶ï¼Œéœ€ä¿è¯æµ‹è¯•é›†çš„è¾“å…¥æ ¼å¼ä¸è®­ç»ƒé›†ä¸€è‡´ï¼ŒåŒ…å«è¶³å¤Ÿçš„è¿‡å»æ—¶é—´æ­¥ä½œä¸ºè¾“å…¥ã€‚</p>
<hr>
<p>ä»¥ä¸Šä¸ºLSTMæ—¶é—´åºåˆ—é¢„æµ‹çš„å…³é”®æ­¥éª¤ä¸æ¦‚å¿µæ€»ç»“ï¼Œç»“åˆpandasæ•°æ®å¤„ç†åŠæ¨¡å‹æ­å»ºï¼Œé€‚åˆåˆå­¦è€…å¿«é€Ÿç†è§£å’Œå®è·µã€‚</p>
<h3 id="GNN-Graph-Neural-Network"><a href="#GNN-Graph-Neural-Network" class="headerlink" title="GNN(Graph Neural Network)"></a>GNN(Graph Neural Network)</h3><h4 id="NN4G-Contextual-Model"><a href="#NN4G-Contextual-Model" class="headerlink" title="NN4G (Contextual Model)"></a>NN4G (Contextual Model)</h4><h5 id="Hidden-Units-State-Variables"><a href="#Hidden-Units-State-Variables" class="headerlink" title="Hidden Units (State Variables)"></a>Hidden Units (State Variables)</h5><p>èŠ‚ç‚¹ v çš„ç¬¬ i  ä¸ªéšè—å•å…ƒï¼ˆçŠ¶æ€å˜é‡ï¼‰$x_i(v)$ é€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—ï¼š</p>
<p>$$<br>x_i(v) &#x3D; f\left( \sum_{j&#x3D;0}^L w_{ij} l_j(v) + \sum_{k&#x3D;1}^{i-1} \sum_{u \in \mathcal{N}(v)} w_{ijk}^{(u,v)} , x_k(u) \right)<br>$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$x_i(v)$ è¡¨ç¤ºèŠ‚ç‚¹ $v$ ç¬¬ $i$ ä¸ªéšè—å•å…ƒçŠ¶æ€ã€‚</li>
<li>$l_j(v)$ æ˜¯èŠ‚ç‚¹ $v$ çš„ç¬¬ $j$ ä¸ªè¾“å…¥ç‰¹å¾ã€‚</li>
<li>$w_{ij}$ æ˜¯è¾“å…¥ç‰¹å¾åˆ°éšè—å•å…ƒçš„æƒé‡ã€‚</li>
<li>$\mathcal{N}(v)$ æ˜¯èŠ‚ç‚¹ $v$ çš„é‚»å±…é›†åˆã€‚</li>
<li>$x_k(u)$ æ˜¯é‚»å±…èŠ‚ç‚¹ $u$ çš„ç¬¬ $k$ ä¸ªéšè—å•å…ƒçŠ¶æ€ã€‚</li>
<li>$w_{ijk}^{(u,v)}$ æ˜¯é‚»å±…éšè—å•å…ƒåˆ°å½“å‰éšè—å•å…ƒçš„æƒé‡ï¼Œå¸¦æœ‰é‚»å±… $u$ å’ŒèŠ‚ç‚¹ $v$ çš„æ ‡è®°ã€‚</li>
<li>$f(\cdot)$ æ˜¯æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ sigmoid æˆ– tanhï¼‰ã€‚</li>
</ul>
<h3 id="Feature-Normalizationï¼ˆç‰¹å¾å½’ä¸€åŒ–ï¼‰"><a href="#Feature-Normalizationï¼ˆç‰¹å¾å½’ä¸€åŒ–ï¼‰" class="headerlink" title="Feature Normalizationï¼ˆç‰¹å¾å½’ä¸€åŒ–ï¼‰"></a>Feature Normalizationï¼ˆç‰¹å¾å½’ä¸€åŒ–ï¼‰</h3><p>åœ¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰æˆ–ä¸€èˆ¬çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œç‰¹å¾å½’ä¸€åŒ–ï¼ˆNormalizationï¼‰åœ¨ä¸åŒé˜¶æ®µæœ‰ä¸åŒä½œç”¨ã€‚å®ƒå¯ä»¥æ˜¾è‘—æå‡è®­ç»ƒç¨³å®šæ€§ã€æ”¶æ•›é€Ÿåº¦ï¼Œå¹¶å…·å¤‡éšå¼æ­£åˆ™åŒ–çš„æ•ˆæœã€‚ä»¥ä¸‹æ˜¯å‡ ç§å¸¸è§çš„å½’ä¸€åŒ–æ–¹å¼ï¼š</p>
<h4 id="ğŸ”¹-1-è¾“å…¥ç‰¹å¾å½’ä¸€åŒ–ï¼ˆInput-Feature-Normalizationï¼‰"><a href="#ğŸ”¹-1-è¾“å…¥ç‰¹å¾å½’ä¸€åŒ–ï¼ˆInput-Feature-Normalizationï¼‰" class="headerlink" title="ğŸ”¹ 1. è¾“å…¥ç‰¹å¾å½’ä¸€åŒ–ï¼ˆInput Feature Normalizationï¼‰"></a>ğŸ”¹ 1. è¾“å…¥ç‰¹å¾å½’ä¸€åŒ–ï¼ˆInput Feature Normalizationï¼‰</h4><p>å¯¹è¾“å…¥èŠ‚ç‚¹ç‰¹å¾ $x_v$ åšå½’ä¸€åŒ–æ˜¯æ•°æ®é¢„å¤„ç†çš„ä¸€éƒ¨åˆ†ï¼Œé€šå¸¸åœ¨æ¨¡å‹è®­ç»ƒå‰æ‰§è¡Œã€‚å¸¸è§æ–¹å¼åŒ…æ‹¬ï¼š</p>
<ul>
<li><p><strong>Z-score æ ‡å‡†åŒ–</strong>ï¼š</p>
<p>$$<br>x_v^{\text{norm}} &#x3D; \frac{x_v - \mu}{\sigma}<br>$$</p>
</li>
<li><p><strong>Min-Max ç¼©æ”¾</strong>ï¼š</p>
<p>$$<br>x_v^{\text{norm}} &#x3D; \frac{x_v - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}}<br>$$</p>
</li>
</ul>
<p><strong>ä½œç”¨</strong>ï¼š</p>
<ul>
<li>ä½¿æ‰€æœ‰ç»´åº¦ç‰¹å¾å¤„äºç›¸ä¼¼æ•°å€¼èŒƒå›´</li>
<li>é˜²æ­¢ç‰¹å¾å€¼å·®å¼‚è¿‡å¤§å¯¼è‡´æ¨¡å‹è®­ç»ƒä¸ç¨³å®š</li>
<li>æé«˜æ¨¡å‹æ”¶æ•›é€Ÿåº¦</li>
</ul>
<hr>
<h4 id="ğŸ”¹-2-ä¸­é—´è¾“å‡ºå½’ä¸€åŒ–ï¼ˆå¯¹çº¿æ€§å±‚è¾“å‡º-z-åš-Normalizationï¼‰"><a href="#ğŸ”¹-2-ä¸­é—´è¾“å‡ºå½’ä¸€åŒ–ï¼ˆå¯¹çº¿æ€§å±‚è¾“å‡º-z-åš-Normalizationï¼‰" class="headerlink" title="ğŸ”¹ 2. ä¸­é—´è¾“å‡ºå½’ä¸€åŒ–ï¼ˆå¯¹çº¿æ€§å±‚è¾“å‡º $z$ åš Normalizationï¼‰"></a>ğŸ”¹ 2. ä¸­é—´è¾“å‡ºå½’ä¸€åŒ–ï¼ˆå¯¹çº¿æ€§å±‚è¾“å‡º $z$ åš Normalizationï¼‰</h4><p>åœ¨æ·±åº¦ç½‘ç»œçš„æ¯ä¸€å±‚ä¸­ï¼Œçº¿æ€§å˜æ¢çš„è¾“å‡ºï¼ˆå¦‚ $z &#x3D; Wx$ï¼‰å¯èƒ½å­˜åœ¨å‡å€¼åç§»æˆ–æ–¹å·®çˆ†ç‚¸ï¼Œå®¹æ˜“å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé€šå¸¸ä¼šå¯¹ $z$ è¿›è¡Œå½’ä¸€åŒ–ï¼š</p>
<ul>
<li><p><strong>æ ‡å‡†åŒ–å…¬å¼</strong>ï¼š</p>
<p>$$<br>\tilde{z} &#x3D; \frac{z - \mu_z}{\sigma_z}<br>$$</p>
<p>åœ¨æ­¤åŸºç¡€ä¸Šé€šå¸¸è¿˜ä¼šåŠ å…¥å¯å­¦ä¹ çš„ç¼©æ”¾ä¸åç§»å‚æ•°ï¼š</p>
<p>$$<br>\tilde{z} &#x3D; \gamma \cdot \frac{z - \mu_z}{\sigma_z} + \beta<br>$$</p>
</li>
</ul>
<hr>
<h4 id="ğŸ”¹-3-Batch-Normalizationï¼ˆBNï¼‰"><a href="#ğŸ”¹-3-Batch-Normalizationï¼ˆBNï¼‰" class="headerlink" title="ğŸ”¹ 3. Batch Normalizationï¼ˆBNï¼‰"></a>ğŸ”¹ 3. Batch Normalizationï¼ˆBNï¼‰</h4><p><strong>BatchNorm</strong> æ˜¯æœ€å¸¸ç”¨çš„ä¸­é—´å±‚å½’ä¸€åŒ–æŠ€æœ¯ï¼Œä½œç”¨äºå°æ‰¹é‡è®­ç»ƒæ ·æœ¬çš„æ¯ä¸€å±‚è¾“å‡ºã€‚</p>
<h5 id="ğŸ“Œ-è®­ç»ƒé˜¶æ®µï¼š"><a href="#ğŸ“Œ-è®­ç»ƒé˜¶æ®µï¼š" class="headerlink" title="ğŸ“Œ è®­ç»ƒé˜¶æ®µï¼š"></a>ğŸ“Œ è®­ç»ƒé˜¶æ®µï¼š</h5><p>å¯¹æ¯ä¸ª feature ç»´åº¦ $z$ï¼š</p>
<p>$$<br>\tilde{z}^{(i)} &#x3D; \frac{z^{(i)} - \mu_{\text{batch}}}{\sqrt{\sigma_{\text{batch}}^2 + \epsilon}}<br>$$</p>
<p>ç„¶åè¿›è¡Œä»¿å°„å˜æ¢ï¼š</p>
<p>$$<br>y^{(i)} &#x3D; \gamma \tilde{z}^{(i)} + \beta<br>$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$\mu_{\text{batch}}, \sigma_{\text{batch}}$ï¼šå½“å‰ batch å†…çš„å‡å€¼ä¸æ–¹å·®</li>
<li>$\gamma, \beta$ï¼šå¯å­¦ä¹ å‚æ•°</li>
<li>$\epsilon$ï¼šä¸ºé¿å…é™¤ä»¥ 0 çš„ä¸€ä¸ªå°å¸¸æ•°</li>
</ul>
<h5 id="ğŸ§®-ç»Ÿè®¡æ›´æ–°ï¼ˆç”¨äºæµ‹è¯•ï¼‰ï¼š"><a href="#ğŸ§®-ç»Ÿè®¡æ›´æ–°ï¼ˆç”¨äºæµ‹è¯•ï¼‰ï¼š" class="headerlink" title="ğŸ§® ç»Ÿè®¡æ›´æ–°ï¼ˆç”¨äºæµ‹è¯•ï¼‰ï¼š"></a>ğŸ§® ç»Ÿè®¡æ›´æ–°ï¼ˆç”¨äºæµ‹è¯•ï¼‰ï¼š</h5><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶ç»´æŠ¤æ»‘åŠ¨å¹³å‡ç»Ÿè®¡é‡ï¼š</p>
<p>$$<br>\bar{\mu} \leftarrow p \cdot \bar{\mu} + (1 - p) \cdot \mu_{\text{batch}}<br>$$</p>
<p>$$<br>\bar{\sigma}^2 \leftarrow p \cdot \bar{\sigma}^2 + (1 - p) \cdot \sigma_{\text{batch}}^2<br>$$</p>
<p>æµ‹è¯•æ—¶ä½¿ç”¨ï¼š</p>
<p>$$<br>\tilde{z}_{\text{test}} &#x3D; \frac{z - \bar{\mu}}{\sqrt{\bar{\sigma}^2 + \epsilon}}<br>$$</p>
<h5 id="âœ…-ä¼˜ç‚¹ï¼š"><a href="#âœ…-ä¼˜ç‚¹ï¼š" class="headerlink" title="âœ… ä¼˜ç‚¹ï¼š"></a>âœ… ä¼˜ç‚¹ï¼š</h5><ul>
<li>å‡å°‘å†…éƒ¨åå˜é‡åç§»ï¼ˆInternal Covariate Shiftï¼‰</li>
<li>æå‡æ”¶æ•›é€Ÿåº¦</li>
<li>åœ¨è®­ç»ƒä¸­å…·å¤‡éšå¼æ­£åˆ™åŒ–ä½œç”¨</li>
<li>å¯¹æ·±å±‚ç¥ç»ç½‘ç»œç‰¹åˆ«æœ‰æ•ˆ</li>
</ul>
<hr>
<h4 id="ğŸ”-å…¶ä»–å½’ä¸€åŒ–æ–¹æ³•ï¼ˆè¡¥å……ï¼‰"><a href="#ğŸ”-å…¶ä»–å½’ä¸€åŒ–æ–¹æ³•ï¼ˆè¡¥å……ï¼‰" class="headerlink" title="ğŸ” å…¶ä»–å½’ä¸€åŒ–æ–¹æ³•ï¼ˆè¡¥å……ï¼‰"></a>ğŸ” å…¶ä»–å½’ä¸€åŒ–æ–¹æ³•ï¼ˆè¡¥å……ï¼‰</h4><table>
<thead>
<tr>
<th>æ–¹æ³•</th>
<th>åœºæ™¯</th>
<th>æ˜¯å¦ä¾èµ– batch</th>
<th>è¯´æ˜</th>
</tr>
</thead>
<tbody><tr>
<td>LayerNorm</td>
<td>NLPã€GNNã€Transformer</td>
<td>å¦</td>
<td>å¯¹æ¯ä¸ªæ ·æœ¬å•ç‹¬å½’ä¸€åŒ–</td>
</tr>
<tr>
<td>InstanceNorm</td>
<td>å›¾åƒç”Ÿæˆ</td>
<td>å¦</td>
<td>å¯¹æ¯ä¸ªæ ·æœ¬çš„æ¯ä¸ªé€šé“å½’ä¸€åŒ–</td>
</tr>
<tr>
<td>GraphNorm</td>
<td>å›¾ç¥ç»ç½‘ç»œ</td>
<td>å¦</td>
<td>è€ƒè™‘å›¾ç»“æ„çš„ç‰¹å¾å½’ä¸€åŒ–ç­–ç•¥</td>
</tr>
</tbody></table>
<hr>
<h3 id="ğŸ“Œ-å°ç»“"><a href="#ğŸ“Œ-å°ç»“" class="headerlink" title="ğŸ“Œ å°ç»“"></a>ğŸ“Œ å°ç»“</h3><table>
<thead>
<tr>
<th>é˜¶æ®µ</th>
<th>æ–¹æ³•</th>
<th>ç›®çš„</th>
</tr>
</thead>
<tbody><tr>
<td>è¾“å…¥é˜¶æ®µ</td>
<td>Z-scoreã€Min-Max</td>
<td>æ¶ˆé™¤ä¸åŒç‰¹å¾é‡çº²å·®å¼‚</td>
</tr>
<tr>
<td>ç½‘ç»œä¸­é—´å±‚</td>
<td>BatchNormã€LayerNorm</td>
<td>ç¨³å®šè®­ç»ƒã€åŠ é€Ÿæ”¶æ•›</td>
</tr>
<tr>
<td>æµ‹è¯•é˜¶æ®µ</td>
<td>ä½¿ç”¨ EMA å¹³æ»‘ç»Ÿè®¡</td>
<td>ä¿è¯é¢„æµ‹ä¸€è‡´æ€§å’Œç¨³å®šæ€§</td>
</tr>
</tbody></table>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><p>Input -&gt; Positional Encoding -&gt; Self-attention -&gt; åŠ residual -&gt; layer norm -&gt; FCçš„feed forward network -&gt; åŠ residual -&gt; layer norm<br>Encoderæ‰€éœ€è¦åšçš„äº‹æƒ…ï¼šç»™ä¸€æ’å‘é‡è¾“å‡ºå¦å¤–ä¸€æ’å‘é‡ï¼Œè¿™ä¸ªå·¥ä½œRNNã€CNNä¹Ÿå¯ä»¥åšã€‚åœ¨Transformeré‡Œé¢ï¼Œç”¨çš„encoderæ˜¯self-attentionã€‚<br>encoderåˆ†æˆäº†å¾ˆå¤šä¸ªblockï¼Œæ¯ä¸€ä¸ªblockéƒ½æ˜¯è¾“å…¥ä¸€æ’å‘é‡ã€è¾“å‡ºä¸€æ’å‘é‡</p>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>ä¸æ˜¯æ¯ä¸€ä¸ªblockæ˜¯ä¸€ä¸ªlayerï¼Œå› ä¸ºä¸€ä¸ªblockæ˜¯å¥½å‡ ä¸ªlayerç»„åˆ<br></p>
</blockquote>
<hr>
<h5 id="è¾“å…¥å®šä¹‰"><a href="#è¾“å…¥å®šä¹‰" class="headerlink" title="è¾“å…¥å®šä¹‰"></a>è¾“å…¥å®šä¹‰</h5><p>è®¾è¾“å…¥åºåˆ—ä¸º<br>$X \in \mathbb{R}^{T \times d_{\text{model}}}$</p>
<ul>
<li>$T$ï¼šåºåˆ—é•¿åº¦  </li>
<li>$d_{\text{model}}$ï¼šæ¯ä¸ª token çš„ç‰¹å¾ç»´åº¦</li>
</ul>
<p>åŠ å…¥ä½ç½®ç¼–ç ï¼š</p>
<p>$H^{(0)} &#x3D; X + PE$</p>
<p>å…¶ä¸­ $PE \in \mathbb{R}^{T \times d_{\text{model}}}$ æ˜¯ä½ç½®ç¼–ç ã€‚</p>
<h5 id="ç¬¬-l-å±‚-Encoder-Block"><a href="#ç¬¬-l-å±‚-Encoder-Block" class="headerlink" title="ç¬¬ l å±‚ Encoder Block"></a>ç¬¬ l å±‚ Encoder Block</h5><p>æ¯ä¸€å±‚åŒ…å«ä¸¤ä¸ªå­å±‚ï¼ˆSub-layerï¼‰ï¼š</p>
<ol>
<li>å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ˆMulti-head Self-Attentionï¼‰</li>
<li>å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFeed Forward Network, FFNï¼‰</li>
</ol>
<p>æ¯ä¸€å­å±‚åé¢éƒ½æ¥æœ‰æ®‹å·®è¿æ¥å’Œ Layer Normalizationã€‚</p>
<h6 id="Multi-head-Self-Attention"><a href="#Multi-head-Self-Attention" class="headerlink" title="Multi-head Self-Attention"></a>Multi-head Self-Attention</h6><p>é¦–å…ˆè®¡ç®—Query, Key, Value:<br>$$<br>Q &#x3D; H^{(l-1)} W^Q,\quad K &#x3D; H^{(l-1)} W^K,\quad V &#x3D; H^{(l-1)} W^V<br>$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$W^Q, W^K, W^V \in \mathbb{R}^{d_{\text{model}} \times d_k}$<br>$d_model$é€šå¸¸ç­‰äºè¾“å…¥æˆ–è¾“å‡ºçš„ç‰¹å¾ç»´åº¦ </li>
<li>é€šå¸¸ $d_k &#x3D; \frac{d_{\text{model}}}{h}$ï¼Œ$h$ ä¸ºæ³¨æ„åŠ›å¤´æ•°</li>
</ul>
<p>å•ä¸ªæ³¨æ„åŠ›å¤´çš„è¾“å‡ºï¼š</p>
<p>$$<br>\text{Attention}(Q, K, V) &#x3D; \text{softmax}\left( \frac{Q K^\top}{\sqrt{d_k}} \right) V<br>$$</p>
<p>å¤šä¸ªå¤´æ‹¼æ¥ï¼š</p>
<p>$$<br>\text{MultiHead}(H) &#x3D; \text{Concat}(\text{head}_1, â€¦, \text{head}_h) W^O<br>$$</p>
<p>åŠ æ®‹å·®è¿æ¥ä¸ LayerNormï¼š</p>
<p>$$<br>\tilde{H}^{(l)} &#x3D; \text{LayerNorm}\left( H^{(l-1)} + \text{MultiHead}(H^{(l-1)}) \right)<br>$$</p>
<h6 id="å‰é¦ˆç½‘ç»œ-Feed-Forward-Network-ï¼ˆMLPï¼‰"><a href="#å‰é¦ˆç½‘ç»œ-Feed-Forward-Network-ï¼ˆMLPï¼‰" class="headerlink" title="å‰é¦ˆç½‘ç»œ(Feed Forward Network)ï¼ˆMLPï¼‰"></a>å‰é¦ˆç½‘ç»œ(Feed Forward Network)ï¼ˆMLPï¼‰</h6><p>ä½ç½®å‰é¦ˆç½‘ç»œ(Position-wise FFN)ä½œç”¨äºæ¯ä¸ªä½ç½®çš„å‘é‡ï¼š<br>$$<br>\text{FFN}(x) &#x3D; \max(0, x W_1 + b_1) W_2 + b_2<br>$$<br>å…¶ä¸­ï¼š</p>
<ul>
<li>$W_1 \in \mathbb{R}^{d_{\text{model}} \times d_{\text{ff}}}$</li>
<li>$W_2 \in \mathbb{R}^{d_{\text{ff}} \times d_{\text{model}}}$</li>
</ul>
<p>åŠ æ®‹å·®ä¸ LayerNormï¼š<br>$$<br>H^{(l)} &#x3D; \text{LayerNorm} \left( \tilde{H}^{(l)} + \text{FFN}(\tilde{H}^{(l)}) \right)<br>$$</p>
<h5 id="å †å å¤šä¸ªEncoder-Block"><a href="#å †å å¤šä¸ªEncoder-Block" class="headerlink" title="å †å å¤šä¸ªEncoder Block"></a>å †å å¤šä¸ªEncoder Block</h5><p>æ€»å…±å †å $L$å±‚Encoder:<br>$$<br>H^{(L)} &#x3D; \text{Encoder}(X) &#x3D; \text{EncoderBlock}^{(L)} \circ \cdots \circ \text{EncoderBlock}^{(1)}(X + PE)<br>$$</p>
<p>æ¯ä¸€å±‚è¾“å…¥è¾“å‡ºçš„ç»´åº¦ä¿æŒä¸º $\mathbb{R}^{T \times d_{\text{model}}}$ã€‚</p>
<h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p>decoderé¦–å…ˆè¦è¯»å–encoderçš„è¾“å‡ºï¼Œdocoderå…ˆä¼šè¾“å‡ºä¸€ä¸ªdistributionï¼Œé€‰å–å¾—åˆ†æœ€å¤§çš„å€¼ï¼ˆæ¦‚ç‡ï¼‰è¾“å‡º</p>
<p>Transformer Decoder æ¥æ”¶ä¸¤ä¸ªè¾“å…¥ï¼š</p>
<ol>
<li>ç¼–ç å™¨è¾“å‡º $H^{(L)} \in \mathbb{R}^{T_{\text{enc}} \times d_{\text{model}}}$</li>
<li>ç›®æ ‡åºåˆ—çš„å‰ç¼€ï¼ˆåœ¨è®­ç»ƒæ—¶ä¸º ground truthï¼Œæ¨ç†æ—¶ä¸ºæ¨¡å‹å†å²é¢„æµ‹ï¼‰(ä¹Ÿå°±æ˜¯å·²ç»ç”Ÿæˆçš„ç›®æ ‡åºåˆ—target sequenceå‰ç¼€çš„embeddingå‘é‡ + ä½ç½®ä¿¡æ¯) e.g., æ³•è¯­ç›®æ ‡å¥: begin Je suis Ã©tudiant<br>ç”±æ­¤å¯çŸ¥åœ¨Transformerçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œtargetåºåˆ—æ˜¯æ˜ç¡®å‚ä¸è®­ç»ƒçš„ï¼Œè¿™ä¹Ÿå«<strong>teacher forcing</strong>çš„æ–¹æ³•:</li>
</ol>
<ul>
<li>Transformerçš„Decoderè¾“å…¥æ˜¯ç›®æ ‡åºåˆ—çš„å‰ç¼€ï¼ˆå³targetçš„éƒ¨åˆ†æˆ–å…¨éƒ¨å·²çŸ¥éƒ¨åˆ†ï¼‰ï¼Œæ¨¡å‹å­¦ä¹ é¢„æµ‹ä¸‹ä¸€ä¸ªtokenã€‚</li>
<li>æ¢å¥è¯è¯´ï¼Œæ¨¡å‹â€œçœ‹åˆ°â€æ­£ç¡®çš„å†å²targetä½œä¸ºä¸Šä¸‹æ–‡æ¥è®­ç»ƒï¼Œå‡å°‘è¯¯å·®ç§¯ç´¯ã€‚</li>
</ul>
<p>Decoder è¾“å‡ºç›®æ ‡åºåˆ—çš„æ¯ä¸€ä¸ª token è¡¨ç¤ºï¼ˆæœ€ç»ˆè¾“å…¥ softmax å¾—å‡ºæ¦‚ç‡åˆ†å¸ƒï¼‰ã€‚</p>
<h5 id="ç¬¬-l-å±‚Decoder-Blockæ„æˆ"><a href="#ç¬¬-l-å±‚Decoder-Blockæ„æˆ" class="headerlink" title="ç¬¬$l$å±‚Decoder Blockæ„æˆ"></a>ç¬¬$l$å±‚Decoder Blockæ„æˆ</h5><p>æ¯ä¸€å±‚ decoder block åŒ…å«ä¸‰ä¸ªå­å±‚ï¼š</p>
<ol>
<li>Masked Multi-head Self-Attentionï¼ˆå¯¹ç›®æ ‡åºåˆ—è‡ªèº«ï¼‰</li>
<li>Multi-head Encoder-Decoder Attentionï¼ˆä½¿ç”¨ encoder è¾“å‡ºï¼‰</li>
<li>Feed Forward Networkï¼ˆFFNï¼‰</li>
</ol>
<p>æ¯ä¸€å­å±‚åå‡ä½¿ç”¨æ®‹å·®è¿æ¥å’Œ LayerNormã€‚</p>
<h6 id="Masked-Multi-head-Self-Attention-å¯¹decoderè¾“å…¥åšè‡ªæ³¨æ„"><a href="#Masked-Multi-head-Self-Attention-å¯¹decoderè¾“å…¥åšè‡ªæ³¨æ„" class="headerlink" title="Masked Multi-head Self-Attention (å¯¹decoderè¾“å…¥åšè‡ªæ³¨æ„)"></a>Masked Multi-head Self-Attention (å¯¹decoderè¾“å…¥åšè‡ªæ³¨æ„)</h6><p>é¿å…çœ‹åˆ°æœªæ¥çš„æ¶ˆæ¯ï¼Œä½¿ç”¨mask:<br>$$<br>Q^{\text{dec}} &#x3D; H_{\text{dec}}^{(l-1)} W^Q, \quad<br>K^{\text{dec}} &#x3D; H_{\text{dec}}^{(l-1)} W^K, \quad<br>V^{\text{dec}} &#x3D; H_{\text{dec}}^{(l-1)} W^V<br>$$</p>
<p>è®¡ç®— masked attentionï¼š</p>
<p>$$<br>\text{MaskedAttention}(Q, K, V) &#x3D; \text{softmax}\left( \frac{Q K^\top}{\sqrt{d_k}} + M \right) V<br>$$</p>
<ul>
<li>$M$ æ˜¯ mask çŸ©é˜µï¼Œç”¨äºé®è”½æœªæ¥çš„ token</li>
</ul>
<p>æ·»åŠ æ®‹å·®è¿æ¥ï¼š</p>
<p>$$<br>\tilde{H}<em>{\text{dec}}^{(l,1)} &#x3D; \text{LayerNorm}\left( H</em>{\text{dec}}^{(l-1)} + \text{MaskedAttention}(\cdot) \right)<br>$$</p>
<h6 id="Encoder-Decoder-Attention-æŸ¥è¯¢encoderè¾“å‡º"><a href="#Encoder-Decoder-Attention-æŸ¥è¯¢encoderè¾“å‡º" class="headerlink" title="Encoder-Decoder Attention (æŸ¥è¯¢encoderè¾“å‡º)"></a>Encoder-Decoder Attention (æŸ¥è¯¢encoderè¾“å‡º)</h6><p>$$<br>Q^{\text{dec-enc}} &#x3D; \tilde{H}<em>{\text{dec}}^{(l,1)} W^Q, \quad<br>K^{\text{enc}} &#x3D; H</em>{\text{enc}}^{(L)} W^K, \quad<br>V^{\text{enc}} &#x3D; H_{\text{enc}}^{(L)} W^V<br>$$</p>
<p>$$<br>\text{CrossAttention}(Q, K, V) &#x3D; \text{softmax}\left( \frac{Q K^\top}{\sqrt{d_k}} \right) V<br>$$</p>
<p>æ®‹å·®è¿æ¥ï¼š</p>
<p>$$<br>\tilde{H}<em>{\text{dec}}^{(l,2)} &#x3D; \text{LayerNorm}\left( \tilde{H}</em>{\text{dec}}^{(l,1)} + \text{CrossAttention}(\cdot) \right)<br>$$</p>
<h6 id="Feed-Forward-Network"><a href="#Feed-Forward-Network" class="headerlink" title="Feed Forward Network"></a>Feed Forward Network</h6><p>$$<br>H_{\text{dec}}^{(l)} &#x3D; \text{LayerNorm}\left( \tilde{H}<em>{\text{dec}}^{(l,2)} + \text{FFN}(\tilde{H}</em>{\text{dec}}^{(l,2)}) \right)<br>$$</p>
<h6 id="æœ€ç»ˆè¾“å‡º"><a href="#æœ€ç»ˆè¾“å‡º" class="headerlink" title="æœ€ç»ˆè¾“å‡º"></a>æœ€ç»ˆè¾“å‡º</h6><p>è¾“å‡ºï¼š</p>
<p>$$<br>Y &#x3D; \text{Decoder}(H_{\text{enc}}^{(L)}, Y_{\text{in}}) \in \mathbb{R}^{T_{\text{dec}} \times d_{\text{model}}}<br>$$</p>
<p>æœ€ç»ˆé€šè¿‡ä¸€ä¸ªçº¿æ€§å˜æ¢ $W_o$ å’Œ softmax æ˜ å°„ä¸ºè¯è¡¨åˆ†å¸ƒï¼š</p>
<p>$$<br>P(y_t | y_{&lt;t}, X) &#x3D; \text{softmax}(W_o H_{\text{dec}, t}^{(L)} + b_o)<br>$$</p>
<h5 id="è‡ªå›å½’-vs-éè‡ªå›å½’"><a href="#è‡ªå›å½’-vs-éè‡ªå›å½’" class="headerlink" title="è‡ªå›å½’ vs éè‡ªå›å½’"></a>è‡ªå›å½’ vs éè‡ªå›å½’</h5><h6 id="Autoregressive-Transformer-AT"><a href="#Autoregressive-Transformer-AT" class="headerlink" title="Autoregressive Transformer (AT)"></a>Autoregressive Transformer (AT)</h6><ul>
<li>Decoder æ¯ä¸€æ­¥åªæ¥æ”¶è¿‡å»çš„è¾“å‡ºï¼Œé€æ­¥ç”Ÿæˆ</li>
<li>åºåˆ—ç”Ÿæˆæ˜¯ <strong>é€æ­¥é¢„æµ‹</strong> çš„ï¼Œæ— æ³•å¹¶è¡Œ</li>
<li>ä½¿ç”¨ Masked Self-Attention é™åˆ¶ä¿¡æ¯æµæ–¹å‘</li>
</ul>
<h6 id="Non-Autoregressive-Transformer-NAT"><a href="#Non-Autoregressive-Transformer-NAT" class="headerlink" title="Non-Autoregressive Transformer (NAT)"></a>Non-Autoregressive Transformer (NAT)</h6><ul>
<li>ä¸€æ¬¡æ€§ç”Ÿæˆå…¨éƒ¨ tokenï¼Œè·³è¿‡é€æ­¥é¢„æµ‹</li>
<li>æ¨¡å‹éœ€é¢å¤– <strong>é¢„æµ‹è¾“å‡ºé•¿åº¦</strong>ï¼Œæˆ–å¼•å…¥ç‰¹æ®Šæœºåˆ¶ï¼ˆå¦‚ maskã€ç¼–è¾‘è·¯å¾„ã€latent alignmentï¼‰</li>
<li>ç¼–ç å™¨è¾“å‡ºéœ€æºå¸¦æ›´å¤šä¿¡æ¯</li>
<li>é€Ÿåº¦å¿«ï¼Œä½†ç²¾åº¦é€šå¸¸ä½äº AT</li>
</ul>
<h3 id="Vision-Transformer-ViT"><a href="#Vision-Transformer-ViT" class="headerlink" title="Vision Transformer (ViT)"></a>Vision Transformer (ViT)</h3><p>ViTå’Œä¸€èˆ¬çš„Transformerä¸åŒï¼Œä¸éœ€è¦decoderï¼Œåªéœ€è¦encoderã€‚<br>ViTå°†è¾“å…¥å›¾ç‰‡åˆ†ä¸ºå¤šä¸ªpatch(16x16),å†å°†æ¯ä¸ªpatchæŠ•å½±ä¸ºå›ºå®šé•¿åº¦çš„å‘é‡é€å…¥Transformerï¼Œåç»­encoderçš„æ“ä½œå’ŒåŸå§‹Transformerä¸­å®Œå…¨ç›¸åŒã€‚<br>å¯¹äºå›¾ç‰‡åˆ†ç±»ï¼Œå› æ­¤åœ¨è¾“å…¥åºåˆ—ä¸­åŠ å…¥ä¸€ä¸ª<strong>ç‰¹æ®Šçš„</strong>tokenï¼Œè¯¥tokenå¯¹åº”çš„è¾“å‡ºå³ä¸ºæœ€åçš„ç±»åˆ«é¢„æµ‹ã€‚</p>
<ul>
<li>patch embedding:<br>ä¾‹å¦‚è¾“å…¥å›¾ç‰‡å¤§å°ä¸º224x224ï¼Œå°†å›¾ç‰‡åˆ†ä¸ºå›ºå®šå¤§å°çš„patchï¼Œpatchå¤§å°ä¸º16x16ï¼Œåˆ™æ¯å¼ å›¾åƒä¼šç”Ÿæˆ224x224&#x2F;16x16&#x3D;196ä¸ªpatchï¼Œä¹Ÿå°±æ˜¯è¯´sequence length &#x3D; 196ï¼Œæ¯ä¸ªpatchç»´åº¦16x16x3 &#x3D; 768ã€‚å› æ­¤è¾“å…¥é€šè¿‡çº¿æ€§æŠ•å°„å±‚ä¹‹åçš„ç»´åº¦ä¾ç„¶ä¸º196x768ï¼Œå³ä¸€å…±æœ‰196ä¸ªtokenï¼Œæ¯ä¸ªtokençš„ç»´åº¦æ˜¯768ã€‚è¿™é‡Œè¿˜éœ€è¦åŠ ä¸Šä¸€ä¸ªç‰¹æ®Šå­—ç¬¦clsï¼Œå› æ­¤æœ€ç»ˆçš„ç»´åº¦æ˜¯197x768ã€‚å› æ­¤ï¼Œé€šè¿‡patch embeddingå¯ä»¥å°†visioné—®é¢˜è½¬ä¸ºä¸€ä¸ªseq2seqé—®é¢˜</li>
<li>positional encoding<br>å’Œbasic transformerä¸€æ ·,å¯ä»¥ç†è§£ä¸ºä¸ºä¸€å¼ è¡¨ï¼Œè¡¨ä¸€å…±æœ‰Nè¡Œï¼ŒNçš„å¤§å°å’Œè¾“å…¥åºåˆ—é•¿åº¦ç›¸åŒï¼Œæ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªå‘é‡ï¼Œå‘é‡çš„ç»´åº¦å’Œè¾“å…¥åºåˆ—embeddingçš„ç»´åº¦ç›¸åŒï¼ˆ768ï¼‰</li>
<li>Layer Normalization&#x2F;multi-head attention&#x2F;Layer Normalization<br>LNè¾“å‡ºç»´åº¦ä¾ç„¶æ˜¯197x768ã€‚å¤šå¤´è‡ªæ³¨æ„åŠ›æ—¶ï¼Œå…ˆå°†è¾“å…¥æ˜ å°„åˆ°qï¼Œkï¼Œvï¼Œå¦‚æœåªæœ‰ä¸€ä¸ªå¤´ï¼Œqkvçš„ç»´åº¦éƒ½æ˜¯197x768ï¼Œå¦‚æœæœ‰12ä¸ªå¤´ï¼ˆ768&#x2F;12&#x3D;64ï¼‰ï¼Œåˆ™qkvçš„ç»´åº¦æ˜¯197x64ï¼Œä¸€å…±æœ‰12ç»„qkvï¼Œæœ€åå†å°†12ç»„qkvçš„è¾“å‡ºæ‹¼æ¥èµ·æ¥ï¼Œè¾“å‡ºç»´åº¦æ˜¯197x768ï¼Œç„¶ååœ¨è¿‡ä¸€å±‚LNï¼Œç»´åº¦ä¾ç„¶æ˜¯197x768</li>
<li>MLPï¼ˆFeed Forward Network FFNï¼‰<br>å°†ç»´åº¦æ”¾å¤§å†ç¼©å°å›å»ï¼Œ197x768æ”¾å¤§ä¸º197x3072ï¼Œå†ç¼©å°å˜ä¸º197x768</li>
</ul>
<p>ä¸€ä¸ªblockä¹‹åç»´åº¦ä¾ç„¶å’Œè¾“å…¥ç›¸åŒï¼Œéƒ½æ˜¯197x768ï¼Œå› æ­¤å¯ä»¥å †å å¤šä¸ªblockã€‚æœ€åä¼šå°†ç‰¹æ®Šå­—ç¬¦clså¯¹åº”çš„è¾“å‡º<br>ä½œä¸ºencoderçš„æœ€ç»ˆè¾“å‡º ï¼Œä»£è¡¨æœ€ç»ˆçš„image presentationï¼ˆå¦ä¸€ç§åšæ³•æ˜¯ä¸åŠ clså­—ç¬¦ï¼Œå¯¹æ‰€æœ‰çš„tokensçš„è¾“å‡ºåšä¸€ä¸ªå¹³å‡ï¼‰</p>
<h3 id="Generative-Adversarial-Networks-GAN"><a href="#Generative-Adversarial-Networks-GAN" class="headerlink" title="Generative Adversarial Networks (GAN)"></a>Generative Adversarial Networks (GAN)</h3><p>Generative Adversarial Networks (GANs) are a class of deep learning models in which <strong>two networks compete</strong>: a <strong>generator</strong> tries to produce realistic data, and a <strong>discriminator</strong> tries to distinguish between real and fake data. This adversarial setup drives both networks to improve.</p>
<h4 id="Key-Components"><a href="#Key-Components" class="headerlink" title="Key Components"></a>Key Components</h4><h5 id="1-Generator-G"><a href="#1-Generator-G" class="headerlink" title="1. Generator (G)"></a>1. Generator (G)</h5><ul>
<li><strong>Input</strong>: random noise vector <code>z</code> (e.g., 100-dimensional Gaussian)</li>
<li><strong>Output</strong>: fake data (e.g., an image)</li>
<li><strong>Goal</strong>: generate samples that look like real data and <strong>fool the discriminator</strong></li>
</ul>
<h5 id="2-Discriminator-D"><a href="#2-Discriminator-D" class="headerlink" title="2. Discriminator (D)"></a>2. Discriminator (D)</h5><ul>
<li><strong>Input</strong>: real or generated data</li>
<li><strong>Output</strong>: a probability (0 &#x3D; fake, 1 &#x3D; real)</li>
<li><strong>Goal</strong>: correctly distinguish real data from generated (fake) data</li>
</ul>
<h4 id="Overall-Objective"><a href="#Overall-Objective" class="headerlink" title="Overall Objective"></a>Overall Objective</h4><p>The two networks play a <strong>minimax game</strong><br>$$<br>\min_G \max_D V(D, G) &#x3D; \mathbb{E}<em>{x \sim p</em>{\text{data}}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]<br>$$</p>
<ul>
<li>Discriminator <code>D</code> tries to <strong>maximize</strong> the ability to classify real vs fake.</li>
<li>Generator <code>G</code> tries to <strong>minimize</strong> the ability of <code>D</code> to detect its fakes.</li>
</ul>
<h4 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h4><h5 id="Step-1-Fix-Generator-Train-Discriminator"><a href="#Step-1-Fix-Generator-Train-Discriminator" class="headerlink" title="Step 1: Fix Generator, Train Discriminator"></a>Step 1: Fix Generator, Train Discriminator</h5><p><strong>Goal</strong>: Teach <code>D</code> to distinguish real and fake data</p>
<ol>
<li>Sample a batch of real data <code>x_real</code> from the dataset.</li>
<li>Sample random noise <code>z</code>, and generate fake data <code>x_fake = G(z)</code>.</li>
<li>Compute discriminator outputs:<ul>
<li><code>D(x_real)</code> â†’ should be close to 1</li>
<li><code>D(G(z))</code> â†’ should be close to 0</li>
</ul>
</li>
<li>Compute discriminator loss:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L_D = -[ \log D(x_&#123;\text&#123;real&#125;&#125;) + \log(1 - D(G(z))) ]</span><br></pre></td></tr></table></figure>
<p>ç”¨GANåŸå§‹è®ºæ–‡ä¸­åˆ¤åˆ«å™¨çš„ç›®æ ‡å‡½æ•°è¡¨è¾¾çš„æ˜¯åŒä¸€ä¸ªæ„æ€ï¼Œåªæ˜¯æ¢äº†è§†è§’ï¼š<br>$$<br>\mathbb{E}<em>{x \sim P</em>{\text{data}}}[\log D(x)] + \mathbb{E}_{xâ€™ \sim P_g}[\log(1 - D(xâ€™))]<br>$$</p>
<ul>
<li>D(x) is the discriminatorâ€™s estimated probability that x is real</li>
<li>G(z) maps a noise vector z to a generated sample xâ€™ &#x3D; G(z)</li>
<li>$P_{data}$æ˜¯real imageé›†ï¼Œä¹Ÿæ˜¯éšæœºå˜é‡ï¼Œ$P_g$æ˜¯ç»è¿‡generatoråäº§ç”Ÿçš„æ•°æ®é›†ã€‚</li>
</ul>
<ol start="5">
<li>Update only <strong>Dâ€™s parameters</strong> (freeze G).</li>
</ol>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>Assuming an optimal discriminator $D^<em>(x) &#x3D; \frac{P_{\text{data}}(x)}{P_{\text{data}}(x) + P_g(x)}$, plugging this into the value function yields:<br><br>$V(D^</em>, G) &#x3D; -\log(4) + 2 \cdot D_{JS}(P_{\text{data}} | P_g)$<br><br>This means <strong>minimizing $V(D^*, G)$ is equivalent to minimizing JS divergence</strong>. Hence, improving the generator means reducing<br> divergence between the two distributions.<br></p>
</blockquote>
<hr>
<h6 id="Step-2-Fix-Discriminator-Train-Generator"><a href="#Step-2-Fix-Discriminator-Train-Generator" class="headerlink" title="Step 2: Fix Discriminator, Train Generator"></a>Step 2: Fix Discriminator, Train Generator</h6><p><strong>Goal</strong>: Improve <code>G</code> so that <code>D</code> canâ€™t tell its output is fake</p>
<ol>
<li>Sample new random noise <code>z</code></li>
<li>Generate fake data <code>x_fake = G(z)</code></li>
<li>Compute discriminator prediction <code>D(G(z))</code></li>
<li>Generator loss (trying to <strong>maximize</strong> Dâ€™s confidence that fakes are real):</li>
</ol>
<p>$$<br>L_G &#x3D; -\log D(G(z))<br>$$</p>
<ol start="5">
<li>Update only <strong>Gâ€™s parameters</strong> (freeze D)</li>
</ol>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>å¯ä»¥æŠŠGeneratorå’ŒDiscriminatoråˆæˆä¸€ä¸ªlarge networkæ¥çœ‹å¾…<br><br>ä¾‹å¦‚Genratoræœ‰5å±‚ç¥ç»ç½‘ç»œï¼ŒDiscriminatoræœ‰5å±‚ç¥ç»ç½‘ç»œï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¸€å…±è¦è®­ç»ƒçš„å°±æ˜¯10å±‚ç¥ç»ç½‘ç»œ<br></p>
</blockquote>
<hr>
<h3 id="Self-Supervised"><a href="#Self-Supervised" class="headerlink" title="Self-Supervised"></a>Self-Supervised</h3><p>Self-supervised learningï¼ˆè‡ªç›‘ç£å­¦ä¹ ï¼‰æ˜¯ä¸€ç§æ— éœ€äººå·¥æ ‡æ³¨æ ‡ç­¾çš„è®­ç»ƒæ–¹æ³•ã€‚å®ƒä»<strong>æ•°æ®æœ¬èº«æ„é€ è®­ç»ƒä¿¡å·</strong>ï¼Œæœ¬è´¨ä¸Šæ˜¯ç›‘ç£å­¦ä¹ ï¼Œä½†æ ‡ç­¾æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ã€‚</p>
<h4 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h4><p>BERTï¼ˆBidirectional Encoder Representations from Transformersï¼‰æ˜¯ Google æå‡ºçš„è¯­è¨€æ¨¡å‹ï¼Œå®ƒåŸºäº Transformer ç¼–ç å™¨ç»“æ„ï¼Œåˆ©ç”¨åŒå‘ä¸Šä¸‹æ–‡ä¿¡æ¯å¯¹æ–‡æœ¬è¿›è¡Œæ·±åº¦ç†è§£ã€‚BERT åœ¨å¤šä¸ªè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸Šå®ç°äº† SOTAï¼ˆstate-of-the-artï¼‰æ€§èƒ½ã€‚<br>BERT çš„è®­ç»ƒä¸éœ€è¦äººå·¥æ ‡æ³¨æ•°æ®ï¼Œè€Œæ˜¯é€šè¿‡ä¸¤ç§ä»»åŠ¡<strong>è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾</strong>ï¼š</p>
<h5 id="Masked-Language-Modeling-MLM"><a href="#Masked-Language-Modeling-MLM" class="headerlink" title="Masked Language Modeling (MLM)"></a>Masked Language Modeling (MLM)</h5><ul>
<li>åŸå§‹å¥å­ï¼š<code>I love spicy food</code></li>
<li>é®ç›–æ„é€ ï¼š<code>I love [MASK] food</code></li>
<li>æ¨¡å‹ç›®æ ‡ï¼šé¢„æµ‹ <code>[MASK]</code> æ˜¯ <code>spicy</code></li>
</ul>
<p><strong>æ ‡ç­¾ spicy æ˜¯ä»åŸå§‹å¥å­è‡ªåŠ¨æå–çš„ï¼Œè€Œä¸æ˜¯äººå·¥å†™å…¥ã€‚</strong></p>
<p>è¿™å°±æ˜¯è‡ªç›‘ç£çš„å…³é”®ç‚¹ï¼š<strong>æ ‡ç­¾è‡ªåŠ¨æ„é€ ã€‚</strong></p>
<h5 id="Next-Sentence-Prediction-NSP"><a href="#Next-Sentence-Prediction-NSP" class="headerlink" title="Next Sentence Prediction (NSP)"></a>Next Sentence Prediction (NSP)</h5><ul>
<li>ç»™å®šå¥å­ A å’Œå¥å­ Bï¼š<ul>
<li>æœ‰ 50% æƒ…å†µï¼šB æ˜¯ A çš„ä¸‹ä¸€å¥ï¼ˆçœŸå®ï¼‰</li>
<li>æœ‰ 50% æƒ…å†µï¼šB æ˜¯éšæœºå¥å­ï¼ˆéçœŸå®ï¼‰</li>
</ul>
</li>
<li>æ¨¡å‹ç›®æ ‡ï¼šé¢„æµ‹ B æ˜¯å¦æ˜¯ A çš„ä¸‹ä¸€å¥</li>
</ul>
<p><strong>è¿™åŒæ ·ä¸éœ€è¦äººå·¥æ ‡æ³¨ï¼ŒBERT ä»è¯­æ–™åº“ä¸­è‡ªåŠ¨é‡‡æ ·å¥å­æ„é€ æ ‡ç­¾ã€‚</strong></p>
<h5 id="BERTçš„è®­ç»ƒæµç¨‹"><a href="#BERTçš„è®­ç»ƒæµç¨‹" class="headerlink" title="BERTçš„è®­ç»ƒæµç¨‹"></a>BERTçš„è®­ç»ƒæµç¨‹</h5><ol>
<li><strong>è¾“å…¥æ„é€ </strong>ï¼š<ul>
<li>è¾“å…¥å¥å­å¯¹ + Token Embeddings + Segment Embeddings + Positional Embeddings</li>
</ul>
</li>
<li><strong>é€šè¿‡å¤šå±‚ Transformer Encoder å¤„ç†</strong></li>
<li><strong>MLM é¢„æµ‹é®ç›–çš„è¯ï¼ŒNSP åˆ¤æ–­å¥å­é¡ºåº</strong></li>
</ol>
<h5 id="æ€»ç»“-1"><a href="#æ€»ç»“-1" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h5><ul>
<li>BERT ä½¿ç”¨äº†è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•è®­ç»ƒï¼Œæ— éœ€äººå·¥æ ‡ç­¾</li>
<li>è™½ç„¶å®ƒæ˜¯ä¸€ä¸ªç›‘ç£å­¦ä¹ é—®é¢˜ï¼ˆæœ‰è¾“å…¥å’Œç›®æ ‡ï¼‰ï¼Œä½†è¿™äº›ç›®æ ‡æ˜¯ä»æ•°æ®æœ¬èº«è‡ªåŠ¨ç”Ÿæˆçš„ã€‚</li>
<li>è‡ªç›‘ç£å­¦ä¹ è®©æ¨¡å‹èƒ½åˆ©ç”¨å¤§è§„æ¨¡æœªæ ‡æ³¨è¯­æ–™ï¼Œæå‡é¢„è®­ç»ƒæ•ˆæœã€‚</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/06/15/C++/" rel="prev" title="C++">
      <i class="fa fa-chevron-left"></i> C++
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/06/17/PyTorch/" rel="next" title="PyTorch">
      PyTorch <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-Concept"><span class="nav-number">1.</span> <span class="nav-text">Basic Concept</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-Model"><span class="nav-number">1.1.</span> <span class="nav-text">Linear Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Define-function-with-unknown-parameters"><span class="nav-number">1.1.1.</span> <span class="nav-text">Define function with unknown parameters</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Define-Loss-from-Training-Data"><span class="nav-number">1.1.2.</span> <span class="nav-text">Define Loss from Training Data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Optimization"><span class="nav-number">1.1.3.</span> <span class="nav-text">Optimization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sophisticated-Models"><span class="nav-number">1.2.</span> <span class="nav-text">Sophisticated Models</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sigmoid-function%EF%BC%88logistic-regression%EF%BC%89"><span class="nav-number">1.2.1.</span> <span class="nav-text">Sigmoid functionï¼ˆlogistic regressionï¼‰</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-Quadratic-and-Higher-Order-Terms"><span class="nav-number">1.3.</span> <span class="nav-text">Use Quadratic and Higher-Order Terms</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Overfitting-Risk"><span class="nav-number">1.3.1.</span> <span class="nav-text">Overfitting Risk</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Rugularization-to-Prevent-Overfitting"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">Rugularization to Prevent Overfitting</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%97%B6%E5%A6%82%E4%BD%95%E5%8A%A0%E4%B8%8A%E6%AD%A3%E5%88%99%E5%8C%96%E7%9B%B8"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">è®­ç»ƒæ—¶å¦‚ä½•åŠ ä¸Šæ­£åˆ™åŒ–ç›¸</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Dropout-Randomly-Dropping-Neurons"><span class="nav-number">1.3.1.3.</span> <span class="nav-text">Dropout: Randomly Dropping Neurons</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PyTorch-CNN-%E4%BA%8C%E5%88%86%E7%B1%BB%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.4.</span> <span class="nav-text">PyTorch CNN äºŒåˆ†ç±»ç¤ºä¾‹</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A2%84%E5%A4%84%E7%90%86transform"><span class="nav-number">1.4.1.</span> <span class="nav-text">é¢„å¤„ç†transform</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89Dataset"><span class="nav-number">1.4.2.</span> <span class="nav-text">è‡ªå®šä¹‰Dataset</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%80%E5%8D%95CNN%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.4.3.</span> <span class="nav-text">ç®€å•CNNæ¨¡å‹</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">è¾“å…¥æ•°æ®æ ¼å¼</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">1.4.3.2.</span> <span class="nav-text">æ¨¡å‹ç»“æ„</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%92%8C%E6%B1%A0%E5%8C%96%E5%B1%82%E6%B5%81%E7%A8%8B"><span class="nav-number">1.4.3.3.</span> <span class="nav-text">å·ç§¯å±‚å’Œæ± åŒ–å±‚æµç¨‹</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E6%B5%81%E7%A8%8B%E3%80%82"><span class="nav-number">1.4.3.4.</span> <span class="nav-text">å…¨è¿æ¥å±‚æµç¨‹ã€‚</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E5%92%8C%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.4.4.</span> <span class="nav-text">å‡†å¤‡æ•°æ®å’Œæ¨¡å‹</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#train-validate-test%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">1.4.4.1.</span> <span class="nav-text">train,validate,testæ•°æ®é›†çš„åŒºåˆ«</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#train-validate-test%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86"><span class="nav-number">1.4.4.2.</span> <span class="nav-text">train,validate,testæ•°æ®é›†çš„åˆ’åˆ†</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E5%BE%AA%E7%8E%AF"><span class="nav-number">1.4.5.</span> <span class="nav-text">è®­ç»ƒå¾ªç¯</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN-ResNet-Residual-Network"><span class="nav-number">1.5.</span> <span class="nav-text">CNN + ResNet (Residual Network)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.5.1.</span> <span class="nav-text">ç¤ºä¾‹</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%86%A8%E8%83%80%E5%8D%B7%E7%A7%AF%EF%BC%88Dilated-Convolution%EF%BC%89"><span class="nav-number">1.6.</span> <span class="nav-text">è†¨èƒ€å·ç§¯ï¼ˆDilated Convolutionï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%AC%E5%BC%8F"><span class="nav-number">1.6.1.</span> <span class="nav-text">å…¬å¼</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Classification"><span class="nav-number">1.7.</span> <span class="nav-text">Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sigmoid%EF%BC%88%E4%BA%8C%E5%88%86%E7%B1%BB%EF%BC%89"><span class="nav-number">1.7.1.</span> <span class="nav-text">Sigmoidï¼ˆäºŒåˆ†ç±»ï¼‰</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Softmax%EF%BC%88%E5%A4%9A%E5%88%86%E7%B1%BB%EF%BC%89"><span class="nav-number">1.7.2.</span> <span class="nav-text">Softmaxï¼ˆå¤šåˆ†ç±»ï¼‰</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Summary"><span class="nav-number">1.8.</span> <span class="nav-text">Summary</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Linear-Regression-vs-Sigmoid-Regression"><span class="nav-number">1.8.1.</span> <span class="nav-text">Linear Regression vs Sigmoid Regression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MSE-vs-Binary-Cross-Entropy"><span class="nav-number">1.8.2.</span> <span class="nav-text">MSE vs Binary Cross-Entropy</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Support-Vector-Machine"><span class="nav-number">1.9.</span> <span class="nav-text">Support Vector Machine</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Linear-Model-1"><span class="nav-number">1.9.1.</span> <span class="nav-text">Linear Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loss-Function"><span class="nav-number">1.9.2.</span> <span class="nav-text">Loss Function</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L-w-b-frac-1-2-w-2-C-sum-n-1-N-max-0-1-y-n-w-T-x-n-b"><span class="nav-number">2.</span> <span class="nav-text">$$L(w,b) &#x3D; \frac{1}{2} |w|^2 + C \sum_{n&#x3D;1}^N \max(0,, 1 - y_n (w^T x_n + b)).$$</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Optimization-Gradient-Descent"><span class="nav-number">2.0.1.</span> <span class="nav-text">Optimization (Gradient Descent)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88Naive-Bayes%EF%BC%89"><span class="nav-number">2.1.</span> <span class="nav-text">æœ´ç´ è´å¶æ–¯ï¼ˆNaive Bayesï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E3%80%82"><span class="nav-number">2.1.1.</span> <span class="nav-text">æ¡ä»¶æ¦‚ç‡ã€‚</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E6%A6%82%E7%8E%87"><span class="nav-number">2.1.2.</span> <span class="nav-text">å…¨æ¦‚ç‡</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E6%96%AD"><span class="nav-number">2.1.3.</span> <span class="nav-text">è´å¶æ–¯æ¨æ–­</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BE%E4%BE%8B%E8%AF%B4%E6%98%8E"><span class="nav-number">2.1.4.</span> <span class="nav-text">ä¸¾ä¾‹è¯´æ˜</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="nav-number">2.1.5.</span> <span class="nav-text">æœ€å¤§ä¼¼ç„¶ä¼°è®¡</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%EF%BC%88MLE%EF%BC%89%E5%8F%8A-GaussianNB-%E7%A4%BA%E4%BE%8B"><span class="nav-number">2.1.6.</span> <span class="nav-text">æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰åŠ GaussianNB ç¤ºä¾‹</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%AD%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E8%AE%A1%E7%AE%97%EF%BC%88%E4%BB%A5%E9%AB%98%E6%96%AF%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%BA%E4%BE%8B%EF%BC%89"><span class="nav-number">2.1.7.</span> <span class="nav-text">æœ´ç´ è´å¶æ–¯ä¸­åéªŒæ¦‚ç‡è®¡ç®—ï¼ˆä»¥é«˜æ–¯æœ´ç´ è´å¶æ–¯ä¸ºä¾‹ï¼‰</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Discriminative-Model-vs-Generative-Model"><span class="nav-number">2.2.</span> <span class="nav-text">Discriminative Model vs Generative Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%AE%9A%E4%B9%89"><span class="nav-number">2.2.1.</span> <span class="nav-text">åŸºæœ¬å®šä¹‰</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%AC%E5%BC%8F%E5%AF%B9%E6%AF%94"><span class="nav-number">2.2.2.</span> <span class="nav-text">å…¬å¼å¯¹æ¯”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">2.2.3.</span> <span class="nav-text">ä¼˜ç¼ºç‚¹</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E7%A4%BA%E4%BE%8B"><span class="nav-number">2.2.4.</span> <span class="nav-text">å¸¸è§ç¤ºä¾‹</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Optimization-1"><span class="nav-number">2.3.</span> <span class="nav-text">Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Hessian%E5%88%86%E6%9E%90Saddle-Point%E5%92%8CLocal-Minimal"><span class="nav-number">2.3.1.</span> <span class="nav-text">ä½¿ç”¨Hessianåˆ†æSaddle Pointå’ŒLocal Minimal</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Adaptive-Learning-Rate"><span class="nav-number">2.3.2.</span> <span class="nav-text">Adaptive Learning Rate</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Root-Mean-Square"><span class="nav-number">2.3.2.1.</span> <span class="nav-text">Root Mean Square</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RMSProp-Root-Mean-Square-Propagation"><span class="nav-number">2.3.2.2.</span> <span class="nav-text">RMSProp (Root Mean Square Propagation)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9B%B4%E8%A7%89%E7%90%86%E8%A7%A3%EF%BC%9A"><span class="nav-number">2.3.2.3.</span> <span class="nav-text">ç›´è§‰ç†è§£ï¼š</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94"><span class="nav-number">2.3.3.</span> <span class="nav-text">æ€»ç»“å¯¹æ¯”</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Learning-Rate-Scheduling"><span class="nav-number">2.3.3.1.</span> <span class="nav-text">Learning Rate Scheduling</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Batch-%E5%92%8C-Momentum%E7%AE%80%E8%A6%81%E8%AF%B4%E6%98%8E"><span class="nav-number">2.3.4.</span> <span class="nav-text">Batch å’Œ Momentumç®€è¦è¯´æ˜</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Batch%EF%BC%88%E5%B0%8F%E6%89%B9%E9%87%8F%EF%BC%89"><span class="nav-number">2.3.4.1.</span> <span class="nav-text">Batchï¼ˆå°æ‰¹é‡ï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BD%9C%E7%94%A8"><span class="nav-number">2.3.4.1.1.</span> <span class="nav-text">ä½œç”¨</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%9B%B4%E8%A7%89%EF%BC%9A"><span class="nav-number">2.3.4.1.2.</span> <span class="nav-text">ç›´è§‰ï¼š</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Momentum%EF%BC%88%E5%8A%A8%E9%87%8F%EF%BC%89"><span class="nav-number">2.3.4.2.</span> <span class="nav-text">Momentumï¼ˆåŠ¨é‡ï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BD%9C%E7%94%A8%EF%BC%9A"><span class="nav-number">2.3.4.2.1.</span> <span class="nav-text">ä½œç”¨ï¼š</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%9B%B4%E8%A7%89%EF%BC%9A-1"><span class="nav-number">2.3.4.2.2.</span> <span class="nav-text">ç›´è§‰ï¼š</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">2.3.4.3.</span> <span class="nav-text">æ€»ç»“</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Self-attention"><span class="nav-number">2.4.</span> <span class="nav-text">Self-attention</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Basic-Concept-1"><span class="nav-number">2.4.1.</span> <span class="nav-text">Basic Concept</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E8%AE%A1%E7%AE%97"><span class="nav-number">2.4.2.</span> <span class="nav-text">å‘é‡è®¡ç®—</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%89%93%E5%88%86%E6%9C%BA%E5%88%B6"><span class="nav-number">2.4.3.</span> <span class="nav-text">æ³¨æ„åŠ›æ‰“åˆ†æœºåˆ¶</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A0%E6%9D%83%E6%B1%82%E5%92%8C%E5%BE%97%E5%88%B0%E8%BE%93%E5%87%BA"><span class="nav-number">2.4.4.</span> <span class="nav-text">åŠ æƒæ±‚å’Œå¾—åˆ°è¾“å‡º</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%B6%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%92%8C%E7%A9%BA%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="nav-number">2.4.5.</span> <span class="nav-text">æ—¶é—´æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93%E6%B5%81%E7%A8%8B%EF%BC%9A"><span class="nav-number">2.4.6.</span> <span class="nav-text">æ€»ç»“æµç¨‹ï¼š</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%B4%E6%98%8E"><span class="nav-number">2.4.7.</span> <span class="nav-text">è¯´æ˜</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Local-Attention"><span class="nav-number">2.4.8.</span> <span class="nav-text">Local Attention</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Pros"><span class="nav-number">2.4.8.1.</span> <span class="nav-text">Pros:</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Global-Attention"><span class="nav-number">2.4.9.</span> <span class="nav-text">Global Attention</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Pros-1"><span class="nav-number">2.4.9.1.</span> <span class="nav-text">Pros:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Cons"><span class="nav-number">2.4.9.2.</span> <span class="nav-text">Cons:</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Clustering-based-Attention"><span class="nav-number">2.4.10.</span> <span class="nav-text">Clustering-based Attention</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RNN-Recurrent-Neural-Network"><span class="nav-number">2.5.</span> <span class="nav-text">RNN (Recurrent Neural Network)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Long-Short-Term-Memory-LSTM-Cell-Explanation"><span class="nav-number">2.5.1.</span> <span class="nav-text">Long Short-Term Memory (LSTM) Cell Explanation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Overview"><span class="nav-number">2.5.2.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LSTM-%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E7%A4%BA%E4%BE%8B"><span class="nav-number">2.5.3.</span> <span class="nav-text">LSTM æ•°å€¼è®¡ç®—ç¤ºä¾‹</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F"><span class="nav-number">2.5.3.1.</span> <span class="nav-text">å…³é”®è®¡ç®—å…¬å¼</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LSTM%E7%9A%84%E6%A8%A1%E5%9D%97%E8%AF%B4%E6%98%8E%E4%BB%A5%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">2.5.4.</span> <span class="nav-text">LSTMçš„æ¨¡å—è¯´æ˜ä»¥åŠåº”ç”¨åœºæ™¯</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BE%93%E5%85%A5%E6%A0%BC%E5%BC%8F"><span class="nav-number">2.5.5.</span> <span class="nav-text">è¾“å…¥æ ¼å¼</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LSTM%E5%8F%82%E6%95%B0%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F"><span class="nav-number">2.5.6.</span> <span class="nav-text">LSTMå‚æ•°è®¡ç®—å…¬å¼</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B-1"><span class="nav-number">2.5.7.</span> <span class="nav-text">ç¤ºä¾‹</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%88pandas%E5%9F%BA%E7%A1%80%EF%BC%89"><span class="nav-number">2.5.7.1.</span> <span class="nav-text">1. æ•°æ®é¢„å¤„ç†ï¼ˆpandasåŸºç¡€ï¼‰</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2%E4%B8%8E%E5%87%86%E5%A4%87"><span class="nav-number">2.5.7.2.</span> <span class="nav-text">2. æ•°æ®åˆ†å‰²ä¸å‡†å¤‡</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E7%A4%BA%E4%BE%8B%EF%BC%88Keras%EF%BC%89"><span class="nav-number">2.5.7.3.</span> <span class="nav-text">3. æ¨¡å‹ç»“æ„ç¤ºä¾‹ï¼ˆKerasï¼‰</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-LSTM%E7%BB%86%E8%83%9E%E7%8A%B6%E6%80%81%E8%AE%A1%E7%AE%97%E7%AE%80%E8%BF%B0"><span class="nav-number">2.5.7.4.</span> <span class="nav-text">4. LSTMç»†èƒçŠ¶æ€è®¡ç®—ç®€è¿°</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-%E9%A2%84%E6%B5%8B%E6%B5%8B%E8%AF%95%E9%9B%86%E6%97%B6%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="nav-number">2.5.7.5.</span> <span class="nav-text">5. é¢„æµ‹æµ‹è¯•é›†æ—¶çš„è¯´æ˜</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GNN-Graph-Neural-Network"><span class="nav-number">2.6.</span> <span class="nav-text">GNN(Graph Neural Network)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#NN4G-Contextual-Model"><span class="nav-number">2.6.1.</span> <span class="nav-text">NN4G (Contextual Model)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Hidden-Units-State-Variables"><span class="nav-number">2.6.1.1.</span> <span class="nav-text">Hidden Units (State Variables)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Normalization%EF%BC%88%E7%89%B9%E5%BE%81%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%89"><span class="nav-number">2.7.</span> <span class="nav-text">Feature Normalizationï¼ˆç‰¹å¾å½’ä¸€åŒ–ï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9F%94%B9-1-%E8%BE%93%E5%85%A5%E7%89%B9%E5%BE%81%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%88Input-Feature-Normalization%EF%BC%89"><span class="nav-number">2.7.1.</span> <span class="nav-text">ğŸ”¹ 1. è¾“å…¥ç‰¹å¾å½’ä¸€åŒ–ï¼ˆInput Feature Normalizationï¼‰</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9F%94%B9-2-%E4%B8%AD%E9%97%B4%E8%BE%93%E5%87%BA%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%88%E5%AF%B9%E7%BA%BF%E6%80%A7%E5%B1%82%E8%BE%93%E5%87%BA-z-%E5%81%9A-Normalization%EF%BC%89"><span class="nav-number">2.7.2.</span> <span class="nav-text">ğŸ”¹ 2. ä¸­é—´è¾“å‡ºå½’ä¸€åŒ–ï¼ˆå¯¹çº¿æ€§å±‚è¾“å‡º $z$ åš Normalizationï¼‰</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9F%94%B9-3-Batch-Normalization%EF%BC%88BN%EF%BC%89"><span class="nav-number">2.7.3.</span> <span class="nav-text">ğŸ”¹ 3. Batch Normalizationï¼ˆBNï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%F0%9F%93%8C-%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%EF%BC%9A"><span class="nav-number">2.7.3.1.</span> <span class="nav-text">ğŸ“Œ è®­ç»ƒé˜¶æ®µï¼š</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%F0%9F%A7%AE-%E7%BB%9F%E8%AE%A1%E6%9B%B4%E6%96%B0%EF%BC%88%E7%94%A8%E4%BA%8E%E6%B5%8B%E8%AF%95%EF%BC%89%EF%BC%9A"><span class="nav-number">2.7.3.2.</span> <span class="nav-text">ğŸ§® ç»Ÿè®¡æ›´æ–°ï¼ˆç”¨äºæµ‹è¯•ï¼‰ï¼š</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E2%9C%85-%E4%BC%98%E7%82%B9%EF%BC%9A"><span class="nav-number">2.7.3.3.</span> <span class="nav-text">âœ… ä¼˜ç‚¹ï¼š</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9F%94%8D-%E5%85%B6%E4%BB%96%E5%BD%92%E4%B8%80%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%88%E8%A1%A5%E5%85%85%EF%BC%89"><span class="nav-number">2.7.4.</span> <span class="nav-text">ğŸ” å…¶ä»–å½’ä¸€åŒ–æ–¹æ³•ï¼ˆè¡¥å……ï¼‰</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%F0%9F%93%8C-%E5%B0%8F%E7%BB%93"><span class="nav-number">2.8.</span> <span class="nav-text">ğŸ“Œ å°ç»“</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Transformer"><span class="nav-number">2.9.</span> <span class="nav-text">Transformer</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Encoder"><span class="nav-number">2.9.1.</span> <span class="nav-text">Encoder</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BE%93%E5%85%A5%E5%AE%9A%E4%B9%89"><span class="nav-number">2.9.1.1.</span> <span class="nav-text">è¾“å…¥å®šä¹‰</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC-l-%E5%B1%82-Encoder-Block"><span class="nav-number">2.9.1.2.</span> <span class="nav-text">ç¬¬ l å±‚ Encoder Block</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Multi-head-Self-Attention"><span class="nav-number">2.9.1.2.1.</span> <span class="nav-text">Multi-head Self-Attention</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C-Feed-Forward-Network-%EF%BC%88MLP%EF%BC%89"><span class="nav-number">2.9.1.2.2.</span> <span class="nav-text">å‰é¦ˆç½‘ç»œ(Feed Forward Network)ï¼ˆMLPï¼‰</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A0%86%E5%8F%A0%E5%A4%9A%E4%B8%AAEncoder-Block"><span class="nav-number">2.9.1.3.</span> <span class="nav-text">å †å å¤šä¸ªEncoder Block</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Decoder"><span class="nav-number">2.9.2.</span> <span class="nav-text">Decoder</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC-l-%E5%B1%82Decoder-Block%E6%9E%84%E6%88%90"><span class="nav-number">2.9.2.1.</span> <span class="nav-text">ç¬¬$l$å±‚Decoder Blockæ„æˆ</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Masked-Multi-head-Self-Attention-%E5%AF%B9decoder%E8%BE%93%E5%85%A5%E5%81%9A%E8%87%AA%E6%B3%A8%E6%84%8F"><span class="nav-number">2.9.2.1.1.</span> <span class="nav-text">Masked Multi-head Self-Attention (å¯¹decoderè¾“å…¥åšè‡ªæ³¨æ„)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Encoder-Decoder-Attention-%E6%9F%A5%E8%AF%A2encoder%E8%BE%93%E5%87%BA"><span class="nav-number">2.9.2.1.2.</span> <span class="nav-text">Encoder-Decoder Attention (æŸ¥è¯¢encoderè¾“å‡º)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Feed-Forward-Network"><span class="nav-number">2.9.2.1.3.</span> <span class="nav-text">Feed Forward Network</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%9C%80%E7%BB%88%E8%BE%93%E5%87%BA"><span class="nav-number">2.9.2.1.4.</span> <span class="nav-text">æœ€ç»ˆè¾“å‡º</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%87%AA%E5%9B%9E%E5%BD%92-vs-%E9%9D%9E%E8%87%AA%E5%9B%9E%E5%BD%92"><span class="nav-number">2.9.2.2.</span> <span class="nav-text">è‡ªå›å½’ vs éè‡ªå›å½’</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Autoregressive-Transformer-AT"><span class="nav-number">2.9.2.2.1.</span> <span class="nav-text">Autoregressive Transformer (AT)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Non-Autoregressive-Transformer-NAT"><span class="nav-number">2.9.2.2.2.</span> <span class="nav-text">Non-Autoregressive Transformer (NAT)</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vision-Transformer-ViT"><span class="nav-number">2.10.</span> <span class="nav-text">Vision Transformer (ViT)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Generative-Adversarial-Networks-GAN"><span class="nav-number">2.11.</span> <span class="nav-text">Generative Adversarial Networks (GAN)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Key-Components"><span class="nav-number">2.11.1.</span> <span class="nav-text">Key Components</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-Generator-G"><span class="nav-number">2.11.1.1.</span> <span class="nav-text">1. Generator (G)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-Discriminator-D"><span class="nav-number">2.11.1.2.</span> <span class="nav-text">2. Discriminator (D)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Overall-Objective"><span class="nav-number">2.11.2.</span> <span class="nav-text">Overall Objective</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Train"><span class="nav-number">2.11.3.</span> <span class="nav-text">Train</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Step-1-Fix-Generator-Train-Discriminator"><span class="nav-number">2.11.3.1.</span> <span class="nav-text">Step 1: Fix Generator, Train Discriminator</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Step-2-Fix-Discriminator-Train-Generator"><span class="nav-number">2.11.3.1.1.</span> <span class="nav-text">Step 2: Fix Discriminator, Train Generator</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Self-Supervised"><span class="nav-number">2.12.</span> <span class="nav-text">Self-Supervised</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#BERT"><span class="nav-number">2.12.1.</span> <span class="nav-text">BERT</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Masked-Language-Modeling-MLM"><span class="nav-number">2.12.1.1.</span> <span class="nav-text">Masked Language Modeling (MLM)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Next-Sentence-Prediction-NSP"><span class="nav-number">2.12.1.2.</span> <span class="nav-text">Next Sentence Prediction (NSP)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#BERT%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B"><span class="nav-number">2.12.1.3.</span> <span class="nav-text">BERTçš„è®­ç»ƒæµç¨‹</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="nav-number">2.12.1.4.</span> <span class="nav-text">æ€»ç»“</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">82</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
