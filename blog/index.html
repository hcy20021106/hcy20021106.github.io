<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hechenyi.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://hechenyi.github.io/blog/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://hechenyi.github.io/blog/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/11/23/11-22/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/11/23/11-22/" class="post-title-link" itemprop="url">11-22</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-11-23 00:43:02 / Modified: 02:25:57" itemprop="dateCreated datePublished" datetime="2025-11-23T00:43:02+08:00">2025-11-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          <h2 id="online视频传输"><a href="#online视频传输" class="headerlink" title="online视频传输"></a>online视频传输</h2><p>transmitter + receiver 进行收发</p>
<p>数据格式转化方式：<br>tensor(int32) -&gt; socket payload (比特流(比特数由max K 决定) -&gt; byte)<br>打包成字节的函数：<br><strong>packed &#x3D; np.packbits(bits_1d, bitorder&#x3D;BITORDER)</strong></p>
<p>tranmitter.py中为了简化，没有按这个方式转为比特流，而是:<br>**latent_np.tobytes()**将int32直接转为4bytes</p>
<h3 id="推流方式"><a href="#推流方式" class="headerlink" title="推流方式"></a>推流方式</h3><ul>
<li>HLS + FFmpeg<br>FFmpeg 负责生成 HLS 分片与 playlist<br>Web 服务器（Nginx&#x2F;Apache&#x2F;S3&#x2F;OSS&#x2F;本地 HTTP）负责提供访问<br>播放端使用浏览器或播放器拉取 m3u8 文件即可</li>
<li>RTMP</li>
<li>SRT</li>
<li>WebRTC<br>不需要FFmpeg编码，<br>浏览器会自动处理：<br>封装 RTP packet<br>发送<br>重传<br>丢包修复<br>抖动控制<br>SRTP 加密</li>
<li>RTSP</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/11/19/Image/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/11/19/Image/" class="post-title-link" itemprop="url">Image</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-11-19 15:45:03 / Modified: 16:50:03" itemprop="dateCreated datePublished" datetime="2025-11-19T15:45:03+08:00">2025-11-19</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          <p>图像中，<strong>频率</strong>是指像素变化的快慢，不是出现次数：</p>
<ul>
<li>纹理</li>
<li>边缘</li>
<li>细小颗粒</li>
<li>噪声</li>
</ul>
<p>低频是指像素变化慢的部分：</p>
<ul>
<li>天空的渐变</li>
<li>大区域的平滑颜色</li>
<li>物体的整体轮廓</li>
<li>大形状<br>这些都是颜色&#x2F;亮度变化慢的</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/11/19/AutoEncoder/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/11/19/AutoEncoder/" class="post-title-link" itemprop="url">AutoEncoder</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-11-19 01:26:42 / Modified: 16:51:17" itemprop="dateCreated datePublished" datetime="2025-11-19T01:26:42+08:00">2025-11-19</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          <h2 id="DINOv2"><a href="#DINOv2" class="headerlink" title="DINOv2"></a>DINOv2</h2><p>DINOv2对普通ViT-B&#x2F;14的backbone做了很多改进，如下：</p>
<ul>
<li><p>使用Conv2d来实现PatchEmbed，不用原生ViT的线性patch projection（Flatten -&gt; Linear）</p>
</li>
<li><p>Memory Efficient Attention<br>  自己的更“搞笑注意力”实现<br>  MemEffAttention(dim &#x3D; 768, num_heads &#x3D; 12)</p>
</li>
<li><p>LayerScale<br>  对稳定大规模训练非常重要<br>  抑制梯度爆炸</p>
</li>
<li><p>DropPath</p>
</li>
<li><p>LayerNorm</p>
</li>
<li><p>MLP</p>
</li>
<li><p>Token</p>
</li>
<li><p>Antialias Positional Interpolation</p>
</li>
<li><p>Weighted Global Pooling<br>  对所有patch进行加权相加，优于CLS token(CLS在分类任务有效，对于LLM的视觉前端，用的是所有patch)</p>
</li>
</ul>
<h3 id="Conv2d与Linear的转换"><a href="#Conv2d与Linear的转换" class="headerlink" title="Conv2d与Linear的转换"></a>Conv2d与Linear的转换</h3><p>Linear projection 对每个 patch 的投影公式是一样的<br>以DINOv2的patch embedding为例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">patch_flat: shape=(14*14*3)</span><br><span class="line">↓</span><br><span class="line">Linear(14*14*3 → 768)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Conv2d(<span class="keyword">in</span>=3, out=768, kernel=14, stride=14)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Swin-Transformer"><a href="#Swin-Transformer" class="headerlink" title="Swin Transformer"></a>Swin Transformer</h2><p>借用CNN下采样思路，每次downsample用的是parch merging，patch个数减少，patch的通道数增加。</p>
<h2 id="RAE"><a href="#RAE" class="headerlink" title="RAE"></a>RAE</h2><p>RAE (Representative AutoEncoder) 是使用预训练表征编码器 (如DINOv2) 替代VAE encoder，目的是让扩散模型在更优、语义更丰富的latent空间中工作，从而提高训练效率和最终生成质量。<br>因此使用SOTA表征模型提供更强latent表示：DINO、SigLIP和MAE等<br>论文提出的 RAE（Representation Autoencoder）结合：</p>
<ul>
<li><p>预训练 encoder（冻结，不再训练）</p>
</li>
<li><p>轻量 ViT decoder（可监督训练）</p>
</li>
</ul>
<h2 id="CLIP"><a href="#CLIP" class="headerlink" title="CLIP"></a>CLIP</h2><h2 id="UNet"><a href="#UNet" class="headerlink" title="UNet"></a>UNet</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">hs = []</span><br><span class="line">t_emb = timestep_embedding(timesteps, self.model_channels, repeat_only=False)</span><br><span class="line">emb = self.time_embed(t_emb)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self.num_classes is not None:</span><br><span class="line">    assert y.shape == (x.shape[0],)</span><br><span class="line">    emb = emb + self.label_emb(y)</span><br><span class="line"></span><br><span class="line">h = x.type(self.dtype)</span><br><span class="line"><span class="keyword">for</span> module <span class="keyword">in</span> self.input_blocks:</span><br><span class="line">    h = module(h, emb, context)</span><br><span class="line">    hs.append(h)</span><br><span class="line">h = self.middle_block(h, emb, context)</span><br><span class="line"><span class="keyword">for</span> module <span class="keyword">in</span> self.output_blocks:</span><br><span class="line">    h = th.cat([h, hs.pop()], dim=1)</span><br><span class="line">    h = module(h, emb, context)</span><br><span class="line">h = h.type(x.dtype)</span><br><span class="line"><span class="keyword">if</span> self.predict_codebook_ids:</span><br><span class="line">    <span class="built_in">return</span> self.id_predictor(h)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">return</span> self.out(h)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>decode每层的输出和encoder对应的每层直接相加</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/11/11/gpu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/11/11/gpu/" class="post-title-link" itemprop="url">gpu</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-11-11 14:27:21" itemprop="dateCreated datePublished" datetime="2025-11-11T14:27:21+08:00">2025-11-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-11-13 10:43:26" itemprop="dateModified" datetime="2025-11-13T10:43:26+08:00">2025-11-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          <pre><code class="language-bash">nvidia-smi
CUDA_VISIBLE_DEVICES=5 python .py
```+
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/09/14/pruning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/14/pruning/" class="post-title-link" itemprop="url">pruning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-14 17:03:44 / Modified: 21:26:41" itemprop="dateCreated datePublished" datetime="2025-09-14T17:03:44+08:00">2025-09-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          <h1 id="README-—-PyTorch-模型剪枝总结"><a href="#README-—-PyTorch-模型剪枝总结" class="headerlink" title="README — PyTorch 模型剪枝总结"></a>README — PyTorch 模型剪枝总结</h1><h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h2><ul>
<li><strong>剪枝 (Pruning)</strong>：通过将部分权重置零，来减少模型的有效参数量，从而降低计算量和显存开销。  </li>
<li><strong>剪枝方式</strong>：<ul>
<li><strong>非结构化剪枝 (Unstructured Pruning)</strong>：在权重矩阵中逐元素置零，灵活但实际加速有限。</li>
<li><strong>结构化剪枝 (Structured Pruning)</strong>：直接删除整个卷积核、通道或层，更适合硬件加速。</li>
</ul>
</li>
</ul>
<h2 id="2-named-parameters-vs-named-modules"><a href="#2-named-parameters-vs-named-modules" class="headerlink" title="2. named_parameters() vs named_modules()"></a>2. <code>named_parameters()</code> vs <code>named_modules()</code></h2><ul>
<li><code>named_parameters()</code>  <ul>
<li>返回 <strong>参数名 + 张量</strong>  </li>
<li>常用于直接操作 <code>weight</code> &#x2F; <code>bias</code>。  </li>
<li>例如剪枝时需要传入 <code>(module, &quot;weight&quot;)</code> 就必须从参数开始。</li>
</ul>
</li>
<li><code>named_modules()</code>  <ul>
<li>返回 <strong>模块名 + 子模块</strong>  </li>
<li>可以枚举出所有子模块 (Conv、Linear、BN 等)。  </li>
<li>适合筛选特定层（比如 Conv3d），再去访问其参数。</li>
</ul>
</li>
</ul>
<p>总结：  </p>
<ul>
<li><strong>要找到具体层</strong> → 用 <code>named_modules()</code>  </li>
<li><strong>要操作参数</strong> → 用 <code>named_parameters()</code></li>
</ul>
<h2 id="3-TorchScript-下的剪枝"><a href="#3-TorchScript-下的剪枝" class="headerlink" title="3. TorchScript 下的剪枝"></a>3. TorchScript 下的剪枝</h2><ul>
<li>TorchScript 模型的子模块 (<code>encoder.jit</code>) 会变成 <code>RecursiveScriptModule</code>。  </li>
<li>可以通过 <code>hasattr(module, &quot;original_name&quot;)</code> 判断模块原始类型，比如 <code>&quot;Conv3d&quot;</code>。  </li>
<li>TorchScript 下不能直接用 <code>torch.nn.utils.prune</code>，因为它需要注册新的 <code>Parameter</code>，而 <code>jit</code> 的权重不是标准 <code>Parameter</code> 类型。</li>
</ul>
<p>解决方案：<strong>手动实现剪枝逻辑</strong>：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prune_jit_global</span>(<span class="params">encoder, amount=<span class="number">0.2</span></span>):</span><br><span class="line">    conv_weights, conv_modules = [], []</span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> encoder.named_modules():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(module, <span class="string">&quot;original_name&quot;</span>) <span class="keyword">and</span> module.original_name == <span class="string">&quot;Conv3d&quot;</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;quant_conv&quot;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&quot;shortcut&quot;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&quot;conv_out.1.conv3d&quot;</span> <span class="keyword">in</span> name:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            conv_weights.append(module.weight.detach().<span class="built_in">abs</span>().flatten())</span><br><span class="line">            conv_modules.append((name, module))</span><br><span class="line"></span><br><span class="line">    all_weights = torch.cat(conv_weights)</span><br><span class="line">    k = <span class="built_in">int</span>(amount * all_weights.numel())</span><br><span class="line">    threshold = torch.topk(all_weights, k, largest=<span class="literal">False</span>).values.<span class="built_in">max</span>()</span><br><span class="line"></span><br><span class="line">    total_pruned, total_params = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> conv_modules:</span><br><span class="line">        W = module.weight.data</span><br><span class="line">        mask = (W.<span class="built_in">abs</span>() &gt; threshold).to(W.dtype)</span><br><span class="line">        pruned = W.numel() - mask.<span class="built_in">sum</span>().item()</span><br><span class="line">        total_pruned += pruned; total_params += W.numel()</span><br><span class="line">        module.weight.data = W * mask</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name:&lt;<span class="number">50</span>&#125;</span> 剪掉 <span class="subst">&#123;pruned&#125;</span>/<span class="subst">&#123;W.numel()&#125;</span> (<span class="subst">&#123;pruned/W.numel():<span class="number">.2</span>%&#125;</span>)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;✅ 全局剪枝完成，总共剪掉 <span class="subst">&#123;total_pruned&#125;</span>/<span class="subst">&#123;total_params&#125;</span> (<span class="subst">&#123;total_pruned/total_params:<span class="number">.2</span>%&#125;</span>)&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> encoder</span><br></pre></td></tr></table></figure>
<h2 id="4-全局剪枝-Global-Unstructured-Pruning"><a href="#4-全局剪枝-Global-Unstructured-Pruning" class="headerlink" title="4. 全局剪枝(Global Unstructured Pruning)"></a>4. 全局剪枝(Global Unstructured Pruning)</h2><p>思路：收集所有层的权重 → 拼接成一个大向量 → 找到全局阈值 → 应用到所有层。</p>
<p>优点：稀疏性分布更均匀，能自动选择“最不重要”的参数。</p>
<p>上述 prune_jit_global 就是全局非结构化剪枝的实现。</p>
<h2 id="5-使用流程"><a href="#5-使用流程" class="headerlink" title="5. 使用流程"></a>5. 使用流程</h2><ul>
<li>加载TorchScript模型</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">encoder = torch.jit.load(<span class="string">&quot;encoder.jit&quot;</span>, map_location=<span class="string">&quot;cuda&quot;</span>).to(dtype=torch.bfloat16)</span><br><span class="line">encoder.eval()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>筛选出需要剪枝的模块 (Conv3d)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, module <span class="keyword">in</span> encoder.named_modules():</span><br><span class="line">    <span class="keyword">if</span> hasattr(module, <span class="string">&quot;original_name&quot;</span>) and module.original_name == <span class="string">&quot;Conv3d&quot;</span>:</span><br><span class="line">        <span class="built_in">print</span>(name, module)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>应用全局剪枝</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">encoder = prune_jit_global(encoder, amount=0.3)  <span class="comment"># 剪掉 30%</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="6-注意事项"><a href="#6-注意事项" class="headerlink" title="6. 注意事项"></a>6. 注意事项</h2><p>TorchScript 的权重是 Tensor，而不是 nn.Parameter → 无法用 torch.nn.utils.prune 的官方 API。</p>
<p>必须手动覆盖 module.weight.data。</p>
<p>剪枝后的权重仍占显存，只是大部分被置零（稀疏矩阵计算需要进一步优化）。</p>
<p>如果想获得实际加速，需要配合 稀疏矩阵库 或 结构化剪枝。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/09/01/Log-Likelihood-Ratio/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/01/Log-Likelihood-Ratio/" class="post-title-link" itemprop="url">Log-Likelihood Ratio</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-01 16:30:48" itemprop="dateCreated datePublished" datetime="2025-09-01T16:30:48+08:00">2025-09-01</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/08/30/AWGN%E4%BF%A1%E9%81%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/30/AWGN%E4%BF%A1%E9%81%93/" class="post-title-link" itemprop="url">AWGN信道</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-08-30 11:02:27 / Modified: 12:14:06" itemprop="dateCreated datePublished" datetime="2025-08-30T11:02:27+08:00">2025-08-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          <h2 id="1-AWGN-信道简介"><a href="#1-AWGN-信道简介" class="headerlink" title="1. AWGN 信道简介"></a>1. AWGN 信道简介</h2><p><strong>AWGN</strong> &#x3D; Additive White Gaussian Noise Channel<br>全称：加性白高斯噪声信道，是最经典的信道模型。</p>
<h3 id="1-1-名称拆解"><a href="#1-1-名称拆解" class="headerlink" title="1.1 名称拆解"></a>1.1 名称拆解</h3><ul>
<li><strong>Additive（加性）</strong>：噪声是叠加在信号上的<br>$$<br>y &#x3D; x + n<br>$$</li>
<li><strong>White（白噪声）</strong>：噪声功率谱密度在所有频率均匀分布  </li>
<li><strong>Gaussian（高斯）</strong>：噪声服从正态分布<br>$$<br>n \sim \mathcal{N}(0, \sigma^2)<br>$$</li>
</ul>
<h3 id="1-2-数学模型"><a href="#1-2-数学模型" class="headerlink" title="1.2 数学模型"></a>1.2 数学模型</h3><p>$$<br>y &#x3D; x + n, \quad n \sim \mathcal{N}(0, \sigma^2)<br>$$</p>
<ul>
<li>$x$：发射符号（BPSK&#x2F;QAM 等调制）  </li>
<li>$n$：高斯白噪声  </li>
<li>$y$：接收符号</li>
</ul>
<p>常用指标：  </p>
<ul>
<li><strong>信噪比 (SNR)</strong><br>$$<br>\text{SNR} &#x3D; \frac{\mathbb{E}[x^2]}{\sigma^2}<br>$$</li>
<li><strong>容量 (Shannon Capacity)</strong><br>$$<br>C &#x3D; \log_2(1+\text{SNR}) \quad [\text{bits per channel use}]<br>$$</li>
</ul>
<hr>
<blockquote>
<p><strong>Notice</strong><br><br>这里采用带宽归一化的假设：<br><br>把每秒能传输的符号数当作带宽B <br><br>每个符号对应一次channel use <br><br>如果不归一化的话，带宽B Hz -&gt; 每秒大约可以传B个符号，那么持续时间T秒内，就可以传B x T个符号。因此也就是B x T次信道使用<br><br>带宽约束d~ &#x3D; 信道使用次数 &#x2F; 源符号数<br><br>d~越大说明信道资源宽裕，说明可以加冗余来提升鲁棒性<br></p>
</blockquote>
<hr>
<h2 id="2-瑞利衰落信道等效为-AWGN"><a href="#2-瑞利衰落信道等效为-AWGN" class="headerlink" title="2. 瑞利衰落信道等效为 AWGN"></a>2. 瑞利衰落信道等效为 AWGN</h2><p>论文中真实信道是 <strong>块衰落瑞利信道</strong>：<br>$$<br>r_i &#x3D; h \cdot s_i + n_i, \quad n_i \sim \mathcal{CN}(0,\delta^2)<br>$$</p>
<p>其中：</p>
<ul>
<li>$h$：瑞利衰落系数（随时间块变化）</li>
<li>$s_i$：发送符号</li>
<li>$n_i$：高斯噪声</li>
</ul>
<h3 id="2-1-信道反演功率控制"><a href="#2-1-信道反演功率控制" class="headerlink" title="2.1 信道反演功率控制"></a>2.1 信道反演功率控制</h3><p>在发射端做信道反演：<br>$$<br>s’_i &#x3D; \frac{s_i}{h}<br>$$</p>
<p>接收端变为：<br>$$<br>r_i &#x3D; h \cdot s’_i + n_i &#x3D; s_i + n_i<br>$$</p>
<h3 id="2-2-等效后的模型"><a href="#2-2-等效后的模型" class="headerlink" title="2.2 等效后的模型"></a>2.2 等效后的模型</h3><p>这样接收端信道就简化为：<br>$$<br>r_i &#x3D; s_i + n_i, \quad n_i \sim \mathcal{CN}(0,\delta^2)<br>$$</p>
<p>即 <strong>AWGN 信道模型</strong>。  </p>
<ul>
<li>等效后的信噪比：$\gamma &#x3D; 1&#x2F;\delta^2$  </li>
<li>便于后续推导容量与误块率。</li>
</ul>
<hr>
<h2 id="3-有限码长信息论-Finite-Blocklength-Theory"><a href="#3-有限码长信息论-Finite-Blocklength-Theory" class="headerlink" title="3. 有限码长信息论 (Finite Blocklength Theory)"></a>3. 有限码长信息论 (Finite Blocklength Theory)</h2><p>传统 Shannon 容量理论假设码长 $L \to \infty$，实际通信系统码长有限，需要修正。</p>
<h3 id="3-1-Polyanskiy–Verdu-结果"><a href="#3-1-Polyanskiy–Verdu-结果" class="headerlink" title="3.1 Polyanskiy–Verdú 结果"></a>3.1 Polyanskiy–Verdú 结果</h3><p>有限码长下，速率 $R_c$、误块率 $\rho$ 和容量 $C$ 的近似关系：<br>$$<br>R_c ;\approx; C - \sqrt{\tfrac{V}{L}} Q^{-1}(\rho) + \mathcal{O}!\left(\tfrac{\log L}{L}\right)<br>$$</p>
<ul>
<li>$C$：信道容量 $\log_2(1+\gamma)$  </li>
<li>$V$：信道弥散度 (dispersion)  </li>
<li>$Q^{-1}$：高斯 Q 函数的反函数</li>
</ul>
<h3 id="3-2-AWGN-信道的容量与弥散度"><a href="#3-2-AWGN-信道的容量与弥散度" class="headerlink" title="3.2 AWGN 信道的容量与弥散度"></a>3.2 AWGN 信道的容量与弥散度</h3><ul>
<li>容量：<br>$$<br>C &#x3D; \log_2(1+\gamma)<br>$$</li>
<li>弥散度：<br>$$<br>V &#x3D; \left(1-\frac{1}{(1+\gamma)^2}\right)(\log_2 e)^2<br>$$</li>
</ul>
<h3 id="3-3-反推得到误块率"><a href="#3-3-反推得到误块率" class="headerlink" title="3.3 反推得到误块率"></a>3.3 反推得到误块率</h3><p>把公式反写为误块率：<br>$$<br>\rho ;\approx; Q!\left(\frac{\sqrt{L},(C-R_c)}{\sqrt{V}}\right)<br>$$</p>
<ul>
<li>分子 $\sqrt{L}(C-R_c)$：离容量的“裕量”  </li>
<li>分母 $\sqrt{V}$：有限码长下的波动项</li>
</ul>
<h3 id="3-4-直觉"><a href="#3-4-直觉" class="headerlink" title="3.4 直觉"></a>3.4 直觉</h3><ul>
<li>如果 $R_c &lt; C$：裕量为正，码长 $L$ 越大，误码率迅速下降  </li>
<li>如果 $R_c &#x3D; C$：误码率收敛到 0.5，不会下降  </li>
<li>如果 $R_c &gt; C$：码率超过容量，误码率始终接近 1</li>
</ul>
<h3 id="3-5-工程经验式"><a href="#3-5-工程经验式" class="headerlink" title="3.5 工程经验式"></a>3.5 工程经验式</h3><p>对具体码型（如极化码），可用指数函数拟合BLER：<br>$$<br>\rho ;\approx; \exp(\beta_1 R_c + \beta_2) \tag{5}<br>$$<br>其中 $\beta_1, \beta_2$ 由仿真拟合，依赖于 $\gamma, L, \text{码型}$。</p>
<h2 id="4-端到端失真上界"><a href="#4-端到端失真上界" class="headerlink" title="4. 端到端失真上界"></a>4. 端到端失真上界</h2><h3 id="4-1-分析思路"><a href="#4-1-分析思路" class="headerlink" title="4.1 分析思路"></a>4.1 分析思路</h3><ul>
<li>一幅图像压缩后得到 $B$ 比特  </li>
<li>源编码速率 $R_s &#x3D; B &#x2F; (\text{源符号数})$  </li>
<li>分为 $T$ 个包，每个包长度 $N$，比特经 $(N,L)$ 信道码 → 码率 $R_c &#x3D; N&#x2F;L$  </li>
<li>每个包传输成功概率 &#x3D; $1-\rho$  </li>
<li>所有 $T$ 个包成功概率 &#x3D; $(1-\rho)^T$  </li>
<li>至少一个失败概率 &#x3D; $1-(1-\rho)^T$</li>
</ul>
<h3 id="4-3-期望失真公式"><a href="#4-3-期望失真公式" class="headerlink" title="4.3 期望失真公式"></a>4.3 期望失真公式</h3><p>$$<br>\mathbb{E}[D] &#x3D; (1-\rho)^T , D_s + \big(1-(1-\rho)^T\big) , O(1)<br>$$</p>
<h3 id="4-4-Theorem-3-1-最终形式"><a href="#4-4-Theorem-3-1-最终形式" class="headerlink" title="4.4 Theorem 3.1 最终形式"></a>4.4 Theorem 3.1 最终形式</h3><p>$$<br>\mathbb{E}[D] ;\leq; (1-\rho)^T D_s + \big(1-(1-\rho)^T\big) O(1) \tag{Theorem 3.1}<br>$$</p>
<hr>
<h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><ul>
<li><p><strong>AWGN 信道</strong>：$y&#x3D;x+n$，最基本的信道模型  </p>
</li>
<li><p><strong>瑞利衰落信道 → AWGN</strong>：通过信道反演功率控制，把衰落抵消掉，只剩高斯噪声  </p>
</li>
<li><p><strong>有限码长信息论</strong>：在有限块长 $L$ 下，误块率不再是“0&#x2F;1”现象，而是通过 Q 函数平滑过渡<br>$$<br>\rho \approx Q!\left(\frac{\sqrt{L}(C-R_c)}{\sqrt{V}}\right)<br>$$</p>
</li>
<li><p>多包传输 + 成功&#x2F;失败概率 -&gt; Theorem 3.1 端到端失真上界</p>
</li>
</ul>
<p><strong>关键依赖变量</strong></p>
<ul>
<li>源编码速率 $R_s \to D_s$  </li>
<li>信道编码速率 $R_c \to \rho$  </li>
<li>包数 $T \to (1-\rho)^T$  </li>
<li>信噪比 $\gamma \to C,V$</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/08/29/D%C2%B2-JSCC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/29/D%C2%B2-JSCC/" class="post-title-link" itemprop="url">D²-JSCC</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-08-29 21:44:15 / Modified: 21:46:40" itemprop="dateCreated datePublished" datetime="2025-08-29T21:44:15+08:00">2025-08-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          <h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><ul>
<li><strong>JSCC (Joint Source Channel Coding)</strong> &#x3D; 联合信源信道编码。</li>
<li>传统方案：<ul>
<li><strong>纯数字传输 (JPEG + LDPC&#x2F;Polar)</strong><br>高 SNR 时接近容量，但低 SNR 时一旦出错会“花屏”。</li>
<li><strong>纯模拟 JSCC</strong><br>没有信道编码，失真随 SNR 平滑退化，但高 SNR 浪费容量。</li>
<li><strong>深度 JSCC</strong><br>用神经网络直接端到端映射图像→信道符号。鲁棒，但高 SNR 不如数字系统。</li>
</ul>
</li>
<li><strong>D²-JSCC</strong>（本文提出）：<br>结合 <strong>深度信源编码 (Deep Source Coding)</strong> + <strong>数字信道编码 (Digital Channel Coding)</strong>，兼顾鲁棒性与容量利用率。</li>
</ul>
<hr>
<h2 id="2-深度-JSCC-vs-D²-JSCC"><a href="#2-深度-JSCC-vs-D²-JSCC" class="headerlink" title="2. 深度 JSCC vs D²-JSCC"></a>2. 深度 JSCC vs D²-JSCC</h2><h3 id="深度-JSCC"><a href="#深度-JSCC" class="headerlink" title="深度 JSCC"></a>深度 JSCC</h3><ul>
<li><strong>没有传统意义上的信道编码</strong>。</li>
<li>图像 → CNN 编码 → 信道符号 → 解码器 CNN → 图像恢复。</li>
<li>鲁棒性来自神经网络自动学到的冗余映射。</li>
<li><strong>优点</strong>：低 SNR 下平滑退化，不会突然花屏。  </li>
<li><strong>缺点</strong>：高 SNR 下码率固定，不能榨干信道容量。</li>
</ul>
<h3 id="D²-JSCC"><a href="#D²-JSCC" class="headerlink" title="D²-JSCC"></a>D²-JSCC</h3><ul>
<li><strong>有传统意义上的信道编码</strong>（如 LDPC、Polar）。  </li>
<li>流程：<br>图像 → 深度信源编码 (DNN) → 比特流<br>→ 信道编码 (LDPC&#x2F;Polar) → 符号<br>→ 无线信道 → 解调&#x2F;译码<br>→ 深度信源解码 (DNN) → 重建图像</li>
<li><strong>优点</strong>：  </li>
<li>低 SNR 下鲁棒（深度信源编码不会像 JPEG 那样产生花屏）；  </li>
<li>高 SNR 下接近信道容量（因为仍有传统信道编码）。</li>
</ul>
<h2 id="3-为什么-D²-JSCC-更鲁棒"><a href="#3-为什么-D²-JSCC-更鲁棒" class="headerlink" title="3. 为什么 D²-JSCC 更鲁棒"></a>3. 为什么 D²-JSCC 更鲁棒</h2><h3 id="JPEG-LDPC-的问题"><a href="#JPEG-LDPC-的问题" class="headerlink" title="JPEG+LDPC 的问题"></a>JPEG+LDPC 的问题</h3><ul>
<li>熵编码比特流对错误极度敏感。</li>
<li>一旦信道码解码失败 → 整帧报废 → 花屏。</li>
</ul>
<h3 id="深度信源编码的优势"><a href="#深度信源编码的优势" class="headerlink" title="深度信源编码的优势"></a>深度信源编码的优势</h3><ul>
<li>DNN 学到的特征是 <strong>分布式冗余</strong>，不依赖严格语法。</li>
<li>即使部分比特错误，解码器 CNN 仍能通过上下文恢复合理图像。</li>
<li>结果：低 SNR 下 <strong>平滑退化</strong>，而不是突然崩溃。</li>
</ul>
<h2 id="4-为什么深度-JSCC-高-SNR-下浪费容量"><a href="#4-为什么深度-JSCC-高-SNR-下浪费容量" class="headerlink" title="4. 为什么深度 JSCC 高 SNR 下浪费容量"></a>4. 为什么深度 JSCC 高 SNR 下浪费容量</h2><h3 id="信道容量"><a href="#信道容量" class="headerlink" title="信道容量"></a>信道容量</h3><ul>
<li>高斯信道容量：<br>[<br>C &#x3D; \log_2(1+\text{SNR})<br>]</li>
<li>数字系统（LDPC&#x2F;Polar）：高 SNR 时码率随 SNR 提升，逼近容量。</li>
</ul>
<h3 id="深度-JSCC-的限制"><a href="#深度-JSCC-的限制" class="headerlink" title="深度 JSCC 的限制"></a>深度 JSCC 的限制</h3><ul>
<li>符号映射是固定的，不会随 SNR 动态提升码率。</li>
<li>优化目标是失真最小化，而不是“码率 &#x3D; 容量”。</li>
<li>即使噪声趋近于 0，仍存在一定的重建误差。</li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul>
<li>高 SNR 下，深度 JSCC 的失真有下限，无法无限逼近零失真。</li>
<li>数字系统能充分利用信道容量，而深度 JSCC 会浪费容量。</li>
</ul>
<h2 id="5-本文创新点"><a href="#5-本文创新点" class="headerlink" title="5. 本文创新点"></a>5. 本文创新点</h2><ol>
<li><p><strong>架构创新</strong><br> 提出 D²-JSCC，把深度信源编码和传统数字信道编码结合。</p>
</li>
<li><p><strong>信源端优化</strong><br> 使用自适应概率模型（辅助潜变量 z + 条件高斯分布）提升压缩效率。</p>
</li>
<li><p><strong>理论贡献</strong><br> 推导了 <strong>端到端失真上界 (Theorem 3.1)</strong>，把信道误块率和系统参数引入到失真公式中。</p>
</li>
<li><p><strong>性能优势</strong></p>
</li>
</ol>
<ul>
<li>低 SNR：比 JPEG+LDPC 鲁棒。  </li>
<li>高 SNR：比深度 JSCC 更接近信道容量。  </li>
<li>实现了“既鲁棒又高效”的传输。</li>
</ul>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><ul>
<li><strong>深度 JSCC</strong>：没有信道编码，低 SNR 鲁棒但高 SNR 浪费容量。  </li>
<li><strong>D²-JSCC</strong>：有信道编码，兼顾低 SNR 鲁棒性和高 SNR 容量利用率。  </li>
<li>本文的价值在于把深度学习的信源编码与传统通信理论结合，提出了一个 <strong>既有实践性能，又有理论保证</strong> 的新型通信框架。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/08/29/Hyperprior/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/29/Hyperprior/" class="post-title-link" itemprop="url">Hyperprior</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-29 11:37:52" itemprop="dateCreated datePublished" datetime="2025-08-29T11:37:52+08:00">2025-08-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hechenyi.github.io/2025/08/29/%E7%86%B5%E7%BC%96%E7%A0%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/29/%E7%86%B5%E7%BC%96%E7%A0%81/" class="post-title-link" itemprop="url">熵编码</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-08-29 11:11:52 / Modified: 11:15:31" itemprop="dateCreated datePublished" datetime="2025-08-29T11:11:52+08:00">2025-08-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">通信原理</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
          <h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h2><ul>
<li><strong>熵编码</strong>（Entropy Coding）是一种<strong>无损压缩方法</strong>，目的是将符号序列用尽可能少的比特表示。</li>
<li>核心思想来自信息论：<br>$H(X) &#x3D; -\sum_x P(x) \log_2 P(x)$<ul>
<li>$H(X)$：理论最少平均比特数（香农熵）  </li>
<li>$P(x)$：符号 $x$ 出现概率</li>
</ul>
</li>
<li>核心原则：<ul>
<li>高频符号 → 用较少比特表示  </li>
<li>低频符号 → 用较多比特表示</li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-常见熵编码方法"><a href="#2-常见熵编码方法" class="headerlink" title="2. 常见熵编码方法"></a>2. 常见熵编码方法</h2><table>
<thead>
<tr>
<th>方法</th>
<th>特点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>霍夫曼编码 (Huffman)</td>
<td>构建前缀码二叉树</td>
<td>符号少，离散概率</td>
</tr>
<tr>
<td>算术编码 (Arithmetic)</td>
<td>将整个序列映射到 [0,1) → 二进制</td>
<td>高维连续概率，精细概率分布</td>
</tr>
<tr>
<td>范围编码 (Range)</td>
<td>算术编码优化实现</td>
<td>类似算术编码，效率高</td>
</tr>
</tbody></table>
<blockquote>
<p>Deep Source Encoder 中使用 <strong>算术编码</strong>。</p>
</blockquote>
<hr>
<h2 id="3-熵编码在深度源编码中的流程"><a href="#3-熵编码在深度源编码中的流程" class="headerlink" title="3. 熵编码在深度源编码中的流程"></a>3. 熵编码在深度源编码中的流程</h2><ol>
<li><strong>DNN 特征提取</strong>：<ul>
<li>输入图像 $x \in X^M$ → DNN → 连续特征向量 $y \in \mathbb{R}^K$</li>
</ul>
</li>
<li><strong>量化</strong>：<ul>
<li>连续特征 $y$ → 离散符号 $\tilde{y} \in \mathbb{Z}^K$</li>
</ul>
</li>
<li><strong>概率建模</strong>：<ul>
<li>使用侧信息 $\tilde{z}$ 建模条件概率：<br>$P_{\tilde{y}|\tilde{z}}(\tilde{y}|\tilde{z})$</li>
<li>使得特征在条件下近似独立，便于编码</li>
</ul>
</li>
<li><strong>熵编码生成比特流</strong>：<ul>
<li>对每个量化符号根据概率分配比特长度</li>
<li>高频符号少比特，低频符号多比特</li>
</ul>
</li>
<li><strong>输出比特流</strong>：<br>$b &#x3D; [b_y, b_z]$<ul>
<li>$b_y$：特征比特  </li>
<li>$b_z$：侧信息比特</li>
</ul>
</li>
</ol>
<hr>
<h2 id="4-示例"><a href="#4-示例" class="headerlink" title="4. 示例"></a>4. 示例</h2><ul>
<li>量化后的符号序列：<br>$\tilde{y} &#x3D; [0, 0, 1, 0, 2, 0, 1, 0]$</li>
<li>概率：<ul>
<li>0 → 0.625  </li>
<li>1 → 0.25  </li>
<li>2 → 0.125</li>
</ul>
</li>
<li>熵编码生成比特数：<ul>
<li>0 → $\sim 0.678$ bit  </li>
<li>1 → 2 bit  </li>
<li>2 → 3 bit</li>
</ul>
</li>
<li>平均比特数：<br>$B_\text{avg} \approx 10.39$ bit</li>
<li>对比固定长度编码 (3 bit × 8 &#x3D; 24 bit) → 节省比特</li>
</ul>
<hr>
<h2 id="5-不使用熵编码的情况"><a href="#5-不使用熵编码的情况" class="headerlink" title="5. 不使用熵编码的情况"></a>5. 不使用熵编码的情况</h2><ul>
<li><strong>固定比特编码</strong>：<ul>
<li>每个量化符号用相同长度的比特表示</li>
<li>示例：特征范围 0–255 → 每个符号 8 bit</li>
<li>序列 $[3,128,255] \to 00000011\ 10000000\ 11111111$</li>
</ul>
</li>
<li><strong>缺点</strong>：<ul>
<li>不能利用符号概率 → 压缩效率低  </li>
<li>总比特数大于熵编码</li>
</ul>
</li>
</ul>
<hr>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><ul>
<li>熵编码是无损压缩的核心方法，用概率分配比特，理论上最接近熵极限  </li>
<li>在 Deep Source Encoder 中：<ol>
<li>DNN 提取特征  </li>
<li>量化离散化  </li>
<li>条件概率建模 + 熵编码生成比特流</li>
</ol>
</li>
<li>相比固定比特编码，熵编码显著减少比特数，提高压缩效率</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/blog/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/blog/page/6/">6</a><a class="extend next" rel="next" href="/blog/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
